{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatars.gif","path":"images/avatars.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/zfb.jpg","path":"images/zfb.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/mm.jpg","path":"images/mm.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1488985946826},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1488985946826},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1488985946826},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1488985946826},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1488985946826},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1488985946826},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1488985946826},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1488985946826},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1488985946826},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1488985946827},{"_id":"themes/next/README.en.md","hash":"4ece25ee5f64447cd522e54cb0fffd9a375f0bd4","modified":1488985946827},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1488985946827},{"_id":"themes/next/_config.yml","hash":"b4a2628172fc60d12aa8e5d140318dd458f23516","modified":1489279114098},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1488985946827},{"_id":"themes/next/gulpfile.coffee","hash":"933e6d29eb82522cff0df209d52b935e91b1111c","modified":1488985946827},{"_id":"themes/next/package.json","hash":"7e87b2621104b39a30488654c2a8a0c6a563574b","modified":1488985946833},{"_id":"source/_posts/20170606.md","hash":"d2ce674b6e1dc280c75f5d2ef40a7b60253065b4","modified":1496847933069},{"_id":"source/_posts/booklist.md","hash":"286b9ebb6fefbe4c71788c9c8945f65fd13ec603","modified":1489594126790},{"_id":"source/_posts/cleverboysusegoodnotebook.md","hash":"4449b46373541e80a4bda6aebe584989ca1e6199","modified":1489076880247},{"_id":"source/_posts/dadaozhijian.md","hash":"a2a568f3abc28094c7865ef7547839408057eb72","modified":1489283568986},{"_id":"source/_posts/duominogu.md","hash":"8fb6bf29f76ee2f504f88d3e8ec3179a6f5d68da","modified":1494433921021},{"_id":"source/_posts/duominogu.md~","hash":"9642d6c3bf95273845f8ddcdfd7e06ece460038a","modified":1494433569819},{"_id":"source/_posts/findandawk.md","hash":"bb3f68559a99e834b666e8797258612ffb63fe9f","modified":1488293307303},{"_id":"source/_posts/groupbyandrollup.md","hash":"c31b2b41fc8151cc54b77e4eaaf6a6b985e36cca","modified":1489414018237},{"_id":"source/_posts/hello-world.md","hash":"177a1aa623b8efd4a073b3589fada4d0ccb3282d","modified":1489017035715},{"_id":"source/_posts/hello.md","hash":"18e4c079bf7e02c4fd940824713e77114d52110e","modified":1488294032231},{"_id":"source/_posts/iterator.md","hash":"d2763146f3106549fbe895e59a5b36f5e3e22f78","modified":1488979872349},{"_id":"source/_posts/mybaby01.md","hash":"69f6a4391aac6012dc04c1715e658b2aae7a1cf7","modified":1494433912609},{"_id":"source/_posts/mybaby01.md~","hash":"f84bd824dfc804dc47334e8aba265ae7e83a22d4","modified":1494347211996},{"_id":"source/_posts/scala-none.md","hash":"121acdd8a28b5f72ccbc7d517eb2ef37aa7936b3","modified":1504193906685},{"_id":"source/_posts/scalaa.md","hash":"e0bc5a970d06d8a7cd2ae36c4b3d185d9dc68bd7","modified":1504102485138},{"_id":"source/_posts/scalab-md.md","hash":"4003d438447f0a224d274f8134c710b289f47226","modified":1504136097748},{"_id":"source/_posts/test.md","hash":"781b9fd3afa05876b8d712082be91efeede8de08","modified":1487958966762},{"_id":"source/About/index.md","hash":"4eaa506fd5125e4a2e2a73cde3519f5ca5f94757","modified":1504195033890},{"_id":"source/categories/index.md","hash":"5e66f4cbf6f485910fd0e62912b12f26322fa3b2","modified":1489274880960},{"_id":"source/tags/index.md","hash":"1ba407be25bafaec1019746c2fdf6f76e7fcee9a","modified":1489275652341},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1488985946790},{"_id":"themes/next/.git/config","hash":"91b6a53b2a7f929b698734717a38d4ac169f0c1f","modified":1488985946791},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1488985724429},{"_id":"themes/next/.git/index","hash":"bf01809e42c4966b00ca0ad8a18ee45980caa76e","modified":1494424821667},{"_id":"themes/next/.git/packed-refs","hash":"547f7c5e2791e36cc09c2444d3a4a65fe5468d12","modified":1488985946680},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1488985946826},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1488985946826},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1488985946827},{"_id":"themes/next/languages/default.yml","hash":"95ec5cdfb563854f231b76162a3494f6ecc5bf61","modified":1488985946827},{"_id":"themes/next/languages/en.yml","hash":"95ec5cdfb563854f231b76162a3494f6ecc5bf61","modified":1488985946827},{"_id":"themes/next/languages/fr-FR.yml","hash":"e98f1558347752a20019b71f0b1f9c8be1b34f42","modified":1488985946827},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1488985946827},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1488985946827},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1488985946828},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1488985946828},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1488985946828},{"_id":"themes/next/languages/ru.yml","hash":"5022885d8955e1b91d8841048db272bf99c59a76","modified":1488985946828},{"_id":"themes/next/languages/zh-Hans.yml","hash":"40d01dc46d57f71c2ef635c45b295d4355456e90","modified":1488985946828},{"_id":"themes/next/languages/zh-hk.yml","hash":"19c23d21f262e24c06ee6ddfd51d2a6585304f88","modified":1488985946828},{"_id":"themes/next/languages/zh-tw.yml","hash":"68407799271c78ecc07f03d238257dd8c65ad42d","modified":1488985946828},{"_id":"themes/next/languages/zh.yml","hash":"40d01dc46d57f71c2ef635c45b295d4355456e90","modified":1488989930145},{"_id":"themes/next/layout/_layout.swig","hash":"2c0c3547a5b470024326a33ae2779d5ee0252266","modified":1488985946829},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1488985946833},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1488985946833},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1488985946833},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1488985946833},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1488985946833},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1488985946833},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1488985946833},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1488985946834},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1488985946834},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1488985946867},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1488985946867},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1488985946867},{"_id":"source/_posts/spark1.md","hash":"e380b13382801206448b4c9b49a5fedc2e04d738","modified":1489275514813},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946842},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"86b9655a9ebbde13ac8dd5795eb4d5b539edab0f","modified":1488985724461},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1488985724490},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"42fa41564917b44183a50c4d94bb03e1768ddad8","modified":1488985724504},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1488985724489},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1488985724493},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"b4ad74c989616b7395dc6c9fce9871bb1e86dfb5","modified":1488985724495},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1488985724493},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1488985724490},{"_id":"themes/next/.git/hooks/update.sample","hash":"39355a075977d05708ef74e1b66d09a36e486df1","modified":1488985724494},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1488985724537},{"_id":"themes/next/.git/logs/HEAD","hash":"1d07f9a2e699c79e45e9ea44dd1c7bc1ff561d29","modified":1488985946790},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1488985946828},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1488985946829},{"_id":"themes/next/layout/_partials/comments.swig","hash":"970aa668680896262b1056bb5787fc9ec8754495","modified":1488985946829},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1488985946829},{"_id":"themes/next/layout/_partials/footer.swig","hash":"4371b920c11f9c6a5b0b2bf90fb6aeae81bbf77e","modified":1489333412150},{"_id":"themes/next/layout/_partials/head.swig","hash":"a0eafe24d1dae30c790ae35612154b3ffbbd5cce","modified":1488985946830},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1489280853616},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1488985946830},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1488985946830},{"_id":"themes/next/layout/_partials/search.swig","hash":"7b61e96508df70152b809ea5354236ab7f0d54f4","modified":1488985946830},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1488985946831},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1488985946831},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1488985946831},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"4512867d80d9eddfc3a0f5fea3c456f33aa9d522","modified":1488985946833},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1488985946829},{"_id":"themes/next/layout/_macro/post.swig","hash":"2c2efe44ea013030f3ce5da7bfdeddb74489eb6e","modified":1488985946829},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1488985946829},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"911b99ba0445b2c07373128d87a4ef2eb7de341a","modified":1488985946829},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1488985946829},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1488985946834},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1488985946834},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1488985946834},{"_id":"themes/next/scripts/tags/exturl.js","hash":"79378f3a1cd90518b07808ed09156a3ab55ffa31","modified":1488985946834},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1488985946834},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1488985946835},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1488985946842},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1488985946842},{"_id":"themes/next/source/images/avatars.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1488985946843},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1488985946843},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1488985946843},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1488985946843},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1488985946843},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1488985946843},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1488985946843},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1488985946843},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1488985946844},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1488985946844},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1488985946844},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1488985946844},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1488985946844},{"_id":"themes/next/source/images/zfb.jpg","hash":"a56542f0428978ff7a91bd10591fb8354a827044","modified":1488992366773},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946831},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946831},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946840},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946840},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946840},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946842},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488985946842},{"_id":"themes/next/.git/refs/heads/master","hash":"8e263f0e3c466c2948b5c2b1e849c404b26898af","modified":1488985946790},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1488985946828},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1488985946828},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1488985946830},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1488985946830},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"2d1075f4cabcb3956b7b84a8e210f5a66f0a5562","modified":1488985946830},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1488985946830},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1488985946830},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1488985946830},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1488985946830},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1488985946830},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1488985946831},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1488985946831},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1488985946831},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"e46900412e28f529c26e25e6bada342006435a32","modified":1488985946831},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"a279e1881208aff2f669fe235e9661ab825bc540","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1488985946833},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"f4dbd4c896e6510ded8ebe05394c28f8a86e71bf","modified":1488985946833},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1488985946833},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1488985946833},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1488985946833},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1488985946840},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1488985946840},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1488985946840},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1488985946842},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"06f432f328a5b8a9ef0dbd5301b002aba600b4ce","modified":1488985946842},{"_id":"themes/next/source/css/_variables/base.styl","hash":"74a4f177e56dba5371571baf1962d52325d94440","modified":1488989457249},{"_id":"themes/next/source/images/mm.jpg","hash":"22fc9bbbe8c2413c20c1abe99c11e7c3b40d8406","modified":1488992361666},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1488985946844},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1488985946844},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1488985946844},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1488985946844},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1488985946844},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1488985946844},{"_id":"themes/next/source/js/src/post-details.js","hash":"3b2d64c2e6ae072ba2a9ebf7f09908a1543abd58","modified":1488985946844},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1488985946845},{"_id":"themes/next/source/js/src/utils.js","hash":"e13c9ccf70d593bdf3b8cc1d768f595abd610e6e","modified":1488985946845},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1488985946845},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1488985946848},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1488985946848},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1488985946848},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1488985946851},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1488985946851},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1488985946851},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1488985946851},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1488985946852},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1488985946852},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1488985946852},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1488985946852},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1488985946852},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1488985946863},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1488985946864},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1488985946864},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1488985946864},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1488985946864},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1488985946864},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1488985946864},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1488985946865},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1488985946865},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1488985946866},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1488985946867},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1488985946867},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1488985946863},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"1d07f9a2e699c79e45e9ea44dd1c7bc1ff561d29","modified":1488985946790},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1488985946770},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1488985946831},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1488985946831},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1488985946831},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-mta.swig","hash":"a652f202bd5b30c648c228ab8f0e997eb4928e44","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/comments/livere.swig","hash":"7240f2e5ec7115f8abbbc4c9ef73d4bed180fdc7","modified":1488985946832},{"_id":"themes/next/layout/_scripts/third-party/comments/youyan.swig","hash":"af9dd8a4aed7d06cf47b363eebff48850888566c","modified":1488985946832},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"59ad08bcc6fe9793594869ac2b4c525021453e78","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"ef089a407c90e58eca10c49bc47ec978f96e03ba","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1488985946838},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"7804e31c44717c9a9ddf0f8482b9b9c1a0f74538","modified":1488985946839},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1488985946839},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1488985946840},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1488985946840},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1488985946840},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1488985946840},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1488985946840},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1488985946840},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1488985946840},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"f15537cee1a9ef4fa1e72a1670ebce4097db8115","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1488985946842},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1488985946842},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1488985946842},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1488985946845},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1488985946850},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1488985946850},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1488985946851},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1488985946851},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1488985946852},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1488985946852},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1488985946853},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1488985946853},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1488985946864},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1488985946864},{"_id":"themes/next/.git/objects/pack/pack-a95573b69ce446566225c894464cba61f7e57293.idx","hash":"3903b3385c6affbb99188c8f10c2f0794fcd7a05","modified":1488985946543},{"_id":"themes/next/source/images/avatar.gif","hash":"3bce2245dd3d2ba011064e17595d68a0e8ded53b","modified":1489276847415},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1488985946862},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1488985946863},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1488985946866},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"1d07f9a2e699c79e45e9ea44dd1c7bc1ff561d29","modified":1488985946790},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1488985946835},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"755b04edbbfbdd981a783edb09c9cc34cb79cea7","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1488985946836},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"b9a2e76f019a5941191f1263b54aef7b69c48789","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"bfd806d0a9f21446a22df82ac02e37d0075cc3b5","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1488985946837},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a2ec22ef4a6817bbb2abe8660fcd99fe4ca0cc5e","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1488985946838},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"8fe1e55bc290e6aaf07cc644fe27b62107a272a8","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"173490e21bece35a34858e8e534cf86e34561350","modified":1488985946839},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1488985946839},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1488985946841},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1488985946841},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1488985946849},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1488985946850},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1488985946850},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1488985946854},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1488985946856},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1488985946862},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1488985946848},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1488985946860},{"_id":"themes/next/.git/objects/pack/pack-a95573b69ce446566225c894464cba61f7e57293.pack","hash":"3e3ac201472e4a0454af57a6dddf7ee59436b224","modified":1488985946536}],"Category":[{"name":"","_id":"cj70mt0or000460tuxolgvinf"},{"name":"spark","_id":"cj70mt0pw000i60tu3c2ps462"},{"name":"","_id":"cj70mt0qk000u60tujrwu8jwn"}],"Data":[],"Page":[{"title":"","date":"2017-03-11T23:15:38.000Z","_content":"\n1. \n    * hadoopsparkflumehivehbasezookeeper\n        1. hadoopmrhdfsapihadoop\n        1. flume\n        111. sqlhive\n        111. hbaseapi\n        111. zk\n\n1. \n    * javascalapythonRshell\n        11. java\n        111. springmybatis\n        111. scala\n        111. pythonnumpy pandas matplotlib \n    * linuxshellsedviemacs\n    * \n        111. svmsvm\n        111. MLPh2omlp\n        111. \n1. \n    - 980548079@qq.com\n    ![wo](/home/fangqing/Downloads/xiong.JPG)\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>\n","source":"About/index.md","raw":"---\ntitle: \ndate: 2017-03-12 07:15:38\n---\n\n1. \n    * hadoopsparkflumehivehbasezookeeper\n        1. hadoopmrhdfsapihadoop\n        1. flume\n        111. sqlhive\n        111. hbaseapi\n        111. zk\n\n1. \n    * javascalapythonRshell\n        11. java\n        111. springmybatis\n        111. scala\n        111. pythonnumpy pandas matplotlib \n    * linuxshellsedviemacs\n    * \n        111. svmsvm\n        111. MLPh2omlp\n        111. \n1. \n    - 980548079@qq.com\n    ![wo](/home/fangqing/Downloads/xiong.JPG)\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>\n","updated":"2017-08-31T15:57:13.890Z","path":"About/index.html","_id":"cj70mt0oh000160tus9f21p48","comments":1,"layout":"page","content":"<p></p>\n<ol>\n<li><p></p>\n<ul>\n<li>hadoopsparkflumehivehbasezookeeper<ol>\n<li>hadoopmrhdfsapihadoop</li>\n<li>flume</li>\n<li>sqlhive</li>\n<li>hbaseapi</li>\n<li>zk</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>javascalapythonRshell<ol>\n<li>java</li>\n<li>springmybatis</li>\n<li>scala</li>\n<li>pythonnumpy pandas matplotlib </li>\n</ol>\n</li>\n<li>linuxshellsedviemacs</li>\n<li><ol>\n<li>svmsvm</li>\n<li>MLPh2omlp</li>\n<li></li>\n</ol>\n</li>\n</ul>\n</li>\n<li><ul>\n<li>980548079@qq.com<br><img src=\"/home/fangqing/Downloads/xiong.JPG\" alt=\"wo\"><iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=\"330\" height=\"86\" src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>\n</li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<p></p>\n<ol>\n<li><p></p>\n<ul>\n<li>hadoopsparkflumehivehbasezookeeper<ol>\n<li>hadoopmrhdfsapihadoop</li>\n<li>flume</li>\n<li>sqlhive</li>\n<li>hbaseapi</li>\n<li>zk</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>javascalapythonRshell<ol>\n<li>java</li>\n<li>springmybatis</li>\n<li>scala</li>\n<li>pythonnumpy pandas matplotlib </li>\n</ol>\n</li>\n<li>linuxshellsedviemacs</li>\n<li><ol>\n<li>svmsvm</li>\n<li>MLPh2omlp</li>\n<li></li>\n</ol>\n</li>\n</ul>\n</li>\n<li><ul>\n<li>980548079@qq.com<br><img src=\"/home/fangqing/Downloads/xiong.JPG\" alt=\"wo\"><iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"","date":"2017-03-11T23:17:33.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: \ndate: 2017-03-12 07:17:33\ntype: \"categories\"\n---\n","updated":"2017-03-11T23:28:00.960Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cj70mt0oo000360tuq8yk789w","content":"","excerpt":"","more":""},{"title":"","date":"2017-03-11T15:40:13.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: \ndate: 2017-03-11 23:40:13\ntype: \"tags\"\n---\n","updated":"2017-03-11T23:40:52.341Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cj70mt0p4000760tu92aan66a","content":"","excerpt":"","more":""}],"Post":[{"title":"","date":"2017-06-07T14:03:26.000Z","_content":"\n\n,,,\n<!-- more -->\n\n,\n:\n\n\n\n\n\n\n\n","source":"_posts/20170606.md","raw":"---\ntitle: \ndate: 2017-06-07 22:03:26\ncategory: \ntags: \n  -\n---\n\n\n,,,\n<!-- more -->\n\n,\n:\n\n\n\n\n\n\n\n","slug":"20170606","published":1,"updated":"2017-06-07T15:05:33.069Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0o9000060tus60zt94y","content":"<p></p>\n<p>,,,<br><a id=\"more\"></a><br><br>,<br>:<br><br><br><br></p>\n","excerpt":"<p></p>\n<p>,,,<br>","more":"<br><br>,<br>:<br><br><br><br></p>"},{"title":"","date":"2017-03-15T15:47:30.000Z","_content":"\n<!-- more -->\n## \n### \n* \n* \n* \n* \n* \n* \n* \n\n\n>\n\n\n\n\n\n\n\n\n### \n* \n* \n* \n* \n* \n\n### \n* \n\n### \n* \n","source":"_posts/booklist.md","raw":"---\ntitle: \ndate: 2017-03-15 23:47:30\ntags:\n---\n\n<!-- more -->\n## \n### \n* \n* \n* \n* \n* \n* \n* \n\n\n>\n\n\n\n\n\n\n\n\n### \n* \n* \n* \n* \n* \n\n### \n* \n\n### \n* \n","slug":"booklist","published":1,"updated":"2017-03-15T16:08:46.790Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0ok000260tuqi1n4fdg","content":"<p><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<blockquote>\n<p><br><br><br><br><br><br><br></p>\n</blockquote>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n</ul>\n","excerpt":"<p><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<blockquote>\n<p><br><br><br><br><br><br><br></p>\n</blockquote>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n</ul>"},{"title":"","date":"2017-03-09T15:57:54.000Z","_content":"\n<!-- more -->\n\n\n\n\n","source":"_posts/cleverboysusegoodnotebook.md","raw":"---\ntitle: \ndate: 2017-03-09 23:57:54\ntag: \n---\n\n<!-- more -->\n\n\n\n\n","slug":"cleverboysusegoodnotebook","published":1,"updated":"2017-03-09T16:28:00.247Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0p0000660tucsr32ywl","content":"<p><br><a id=\"more\"></a><br></p>\n<p><br></p>\n","excerpt":"<p><br>","more":"<br></p>\n<p><br></p>"},{"title":"","date":"2017-03-09T16:00:00.000Z","_content":"\n\n<!-- more -->\n\n 30\n\n\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>\n\n","source":"_posts/dadaozhijian.md","raw":"---\ntitle: \ndate: 2017-03-10\ntags: \n---\n\n\n<!-- more -->\n\n 30\n\n\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>\n\n","slug":"dadaozhijian","published":1,"updated":"2017-03-12T01:52:48.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0p8000860tugthcweur","content":"<p><br><a id=\"more\"></a><br><br> 30<br><br></p>\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=\"330\" height=\"86\" src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>\n\n","excerpt":"<p><br>","more":"<br><br> 30<br><br></p>\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"http://music.163.com/outchain/player?type=2&id=430685732&auto=1&height=66\"></iframe>"},{"title":"","date":"2017-05-09T16:00:00.000Z","_content":"  --\n<!-- more -->\n\n^_^,bug\n\n\n\n\n\n","source":"_posts/duominogu.md","raw":"---\ntitle: \ndate: 2017-05-10\ntags: \n---\n  --\n<!-- more -->\n\n^_^,bug\n\n\n\n\n\n","slug":"duominogu","published":1,"updated":"2017-05-10T16:32:01.021Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0pg000960tu6xsgjttb","content":"<p>  <br><a id=\"more\"></a><br><br>^_^,bug<br><br><br><br><br><br></p>\n","excerpt":"<p>  <br>","more":"<br><br>^_^,bug<br><br><br><br><br><br></p>"},{"title":"find awk  grep ","date":"2017-02-23T15:57:54.000Z","_content":"find awk  grep \nlinuxfindawkgrep\nlinux\n\n<!--more-->\n## find\nfind\n``` bash\nfind\n.\n./_posts\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n```\n\n1. \n1. \n1. -print\nfindfind\n\n``` bash\nfind  ./ -print -name \"*\"\n./\n./-name\n./_posts\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n```\n-print0\n``` bash\nfind  ./ -print0 -name \"*\"\n././-name./_posts./_posts/hello-world.md./_posts/findandawk.md./_posts/test.md\n```\n-printf \n```bash\nfind . -type f -printf \" %Tc %p\\n\"\n Mon 27 Feb 2017 08:54:40 PM CST ./-name\n Mon 27 Feb 2017 12:31:29 AM CST ./_posts/hello-world.md\n Mon 27 Feb 2017 09:01:12 PM CST ./_posts/findandawk.md\n Sat 25 Feb 2017 01:56:06 AM CST ./_posts/test.md\n```\n man find printf\nfindfind \nfind ,\n```bash\n\nfind ./ -name \"*.md\"\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n\nfind ./ -type f -name \"*.md\"\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n\n\nfind ./ -mtime +1\n```\nfindexec\nrm-exec\n```bash\nls\n./ -mtime +1 -exec ls -l {} \\;\n-rw-rw-r--. 1 fangqing fangqing 5456 Feb 25 01:56 ./_posts/test.md\n\nfind ./ -name \"*.log\"  -exec rm -f {} \\;\n```\nfindfind\n# awk\nawkawkawk\nawklinuxawk\n\nawk\n```bash\nawk\n    ARGC        \n    ARGIND      ARGV\n    ARGV        \n    FILENAME    \n    FS          \n    NF          .\n    NR          .\n    OFMT        , \"%.6g\".\n    OFS         .\n    ORS         .\n    RS          .\n```\nawk\n```bash\n./ -print -name \"*\" -exec ls -l {} \\; |awk '{print $NF}'\n./\n-name\n_posts\n./-name\n./-name\n./_posts\nfindandawk.md\nhello-world.md\ntest.md\n./_posts/hello-world.md\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/findandawk.md\n./_posts/test.md\n./_posts/test.md\n````\n-F $NF.\n\n## grep\nLinuxgrep grepGlobal Regular Expression Print\n1. \ngrep [options]\n\n1. \n```\n[options]\nc\nI()\nh\nl\nn\ns\nv\npattern\n\\ \n^\n$: \n\\<\n\\>\n[ ][A]A \n[ - ][A-Z]ABCZ \n.\n* 0\n```\n1. grep\n$ grep ERROR d*\ndERROR\n$ grep ERROR a.log b.log c.log\na.log b.log c.log ERROR\n$ grep [a-z]\\{5\\} a.log\n5\n$ grep w\\(es\\)t.*\\1 a.log\nwestes1(.*) es(\\1)egrepgrep -E\\w(es)t.*\\1\n\n1. grep\n/usr/local/spark/ spark\n$ grep spark /usr/local/spark/*\ngrepgrep\ngrep: spark: Is a directory\n-rgrep -r\ngrep -d skip\n\n1. grep\ngrep -i pattern files \ngrep -l pattern files \ngrep -L pattern files \ngrep -w pattern files (foodfoo)\ngrep -C number pattern files [number]\n grep -C 3 \"hexo\" source/_posts/* hexohexo\ngrep pattern1 | pattern2 files  pattern1  pattern2 \ngrep pattern1 files | grep pattern2  pattern1  pattern2 \ngrep -n pattern files  \ngrep -c pattern files  \n\n1. grep \n\\<  \\> \n\ngrep good *  gooddddggoodgood\ngrep \\<good * gooddddgoodggood\ngrep \\<good\\> good\n^\n$ \n11. grep\n\n[[:upper:]]   [A-Z]\n[[:lower:]]   [a-z]\n[[:digit:]]   [0-9]\n[[:alnum:]]   [0-9a-zA-Z]\n[[:space:]]   tab\n[[:alpha:]]   [a-zA-Z]\ngrep '#[[:upper:]][[:upper:]]' data.doc     ##\ngrep linux\n","source":"_posts/findandawk.md","raw":"---\ntitle: find awk  grep \ndate: 2017-02-23 23:57:54\ntags: linux\n---\nfind awk  grep \nlinuxfindawkgrep\nlinux\n\n<!--more-->\n## find\nfind\n``` bash\nfind\n.\n./_posts\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n```\n\n1. \n1. \n1. -print\nfindfind\n\n``` bash\nfind  ./ -print -name \"*\"\n./\n./-name\n./_posts\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n```\n-print0\n``` bash\nfind  ./ -print0 -name \"*\"\n././-name./_posts./_posts/hello-world.md./_posts/findandawk.md./_posts/test.md\n```\n-printf \n```bash\nfind . -type f -printf \" %Tc %p\\n\"\n Mon 27 Feb 2017 08:54:40 PM CST ./-name\n Mon 27 Feb 2017 12:31:29 AM CST ./_posts/hello-world.md\n Mon 27 Feb 2017 09:01:12 PM CST ./_posts/findandawk.md\n Sat 25 Feb 2017 01:56:06 AM CST ./_posts/test.md\n```\n man find printf\nfindfind \nfind ,\n```bash\n\nfind ./ -name \"*.md\"\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n\nfind ./ -type f -name \"*.md\"\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/test.md\n\n\nfind ./ -mtime +1\n```\nfindexec\nrm-exec\n```bash\nls\n./ -mtime +1 -exec ls -l {} \\;\n-rw-rw-r--. 1 fangqing fangqing 5456 Feb 25 01:56 ./_posts/test.md\n\nfind ./ -name \"*.log\"  -exec rm -f {} \\;\n```\nfindfind\n# awk\nawkawkawk\nawklinuxawk\n\nawk\n```bash\nawk\n    ARGC        \n    ARGIND      ARGV\n    ARGV        \n    FILENAME    \n    FS          \n    NF          .\n    NR          .\n    OFMT        , \"%.6g\".\n    OFS         .\n    ORS         .\n    RS          .\n```\nawk\n```bash\n./ -print -name \"*\" -exec ls -l {} \\; |awk '{print $NF}'\n./\n-name\n_posts\n./-name\n./-name\n./_posts\nfindandawk.md\nhello-world.md\ntest.md\n./_posts/hello-world.md\n./_posts/hello-world.md\n./_posts/findandawk.md\n./_posts/findandawk.md\n./_posts/test.md\n./_posts/test.md\n````\n-F $NF.\n\n## grep\nLinuxgrep grepGlobal Regular Expression Print\n1. \ngrep [options]\n\n1. \n```\n[options]\nc\nI()\nh\nl\nn\ns\nv\npattern\n\\ \n^\n$: \n\\<\n\\>\n[ ][A]A \n[ - ][A-Z]ABCZ \n.\n* 0\n```\n1. grep\n$ grep ERROR d*\ndERROR\n$ grep ERROR a.log b.log c.log\na.log b.log c.log ERROR\n$ grep [a-z]\\{5\\} a.log\n5\n$ grep w\\(es\\)t.*\\1 a.log\nwestes1(.*) es(\\1)egrepgrep -E\\w(es)t.*\\1\n\n1. grep\n/usr/local/spark/ spark\n$ grep spark /usr/local/spark/*\ngrepgrep\ngrep: spark: Is a directory\n-rgrep -r\ngrep -d skip\n\n1. grep\ngrep -i pattern files \ngrep -l pattern files \ngrep -L pattern files \ngrep -w pattern files (foodfoo)\ngrep -C number pattern files [number]\n grep -C 3 \"hexo\" source/_posts/* hexohexo\ngrep pattern1 | pattern2 files  pattern1  pattern2 \ngrep pattern1 files | grep pattern2  pattern1  pattern2 \ngrep -n pattern files  \ngrep -c pattern files  \n\n1. grep \n\\<  \\> \n\ngrep good *  gooddddggoodgood\ngrep \\<good * gooddddgoodggood\ngrep \\<good\\> good\n^\n$ \n11. grep\n\n[[:upper:]]   [A-Z]\n[[:lower:]]   [a-z]\n[[:digit:]]   [0-9]\n[[:alnum:]]   [0-9a-zA-Z]\n[[:space:]]   tab\n[[:alpha:]]   [a-zA-Z]\ngrep '#[[:upper:]][[:upper:]]' data.doc     ##\ngrep linux\n","slug":"findandawk","published":1,"updated":"2017-02-28T14:48:27.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0pk000c60tucebvddu5","content":"<p>find awk  grep <br>linuxfindawkgrep<br>linux<br><br><a id=\"more\"></a></p>\n<h2 id=\"find\"><a href=\"#find\" class=\"headerlink\" title=\"find\"></a>find</h2><p>find<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">find</div><div class=\"line\">.</div><div class=\"line\">./_posts</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div></pre></td></tr></table></figure></p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li>-print<br>findfind</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">find  ./ -print -name <span class=\"string\">\"*\"</span></div><div class=\"line\">./</div><div class=\"line\">./-name</div><div class=\"line\">./_posts</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div></pre></td></tr></table></figure>\n<p>-print0<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">find  ./ -print0 -name <span class=\"string\">\"*\"</span></div><div class=\"line\">././-name./_posts./_posts/hello-world.md./_posts/findandawk.md./_posts/test.md</div></pre></td></tr></table></figure></p>\n<p>-printf <br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -type f -printf <span class=\"string\">\" %Tc %p\\n\"</span></div><div class=\"line\"> Mon 27 Feb 2017 08:54:40 PM CST ./-name</div><div class=\"line\"> Mon 27 Feb 2017 12:31:29 AM CST ./_posts/hello-world.md</div><div class=\"line\"> Mon 27 Feb 2017 09:01:12 PM CST ./_posts/findandawk.md</div><div class=\"line\"> Sat 25 Feb 2017 01:56:06 AM CST ./_posts/test.md</div></pre></td></tr></table></figure></p>\n<p> man find printf<br>findfind <br>find ,<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">find ./ -name <span class=\"string\">\"*.md\"</span></div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\"></div><div class=\"line\">find ./ -type f -name <span class=\"string\">\"*.md\"</span></div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">find ./ -mtime +1</div></pre></td></tr></table></figure></p>\n<p>findexec<br>rm-exec<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">ls</div><div class=\"line\">./ -mtime +1 -exec ls <span class=\"_\">-l</span> &#123;&#125; \\;</div><div class=\"line\">-rw-rw-r--. 1 fangqing fangqing 5456 Feb 25 01:56 ./_posts/test.md</div><div class=\"line\"></div><div class=\"line\">find ./ -name <span class=\"string\">\"*.log\"</span>  -exec rm <span class=\"_\">-f</span> &#123;&#125; \\;</div></pre></td></tr></table></figure></p>\n<p>findfind</p>\n<h1 id=\"awk\"><a href=\"#awk\" class=\"headerlink\" title=\"awk\"></a>awk</h1><p>awkawkawk<br>awklinuxawk<br><br>awk<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">awk</div><div class=\"line\">    ARGC        </div><div class=\"line\">    ARGIND      ARGV</div><div class=\"line\">    ARGV        </div><div class=\"line\">    FILENAME    </div><div class=\"line\">    FS          </div><div class=\"line\">    NF          .</div><div class=\"line\">    NR          .</div><div class=\"line\">    OFMT        , <span class=\"string\">\"%.6g\"</span>.</div><div class=\"line\">    OFS         .</div><div class=\"line\">    ORS         .</div><div class=\"line\">    RS          .</div></pre></td></tr></table></figure></p>\n<p>awk<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">./ -print -name <span class=\"string\">\"*\"</span> -exec ls <span class=\"_\">-l</span> &#123;&#125; \\; |awk <span class=\"string\">'&#123;print $NF&#125;'</span></div><div class=\"line\">./</div><div class=\"line\">-name</div><div class=\"line\">_posts</div><div class=\"line\">./-name</div><div class=\"line\">./-name</div><div class=\"line\">./_posts</div><div class=\"line\">findandawk.md</div><div class=\"line\">hello-world.md</div><div class=\"line\">test.md</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\">`</div></pre></td></tr></table></figure></p>\n<p>-F $NF.</p>\n<h2 id=\"grep\"><a href=\"#grep\" class=\"headerlink\" title=\"grep\"></a>grep</h2><p>Linuxgrep grepGlobal Regular Expression Print</p>\n<ol>\n<li><p><br>grep [options]</p>\n</li>\n<li><p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">[options]</div><div class=\"line\">c</div><div class=\"line\">I()</div><div class=\"line\">h</div><div class=\"line\">l</div><div class=\"line\">n</div><div class=\"line\">s</div><div class=\"line\">v</div><div class=\"line\">pattern</div><div class=\"line\">\\ </div><div class=\"line\">^</div><div class=\"line\">$: </div><div class=\"line\">\\&lt;</div><div class=\"line\">\\&gt;</div><div class=\"line\">[ ][A]A </div><div class=\"line\">[ - ][A-Z]ABCZ </div><div class=\"line\">.</div><div class=\"line\">* 0</div></pre></td></tr></table></figure>\n</li>\n<li><p>grep<br>$ grep ERROR d<em><br>dERROR<br>$ grep ERROR a.log b.log c.log<br>a.log b.log c.log ERROR<br>$ grep [a-z]{5} a.log<br>5<br>$ grep w(es)t.</em>\\1 a.log<br>westes1(.<em>) es(\\1)egrepgrep -E\\w(es)t.</em>\\1</p>\n</li>\n<li><p>grep<br>/usr/local/spark/ spark<br>$ grep spark /usr/local/spark/*<br>grepgrep<br>grep: spark: Is a directory<br>-rgrep -r<br>grep -d skip</p>\n</li>\n<li><p>grep<br>grep -i pattern files <br>grep -l pattern files <br>grep -L pattern files <br>grep -w pattern files (foodfoo)<br>grep -C number pattern files [number]<br> grep -C 3 hexo source/_posts/* hexohexo<br>grep pattern1 | pattern2 files  pattern1  pattern2 <br>grep pattern1 files | grep pattern2  pattern1  pattern2 <br>grep -n pattern files  <br>grep -c pattern files  </p>\n</li>\n<li><p>grep <br>\\&lt;  > <br><br>grep good <em>  gooddddggoodgood<br>grep \\&lt;good </em> gooddddgoodggood<br>grep \\<good\\> good<br>^<br>$ </good\\></p>\n</li>\n<li>grep<br><br>[[:upper:]]   [A-Z]<br>[[:lower:]]   [a-z]<br>[[:digit:]]   [0-9]<br>[[:alnum:]]   [0-9a-zA-Z]<br>[[:space:]]   tab<br>[[:alpha:]]   [a-zA-Z]<br>grep #[[:upper:]][[:upper:]] data.doc     ##<br>grep linux</li>\n</ol>\n","excerpt":"<p>find awk  grep <br>linuxfindawkgrep<br>linux<br><br>","more":"</p>\n<h2 id=\"find\"><a href=\"#find\" class=\"headerlink\" title=\"find\"></a>find</h2><p>find<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">find</div><div class=\"line\">.</div><div class=\"line\">./_posts</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div></pre></td></tr></table></figure></p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li>-print<br>findfind</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">find  ./ -print -name <span class=\"string\">\"*\"</span></div><div class=\"line\">./</div><div class=\"line\">./-name</div><div class=\"line\">./_posts</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div></pre></td></tr></table></figure>\n<p>-print0<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">find  ./ -print0 -name <span class=\"string\">\"*\"</span></div><div class=\"line\">././-name./_posts./_posts/hello-world.md./_posts/findandawk.md./_posts/test.md</div></pre></td></tr></table></figure></p>\n<p>-printf <br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -type f -printf <span class=\"string\">\" %Tc %p\\n\"</span></div><div class=\"line\"> Mon 27 Feb 2017 08:54:40 PM CST ./-name</div><div class=\"line\"> Mon 27 Feb 2017 12:31:29 AM CST ./_posts/hello-world.md</div><div class=\"line\"> Mon 27 Feb 2017 09:01:12 PM CST ./_posts/findandawk.md</div><div class=\"line\"> Sat 25 Feb 2017 01:56:06 AM CST ./_posts/test.md</div></pre></td></tr></table></figure></p>\n<p> man find printf<br>findfind <br>find ,<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">find ./ -name <span class=\"string\">\"*.md\"</span></div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\"></div><div class=\"line\">find ./ -type f -name <span class=\"string\">\"*.md\"</span></div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">find ./ -mtime +1</div></pre></td></tr></table></figure></p>\n<p>findexec<br>rm-exec<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">ls</div><div class=\"line\">./ -mtime +1 -exec ls <span class=\"_\">-l</span> &#123;&#125; \\;</div><div class=\"line\">-rw-rw-r--. 1 fangqing fangqing 5456 Feb 25 01:56 ./_posts/test.md</div><div class=\"line\"></div><div class=\"line\">find ./ -name <span class=\"string\">\"*.log\"</span>  -exec rm <span class=\"_\">-f</span> &#123;&#125; \\;</div></pre></td></tr></table></figure></p>\n<p>findfind</p>\n<h1 id=\"awk\"><a href=\"#awk\" class=\"headerlink\" title=\"awk\"></a>awk</h1><p>awkawkawk<br>awklinuxawk<br><br>awk<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">awk</div><div class=\"line\">    ARGC        </div><div class=\"line\">    ARGIND      ARGV</div><div class=\"line\">    ARGV        </div><div class=\"line\">    FILENAME    </div><div class=\"line\">    FS          </div><div class=\"line\">    NF          .</div><div class=\"line\">    NR          .</div><div class=\"line\">    OFMT        , <span class=\"string\">\"%.6g\"</span>.</div><div class=\"line\">    OFS         .</div><div class=\"line\">    ORS         .</div><div class=\"line\">    RS          .</div></pre></td></tr></table></figure></p>\n<p>awk<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">./ -print -name <span class=\"string\">\"*\"</span> -exec ls <span class=\"_\">-l</span> &#123;&#125; \\; |awk <span class=\"string\">'&#123;print $NF&#125;'</span></div><div class=\"line\">./</div><div class=\"line\">-name</div><div class=\"line\">_posts</div><div class=\"line\">./-name</div><div class=\"line\">./-name</div><div class=\"line\">./_posts</div><div class=\"line\">findandawk.md</div><div class=\"line\">hello-world.md</div><div class=\"line\">test.md</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/hello-world.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/findandawk.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\">./_posts/test.md</div><div class=\"line\">`</div></pre></td></tr></table></figure></p>\n<p>-F $NF.</p>\n<h2 id=\"grep\"><a href=\"#grep\" class=\"headerlink\" title=\"grep\"></a>grep</h2><p>Linuxgrep grepGlobal Regular Expression Print</p>\n<ol>\n<li><p><br>grep [options]</p>\n</li>\n<li><p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">[options]</div><div class=\"line\">c</div><div class=\"line\">I()</div><div class=\"line\">h</div><div class=\"line\">l</div><div class=\"line\">n</div><div class=\"line\">s</div><div class=\"line\">v</div><div class=\"line\">pattern</div><div class=\"line\">\\ </div><div class=\"line\">^</div><div class=\"line\">$: </div><div class=\"line\">\\&lt;</div><div class=\"line\">\\&gt;</div><div class=\"line\">[ ][A]A </div><div class=\"line\">[ - ][A-Z]ABCZ </div><div class=\"line\">.</div><div class=\"line\">* 0</div></pre></td></tr></table></figure>\n</li>\n<li><p>grep<br>$ grep ERROR d<em><br>dERROR<br>$ grep ERROR a.log b.log c.log<br>a.log b.log c.log ERROR<br>$ grep [a-z]{5} a.log<br>5<br>$ grep w(es)t.</em>\\1 a.log<br>westes1(.<em>) es(\\1)egrepgrep -E\\w(es)t.</em>\\1</p>\n</li>\n<li><p>grep<br>/usr/local/spark/ spark<br>$ grep spark /usr/local/spark/*<br>grepgrep<br>grep: spark: Is a directory<br>-rgrep -r<br>grep -d skip</p>\n</li>\n<li><p>grep<br>grep -i pattern files <br>grep -l pattern files <br>grep -L pattern files <br>grep -w pattern files (foodfoo)<br>grep -C number pattern files [number]<br> grep -C 3 hexo source/_posts/* hexohexo<br>grep pattern1 | pattern2 files  pattern1  pattern2 <br>grep pattern1 files | grep pattern2  pattern1  pattern2 <br>grep -n pattern files  <br>grep -c pattern files  </p>\n</li>\n<li><p>grep <br>\\&lt;  > <br><br>grep good <em>  gooddddggoodgood<br>grep \\&lt;good </em> gooddddgoodggood<br>grep \\<good\\> good<br>^<br>$ </p>\n</li>\n<li>grep<br><br>[[:upper:]]   [A-Z]<br>[[:lower:]]   [a-z]<br>[[:digit:]]   [0-9]<br>[[:alnum:]]   [0-9a-zA-Z]<br>[[:space:]]   tab<br>[[:alpha:]]   [a-zA-Z]<br>grep #[[:upper:]][[:upper:]] data.doc     ##<br>grep linux</li>\n</ol>"},{"title":"group by rollup  cube","date":"2017-03-12T15:53:14.000Z","_content":"\n\nsparksqldataframe,tmp\n```\ncolume1colume2value\nA    X            2\nA    X            1\nA  Y            2\nA  Y            1\nB  X            3\nB  Y            2\nB  Y            2\n```\n<!-- more -->\n## group by\ngroup by SUM()\n```\nSELECT colume1,colume2,SUM(value) \n  FROM tmp\n  GROUP BY colume1,colume2\n```\ncolume1colume2 \n```\ncolume1colume2sum(value)\n\n  A X 3\n  B X 3\n  A Y 3\n  B Y 4\n```\nCubeRollupGroup By\n\n##  Rollup\n rollup Group Bycolume1AB\n```\n  SELECT colume1,colume2,SUM(value)\n  FROM tmp\n  GROUP BY colume1,colume2\n      WITH ROLLUP\n```\ncolume1colme2,colume1\n```\ncolume1colume2sum(value)\n\n  A X 3\n  A Y 3\n  A NULL 6\n  B X 3\n  B Y 4\n  B NULL 7\n  NULL NULL 13\n```\n\n\n\n## Cube\n\nCubeRollupCubecolume1colume2\n```\n  SELECT colume1,colume2,SUM(value)\n  FROM tmp\n  GROUP BY colume1,colume2\n      WITH CUBE\n```\n\n\n```\ncolume1colume2sum(value)\n  A X 3\n  B X 3\n  NULL X 6\n  A Y 3\n  B Y 4\n  NULL Y 7\n  NULL NULL 13\n  A NULL 6\n  B NULL 7\n```\n12colume2XY\n","source":"_posts/groupbyandrollup.md","raw":"---\ntitle: group by rollup  cube\ndate: 2017-03-12 23:53:14\ntags: \n  - spark\n  - sql\ncategory: spark\n---\n\n\nsparksqldataframe,tmp\n```\ncolume1colume2value\nA    X            2\nA    X            1\nA  Y            2\nA  Y            1\nB  X            3\nB  Y            2\nB  Y            2\n```\n<!-- more -->\n## group by\ngroup by SUM()\n```\nSELECT colume1,colume2,SUM(value) \n  FROM tmp\n  GROUP BY colume1,colume2\n```\ncolume1colume2 \n```\ncolume1colume2sum(value)\n\n  A X 3\n  B X 3\n  A Y 3\n  B Y 4\n```\nCubeRollupGroup By\n\n##  Rollup\n rollup Group Bycolume1AB\n```\n  SELECT colume1,colume2,SUM(value)\n  FROM tmp\n  GROUP BY colume1,colume2\n      WITH ROLLUP\n```\ncolume1colme2,colume1\n```\ncolume1colume2sum(value)\n\n  A X 3\n  A Y 3\n  A NULL 6\n  B X 3\n  B Y 4\n  B NULL 7\n  NULL NULL 13\n```\n\n\n\n## Cube\n\nCubeRollupCubecolume1colume2\n```\n  SELECT colume1,colume2,SUM(value)\n  FROM tmp\n  GROUP BY colume1,colume2\n      WITH CUBE\n```\n\n\n```\ncolume1colume2sum(value)\n  A X 3\n  B X 3\n  NULL X 6\n  A Y 3\n  B Y 4\n  NULL Y 7\n  NULL NULL 13\n  A NULL 6\n  B NULL 7\n```\n12colume2XY\n","slug":"groupbyandrollup","published":1,"updated":"2017-03-13T14:06:58.237Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0pn000e60tu14g5drzk","content":"<p>sparksqldataframe,tmp<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2value</div><div class=\"line\">A    X            2</div><div class=\"line\">A    X            1</div><div class=\"line\">A  Y            2</div><div class=\"line\">A  Y            1</div><div class=\"line\">B  X            3</div><div class=\"line\">B  Y            2</div><div class=\"line\">B  Y            2</div></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<h2 id=\"group-by\"><a href=\"#group-by\" class=\"headerlink\" title=\"group by\"></a>group by</h2><p>group by SUM()<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT colume1,colume2,SUM(value) </div><div class=\"line\">  FROM tmp</div><div class=\"line\">  GROUP BY colume1,colume2</div></pre></td></tr></table></figure></p>\n<p>colume1colume2 <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2sum(value)</div><div class=\"line\"></div><div class=\"line\">  A X 3</div><div class=\"line\">  B X 3</div><div class=\"line\">  A Y 3</div><div class=\"line\">  B Y 4</div></pre></td></tr></table></figure></p>\n<p>CubeRollupGroup By</p>\n<h2 id=\"Rollup\"><a href=\"#Rollup\" class=\"headerlink\" title=\"Rollup\"></a>Rollup</h2><p> rollup Group Bycolume1AB<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT colume1,colume2,SUM(value)</div><div class=\"line\">FROM tmp</div><div class=\"line\">GROUP BY colume1,colume2</div><div class=\"line\">    WITH ROLLUP</div></pre></td></tr></table></figure></p>\n<p>colume1colme2,colume1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2sum(value)</div><div class=\"line\"></div><div class=\"line\">  A X 3</div><div class=\"line\">  A Y 3</div><div class=\"line\">  A NULL 6</div><div class=\"line\">  B X 3</div><div class=\"line\">  B Y 4</div><div class=\"line\">  B NULL 7</div><div class=\"line\">  NULL NULL 13</div></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"Cube\"><a href=\"#Cube\" class=\"headerlink\" title=\"Cube\"></a>Cube</h2><p>CubeRollupCubecolume1colume2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT colume1,colume2,SUM(value)</div><div class=\"line\">FROM tmp</div><div class=\"line\">GROUP BY colume1,colume2</div><div class=\"line\">    WITH CUBE</div></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2sum(value)</div><div class=\"line\">  A X 3</div><div class=\"line\">  B X 3</div><div class=\"line\">  NULL X 6</div><div class=\"line\">  A Y 3</div><div class=\"line\">  B Y 4</div><div class=\"line\">  NULL Y 7</div><div class=\"line\">  NULL NULL 13</div><div class=\"line\">  A NULL 6</div><div class=\"line\">  B NULL 7</div></pre></td></tr></table></figure>\n<p>12colume2XY</p>\n","excerpt":"<p>sparksqldataframe,tmp<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2value</div><div class=\"line\">A    X            2</div><div class=\"line\">A    X            1</div><div class=\"line\">A  Y            2</div><div class=\"line\">A  Y            1</div><div class=\"line\">B  X            3</div><div class=\"line\">B  Y            2</div><div class=\"line\">B  Y            2</div></pre></td></tr></table></figure></p>","more":"<h2 id=\"group-by\"><a href=\"#group-by\" class=\"headerlink\" title=\"group by\"></a>group by</h2><p>group by SUM()<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT colume1,colume2,SUM(value) </div><div class=\"line\">  FROM tmp</div><div class=\"line\">  GROUP BY colume1,colume2</div></pre></td></tr></table></figure></p>\n<p>colume1colume2 <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2sum(value)</div><div class=\"line\"></div><div class=\"line\">  A X 3</div><div class=\"line\">  B X 3</div><div class=\"line\">  A Y 3</div><div class=\"line\">  B Y 4</div></pre></td></tr></table></figure></p>\n<p>CubeRollupGroup By</p>\n<h2 id=\"Rollup\"><a href=\"#Rollup\" class=\"headerlink\" title=\"Rollup\"></a>Rollup</h2><p> rollup Group Bycolume1AB<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT colume1,colume2,SUM(value)</div><div class=\"line\">FROM tmp</div><div class=\"line\">GROUP BY colume1,colume2</div><div class=\"line\">    WITH ROLLUP</div></pre></td></tr></table></figure></p>\n<p>colume1colme2,colume1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2sum(value)</div><div class=\"line\"></div><div class=\"line\">  A X 3</div><div class=\"line\">  A Y 3</div><div class=\"line\">  A NULL 6</div><div class=\"line\">  B X 3</div><div class=\"line\">  B Y 4</div><div class=\"line\">  B NULL 7</div><div class=\"line\">  NULL NULL 13</div></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"Cube\"><a href=\"#Cube\" class=\"headerlink\" title=\"Cube\"></a>Cube</h2><p>CubeRollupCubecolume1colume2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT colume1,colume2,SUM(value)</div><div class=\"line\">FROM tmp</div><div class=\"line\">GROUP BY colume1,colume2</div><div class=\"line\">    WITH CUBE</div></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">colume1colume2sum(value)</div><div class=\"line\">  A X 3</div><div class=\"line\">  B X 3</div><div class=\"line\">  NULL X 6</div><div class=\"line\">  A Y 3</div><div class=\"line\">  B Y 4</div><div class=\"line\">  NULL Y 7</div><div class=\"line\">  NULL NULL 13</div><div class=\"line\">  A NULL 6</div><div class=\"line\">  B NULL 7</div></pre></td></tr></table></figure>\n<p>12colume2XY</p>"},{"title":"hexo","date":"2017-02-21T15:57:54.000Z","_content":"hexohexo,\n## \n<!--more-->\n###  \n\n``` bash\n$ hexo new \"My New Post\"\n```\n\n: [Writing](https://hexo.io/docs/writing.html)\n\n### server\n\n``` bash\n$ hexo server\n```\n\n: [Server](https://hexo.io/docs/server.html)\n\n### \n\n``` bash\n$ hexo generate\n```\n\n: [Generating](https://hexo.io/docs/generating.html)\n\n### \n\n``` bash\n$ hexo deploy\n```\n\n: [Deployment](https://hexo.io/docs/deployment.html)\nhexo: [hexo](https://hexo.io/docs)\n\n## next\n```\n$ cd your-hexo-site\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\nNextGihub\n\n/root/_config.ymltheme\n```\n# Extensions\n## Plugins: http://hexo.io/plugins/\n## Themes: http://hexo.io/themes/\ntheme: next\n```\n\n```\n$ hexo s --debug\n```\nENOSPC Error (Linux)\n```\n  Sometimes when running the command $ hexo server it returns an error:\n\n  Error: watch ENOSPC ...\n\n  It can be fixed by running $ npm dedupe or, if that doesnt help, try the following in the Linux console:\n\n  $ echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p\n```\n  This will increase the limit for the number of files you can watch.\n","source":"_posts/hello-world.md","raw":"---\ntitle: hexo\ndate: 2017-02-21 23:57:54\ntag: hexo\n---\nhexohexo,\n## \n<!--more-->\n###  \n\n``` bash\n$ hexo new \"My New Post\"\n```\n\n: [Writing](https://hexo.io/docs/writing.html)\n\n### server\n\n``` bash\n$ hexo server\n```\n\n: [Server](https://hexo.io/docs/server.html)\n\n### \n\n``` bash\n$ hexo generate\n```\n\n: [Generating](https://hexo.io/docs/generating.html)\n\n### \n\n``` bash\n$ hexo deploy\n```\n\n: [Deployment](https://hexo.io/docs/deployment.html)\nhexo: [hexo](https://hexo.io/docs)\n\n## next\n```\n$ cd your-hexo-site\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\nNextGihub\n\n/root/_config.ymltheme\n```\n# Extensions\n## Plugins: http://hexo.io/plugins/\n## Themes: http://hexo.io/themes/\ntheme: next\n```\n\n```\n$ hexo s --debug\n```\nENOSPC Error (Linux)\n```\n  Sometimes when running the command $ hexo server it returns an error:\n\n  Error: watch ENOSPC ...\n\n  It can be fixed by running $ npm dedupe or, if that doesnt help, try the following in the Linux console:\n\n  $ echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p\n```\n  This will increase the limit for the number of files you can watch.\n","slug":"hello-world","published":1,"updated":"2017-03-08T23:50:35.715Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0ps000g60tupfaojebl","content":"<p>hexohexo,</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><a id=\"more\"></a>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"server\"><a href=\"#server\" class=\"headerlink\" title=\"server\"></a>server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a><br>hexo: <a href=\"https://hexo.io/docs\" target=\"_blank\" rel=\"external\">hexo</a></p>\n<h2 id=\"next\"><a href=\"#next\" class=\"headerlink\" title=\"next\"></a>next</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd your-hexo-site</div><div class=\"line\">$ git clone https://github.com/iissnan/hexo-theme-next themes/next</div></pre></td></tr></table></figure>\n<p>NextGihub<br><br>/root/_config.ymltheme<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Extensions</div><div class=\"line\">## Plugins: http://hexo.io/plugins/</div><div class=\"line\">## Themes: http://hexo.io/themes/</div><div class=\"line\">theme: next</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo s --debug</div></pre></td></tr></table></figure></p>\n<p>ENOSPC Error (Linux)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">Sometimes when running the command $ hexo server it returns an error:</div><div class=\"line\"></div><div class=\"line\">Error: watch ENOSPC ...</div><div class=\"line\"></div><div class=\"line\">It can be fixed by running $ npm dedupe or, if that doesnt help, try the following in the Linux console:</div><div class=\"line\"></div><div class=\"line\">$ echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;&amp; sudo sysctl -p</div></pre></td></tr></table></figure></p>\n<p>  This will increase the limit for the number of files you can watch.</p>\n","excerpt":"<p>hexohexo,</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>","more":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"server\"><a href=\"#server\" class=\"headerlink\" title=\"server\"></a>server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>: <a href=\"https://hexo.io/docs/deployment.html\">Deployment</a><br>hexo: <a href=\"https://hexo.io/docs\">hexo</a></p>\n<h2 id=\"next\"><a href=\"#next\" class=\"headerlink\" title=\"next\"></a>next</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd your-hexo-site</div><div class=\"line\">$ git clone https://github.com/iissnan/hexo-theme-next themes/next</div></pre></td></tr></table></figure>\n<p>NextGihub<br><br>/root/_config.ymltheme<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Extensions</div><div class=\"line\">## Plugins: http://hexo.io/plugins/</div><div class=\"line\">## Themes: http://hexo.io/themes/</div><div class=\"line\">theme: next</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo s --debug</div></pre></td></tr></table></figure></p>\n<p>ENOSPC Error (Linux)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">Sometimes when running the command $ hexo server it returns an error:</div><div class=\"line\"></div><div class=\"line\">Error: watch ENOSPC ...</div><div class=\"line\"></div><div class=\"line\">It can be fixed by running $ npm dedupe or, if that doesnt help, try the following in the Linux console:</div><div class=\"line\"></div><div class=\"line\">$ echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;&amp; sudo sysctl -p</div></pre></td></tr></table></figure></p>\n<p>  This will increase the limit for the number of files you can watch.</p>"},{"title":"sparkshufferpattition","date":"2017-02-28T15:57:54.000Z","_content":"1. spark 2.0.1 csv\n```\nval option=Map(\"header\"->\"true\",\"seq\"->\":\")\nval tmpdf=spark.sqlContext.read.option(op).format(csv).load(\"/test.csv\");\ntmpdf.OrderBy(\"age\").write.csv(\"/testrs.csv\");\n```\nspark-shellspark\n/testrs.csv200sparksqlspark.sql.shuffle.partitions200sparkspark-default20\n","source":"_posts/hello.md","raw":"---\ntitle: sparkshufferpattition\ndate: 2017-02-28 23:57:54\ntags: spark\n---\n1. spark 2.0.1 csv\n```\nval option=Map(\"header\"->\"true\",\"seq\"->\":\")\nval tmpdf=spark.sqlContext.read.option(op).format(csv).load(\"/test.csv\");\ntmpdf.OrderBy(\"age\").write.csv(\"/testrs.csv\");\n```\nspark-shellspark\n/testrs.csv200sparksqlspark.sql.shuffle.partitions200sparkspark-default20\n","slug":"hello","published":1,"updated":"2017-02-28T15:00:32.231Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0py000j60tupzkv0omm","content":"<ol>\n<li>spark 2.0.1 csv<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">val option=Map(&quot;header&quot;-&gt;&quot;true&quot;,&quot;seq&quot;-&gt;&quot;:&quot;)</div><div class=\"line\">val tmpdf=spark.sqlContext.read.option(op).format(csv).load(&quot;/test.csv&quot;);</div><div class=\"line\">tmpdf.OrderBy(&quot;age&quot;).write.csv(&quot;/testrs.csv&quot;);</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>spark-shellspark<br>/testrs.csv200sparksqlspark.sql.shuffle.partitions200sparkspark-default20</p>\n","excerpt":"","more":"<ol>\n<li>spark 2.0.1 csv<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">val option=Map(&quot;header&quot;-&gt;&quot;true&quot;,&quot;seq&quot;-&gt;&quot;:&quot;)</div><div class=\"line\">val tmpdf=spark.sqlContext.read.option(op).format(csv).load(&quot;/test.csv&quot;);</div><div class=\"line\">tmpdf.OrderBy(&quot;age&quot;).write.csv(&quot;/testrs.csv&quot;);</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>spark-shellspark<br>/testrs.csv200sparksqlspark.sql.shuffle.partitions200sparkspark-default20</p>\n"},{"title":"java ","date":"2017-03-08T12:57:54.000Z","_content":"\n\n\njava\n```bash\n1 3 6 10 15 21\n2 5 9 14 20\n4 8 13 19\n7 12 18\n11 17\n16\n```\n<!-- more -->\n\n```java\nint xx[][] = new int[6][6];\nint num = 1;\n\n     for (int i = 0; i <= 5; i++) {\n\n         for (int j = 0; j <= 5; j++) {\n\n             xx[i][j] = -1;\n\n         }\n\n     }\n     for (int i = 0; i <= 5; i++) {\n         int m = i;\n         for (int j = 0; j <= i; j++) {\n             xx[j][m--] = num;\n             num++;\n         }\n         System.out.println();\n     }\n     for (int i = 0; i <= 5; i++) {\n         for (int j = 0; j <= 5; j++) {\n             if (xx[i][j] != -1)\n                 System.out.print(xx[j][i] + \" \");\n         }\n         System.out.println();\n     }\n```\nxx arrayarray\n\n\n```java\npublic static void main(String[] args) {\n       ArrayList<Integer> arrlist = new ArrayList<Integer>(5);//ArrayList \n       for (int i = 0; i < 5; i++) {\n           arrlist.add(i);\n       }\n       arrlist.add(0);\n       Iterator<Integer> it;\n       arrprint(arrlist.iterator());\n       for (it = arrlist.iterator(); it.hasNext(); ) {\n           if (it.next() == 0) {\n               it.remove();//arrlist\n//                arrlist.remove((Integer)0); //Exception in thread \"main\" java.util.ConcurrentModificationException\n           }\n       }\n       System.out.println();\n       arrprint(arrlist.iterator());\n   }\n\n   private static void arrprint(Iterator<Integer> it) {\n       for (; it.hasNext(); ) {\n           System.out.print(it.next() + \" \");\n       }\n   }\n```\n\n\n```bash\n0 1 2 3 4 0\n1 2 3 4\n```\narraylist   JavaarrarylistJava\n\n\n1. JavaIterator\n11. iterator()IteratorIteratornext()iterator()java.lang.Iterable,Collection\n11. next()\n11. hasNext()\n11. remove()\n","source":"_posts/iterator.md","raw":"---\ntitle: java \ndate: 2017-03-08 20:57:54\ntags: java\n---\n\n\n\njava\n```bash\n1 3 6 10 15 21\n2 5 9 14 20\n4 8 13 19\n7 12 18\n11 17\n16\n```\n<!-- more -->\n\n```java\nint xx[][] = new int[6][6];\nint num = 1;\n\n     for (int i = 0; i <= 5; i++) {\n\n         for (int j = 0; j <= 5; j++) {\n\n             xx[i][j] = -1;\n\n         }\n\n     }\n     for (int i = 0; i <= 5; i++) {\n         int m = i;\n         for (int j = 0; j <= i; j++) {\n             xx[j][m--] = num;\n             num++;\n         }\n         System.out.println();\n     }\n     for (int i = 0; i <= 5; i++) {\n         for (int j = 0; j <= 5; j++) {\n             if (xx[i][j] != -1)\n                 System.out.print(xx[j][i] + \" \");\n         }\n         System.out.println();\n     }\n```\nxx arrayarray\n\n\n```java\npublic static void main(String[] args) {\n       ArrayList<Integer> arrlist = new ArrayList<Integer>(5);//ArrayList \n       for (int i = 0; i < 5; i++) {\n           arrlist.add(i);\n       }\n       arrlist.add(0);\n       Iterator<Integer> it;\n       arrprint(arrlist.iterator());\n       for (it = arrlist.iterator(); it.hasNext(); ) {\n           if (it.next() == 0) {\n               it.remove();//arrlist\n//                arrlist.remove((Integer)0); //Exception in thread \"main\" java.util.ConcurrentModificationException\n           }\n       }\n       System.out.println();\n       arrprint(arrlist.iterator());\n   }\n\n   private static void arrprint(Iterator<Integer> it) {\n       for (; it.hasNext(); ) {\n           System.out.print(it.next() + \" \");\n       }\n   }\n```\n\n\n```bash\n0 1 2 3 4 0\n1 2 3 4\n```\narraylist   JavaarrarylistJava\n\n\n1. JavaIterator\n11. iterator()IteratorIteratornext()iterator()java.lang.Iterable,Collection\n11. next()\n11. hasNext()\n11. remove()\n","slug":"iterator","published":1,"updated":"2017-03-08T13:31:12.349Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0q2000l60tu3a1pfoam","content":"<p>java<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">1 3 6 10 15 21</div><div class=\"line\">2 5 9 14 20</div><div class=\"line\">4 8 13 19</div><div class=\"line\">7 12 18</div><div class=\"line\">11 17</div><div class=\"line\">16</div></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<p><br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> xx[][] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">6</span>][<span class=\"number\">6</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> num = <span class=\"number\">1</span>;</div><div class=\"line\"></div><div class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\"></div><div class=\"line\">         <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt;= <span class=\"number\">5</span>; j++) &#123;</div><div class=\"line\"></div><div class=\"line\">             xx[i][j] = -<span class=\"number\">1</span>;</div><div class=\"line\"></div><div class=\"line\">         &#125;</div><div class=\"line\"></div><div class=\"line\">     &#125;</div><div class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\">         <span class=\"keyword\">int</span> m = i;</div><div class=\"line\">         <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt;= i; j++) &#123;</div><div class=\"line\">             xx[j][m--] = num;</div><div class=\"line\">             num++;</div><div class=\"line\">         &#125;</div><div class=\"line\">         System.out.println();</div><div class=\"line\">     &#125;</div><div class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\">         <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt;= <span class=\"number\">5</span>; j++) &#123;</div><div class=\"line\">             <span class=\"keyword\">if</span> (xx[i][j] != -<span class=\"number\">1</span>)</div><div class=\"line\">                 System.out.print(xx[j][i] + <span class=\"string\">\" \"</span>);</div><div class=\"line\">         &#125;</div><div class=\"line\">         System.out.println();</div><div class=\"line\">     &#125;</div></pre></td></tr></table></figure></p>\n<p>xx arrayarray<br></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</div><div class=\"line\">       ArrayList&lt;Integer&gt; arrlist = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;(<span class=\"number\">5</span>);<span class=\"comment\">//ArrayList </span></div><div class=\"line\">       <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\">           arrlist.add(i);</div><div class=\"line\">       &#125;</div><div class=\"line\">       arrlist.add(<span class=\"number\">0</span>);</div><div class=\"line\">       Iterator&lt;Integer&gt; it;</div><div class=\"line\">       arrprint(arrlist.iterator());</div><div class=\"line\">       <span class=\"keyword\">for</span> (it = arrlist.iterator(); it.hasNext(); ) &#123;</div><div class=\"line\">           <span class=\"keyword\">if</span> (it.next() == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">               it.remove();<span class=\"comment\">//arrlist</span></div><div class=\"line\"><span class=\"comment\">//                arrlist.remove((Integer)0); //Exception in thread \"main\" java.util.ConcurrentModificationException</span></div><div class=\"line\">           &#125;</div><div class=\"line\">       &#125;</div><div class=\"line\">       System.out.println();</div><div class=\"line\">       arrprint(arrlist.iterator());</div><div class=\"line\">   &#125;</div><div class=\"line\"></div><div class=\"line\">   <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">arrprint</span><span class=\"params\">(Iterator&lt;Integer&gt; it)</span> </span>&#123;</div><div class=\"line\">       <span class=\"keyword\">for</span> (; it.hasNext(); ) &#123;</div><div class=\"line\">           System.out.print(it.next() + <span class=\"string\">\" \"</span>);</div><div class=\"line\">       &#125;</div><div class=\"line\">   &#125;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">0 1 2 3 4 0</div><div class=\"line\">1 2 3 4</div></pre></td></tr></table></figure>\n<p>arraylist   JavaarrarylistJava<br></p>\n<ol>\n<li>JavaIterator</li>\n<li>iterator()IteratorIteratornext()iterator()java.lang.Iterable,Collection</li>\n<li>next()</li>\n<li>hasNext()</li>\n<li>remove()</li>\n</ol>\n","excerpt":"<p>java<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">1 3 6 10 15 21</div><div class=\"line\">2 5 9 14 20</div><div class=\"line\">4 8 13 19</div><div class=\"line\">7 12 18</div><div class=\"line\">11 17</div><div class=\"line\">16</div></pre></td></tr></table></figure></p>","more":"<p><br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> xx[][] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">6</span>][<span class=\"number\">6</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> num = <span class=\"number\">1</span>;</div><div class=\"line\"></div><div class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\"></div><div class=\"line\">         <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt;= <span class=\"number\">5</span>; j++) &#123;</div><div class=\"line\"></div><div class=\"line\">             xx[i][j] = -<span class=\"number\">1</span>;</div><div class=\"line\"></div><div class=\"line\">         &#125;</div><div class=\"line\"></div><div class=\"line\">     &#125;</div><div class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\">         <span class=\"keyword\">int</span> m = i;</div><div class=\"line\">         <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt;= i; j++) &#123;</div><div class=\"line\">             xx[j][m--] = num;</div><div class=\"line\">             num++;</div><div class=\"line\">         &#125;</div><div class=\"line\">         System.out.println();</div><div class=\"line\">     &#125;</div><div class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\">         <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt;= <span class=\"number\">5</span>; j++) &#123;</div><div class=\"line\">             <span class=\"keyword\">if</span> (xx[i][j] != -<span class=\"number\">1</span>)</div><div class=\"line\">                 System.out.print(xx[j][i] + <span class=\"string\">\" \"</span>);</div><div class=\"line\">         &#125;</div><div class=\"line\">         System.out.println();</div><div class=\"line\">     &#125;</div></pre></td></tr></table></figure></p>\n<p>xx arrayarray<br></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</div><div class=\"line\">       ArrayList&lt;Integer&gt; arrlist = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;(<span class=\"number\">5</span>);<span class=\"comment\">//ArrayList </span></div><div class=\"line\">       <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++) &#123;</div><div class=\"line\">           arrlist.add(i);</div><div class=\"line\">       &#125;</div><div class=\"line\">       arrlist.add(<span class=\"number\">0</span>);</div><div class=\"line\">       Iterator&lt;Integer&gt; it;</div><div class=\"line\">       arrprint(arrlist.iterator());</div><div class=\"line\">       <span class=\"keyword\">for</span> (it = arrlist.iterator(); it.hasNext(); ) &#123;</div><div class=\"line\">           <span class=\"keyword\">if</span> (it.next() == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">               it.remove();<span class=\"comment\">//arrlist</span></div><div class=\"line\"><span class=\"comment\">//                arrlist.remove((Integer)0); //Exception in thread \"main\" java.util.ConcurrentModificationException</span></div><div class=\"line\">           &#125;</div><div class=\"line\">       &#125;</div><div class=\"line\">       System.out.println();</div><div class=\"line\">       arrprint(arrlist.iterator());</div><div class=\"line\">   &#125;</div><div class=\"line\"></div><div class=\"line\">   <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">arrprint</span><span class=\"params\">(Iterator&lt;Integer&gt; it)</span> </span>&#123;</div><div class=\"line\">       <span class=\"keyword\">for</span> (; it.hasNext(); ) &#123;</div><div class=\"line\">           System.out.print(it.next() + <span class=\"string\">\" \"</span>);</div><div class=\"line\">       &#125;</div><div class=\"line\">   &#125;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">0 1 2 3 4 0</div><div class=\"line\">1 2 3 4</div></pre></td></tr></table></figure>\n<p>arraylist   JavaarrarylistJava<br></p>\n<ol>\n<li>JavaIterator</li>\n<li>iterator()IteratorIteratornext()iterator()java.lang.Iterable,Collection</li>\n<li>next()</li>\n<li>hasNext()</li>\n<li>remove()</li>\n</ol>"},{"title":"","date":"2017-05-08T16:00:00.000Z","_content":"\n<!-- more -->\n\n# \nXXX\n# \n\n\n# \n","source":"_posts/mybaby01.md","raw":"---\ntitle: \ndate: 2017-05-09\ntags: \n---\n\n<!-- more -->\n\n# \nXXX\n# \n\n\n# \n","slug":"mybaby01","published":1,"updated":"2017-05-10T16:31:52.609Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0q6000n60tu24fljvsv","content":"<p><br><a id=\"more\"></a><br></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>XXX</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n","excerpt":"<p><br>","more":"<br></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>XXX</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>"},{"title":"scala OptionSomeNone","date":"2017-08-31T15:09:46.000Z","_content":"null\n\nNULLnullc/c++NULLNULL0JavanullJava null c/c++bugNULLjavanullscalaoption\n<!-- more -->\n\nScalaOption\n\nScalaOptionNoneOptionSomeSomeOption\nNonenullNone\n\nscalasdk\nOptionScalaList,MapMapget\n```scala\nscala> val capitals = Map(\"France\"->\"Paris\", \"Japan\"->\"Tokyo\", \"China\"->\"Beijing\")\ncapitals: scala.collection.immutable.Map[String,String] = Map(France -> Paris, Japan -> Tokyo, China -> Beijing)\n\nscala> capitals get \"France\"\nres0: Option[String] = Some(Paris)\n\nscala> capitals get \"North Pole\"\nres1: Option[String] = None\n```\nOptionSomeNoneSomeStringget()StringNone\nNoneStringget() String ScalaNoSuchElementException\ngetOrElseOptionSomeNonegetOrElse\n```scala\nscala> capitals get \"North Pole\" get\nwarning: there was one feature warning; re-run with -feature for details\njava.util.NoSuchElementException: None.get\n  at scala.None$.get(Option.scala:347)\n  at scala.None$.get(Option.scala:345)\n  ... 33 elided\n\nscala> capitals get \"France\" get\nwarning: there was one feature warning; re-run with -feature for details\nres3: String = Paris\n\nscala> (capitals get \"North Pole\") getOrElse \"Oops\"\nres7: String = Oops\n\nscala> capitals get \"France\" getOrElse \"Oops\"\nres8: String = Paris\n```\nSomeSomex\n```scala\ndef showCapital(x: Option[String]) = x match {\n    case Some(s) => s\n    case None => \"?\"\n}\n```\n\nScalaOptionJavanullJavanull,nullNullPointerException\nScalaOptionScalaOptionOptionNone\n\nScalanullJavaScalaJavanullScalaOption[String]StringOption\n\nOption[T]\n\nScalaOption[T]ListList\nOptionList1 SomeOption0 None\n\nfor\n\nOptionListforOptionOptionNoneforOptionNone\n```scala\nscala> val map1 = Map(\"key1\" -> \"value1\")\nmap1: scala.collection.immutable.Map[String,String] = Map(key1 -> value1)\n\nscala> val value1 = map1.get(\"key1\")\nvalue1: Option[String] = Some(value1)\n\nscala> val value2 = map1.get(\"key2\")\nvalue2: Option[String] = None\n\nscala> def printContentLength(x: Option[String]) {\n     |   for (c <- x){\n     |     println(c.length)\n     |   }\n     | }\nprintContentLength: (x: Option[String])Unit\n\nscala> printContentLength(value1)\n6\n\nscala> printContentLength(value2)\n```\nmap\n\nmap()\nOptionmaplength: xxx\n\n Option \n \"length: \" \n\n```scala\nscala> value1.map(_.length).map(\"length: \" + _).foreach(println)\nlength: 6\n\nscala> value1.map(\"length: \" + _.length).foreach(println)\nlength: 6\n```\n","source":"_posts/scala-none.md","raw":"---\ntitle: scala OptionSomeNone\ndate: 2017-08-31 23:09:46\n\ncategory: \ntags: scala\n---\nnull\n\nNULLnullc/c++NULLNULL0JavanullJava null c/c++bugNULLjavanullscalaoption\n<!-- more -->\n\nScalaOption\n\nScalaOptionNoneOptionSomeSomeOption\nNonenullNone\n\nscalasdk\nOptionScalaList,MapMapget\n```scala\nscala> val capitals = Map(\"France\"->\"Paris\", \"Japan\"->\"Tokyo\", \"China\"->\"Beijing\")\ncapitals: scala.collection.immutable.Map[String,String] = Map(France -> Paris, Japan -> Tokyo, China -> Beijing)\n\nscala> capitals get \"France\"\nres0: Option[String] = Some(Paris)\n\nscala> capitals get \"North Pole\"\nres1: Option[String] = None\n```\nOptionSomeNoneSomeStringget()StringNone\nNoneStringget() String ScalaNoSuchElementException\ngetOrElseOptionSomeNonegetOrElse\n```scala\nscala> capitals get \"North Pole\" get\nwarning: there was one feature warning; re-run with -feature for details\njava.util.NoSuchElementException: None.get\n  at scala.None$.get(Option.scala:347)\n  at scala.None$.get(Option.scala:345)\n  ... 33 elided\n\nscala> capitals get \"France\" get\nwarning: there was one feature warning; re-run with -feature for details\nres3: String = Paris\n\nscala> (capitals get \"North Pole\") getOrElse \"Oops\"\nres7: String = Oops\n\nscala> capitals get \"France\" getOrElse \"Oops\"\nres8: String = Paris\n```\nSomeSomex\n```scala\ndef showCapital(x: Option[String]) = x match {\n    case Some(s) => s\n    case None => \"?\"\n}\n```\n\nScalaOptionJavanullJavanull,nullNullPointerException\nScalaOptionScalaOptionOptionNone\n\nScalanullJavaScalaJavanullScalaOption[String]StringOption\n\nOption[T]\n\nScalaOption[T]ListList\nOptionList1 SomeOption0 None\n\nfor\n\nOptionListforOptionOptionNoneforOptionNone\n```scala\nscala> val map1 = Map(\"key1\" -> \"value1\")\nmap1: scala.collection.immutable.Map[String,String] = Map(key1 -> value1)\n\nscala> val value1 = map1.get(\"key1\")\nvalue1: Option[String] = Some(value1)\n\nscala> val value2 = map1.get(\"key2\")\nvalue2: Option[String] = None\n\nscala> def printContentLength(x: Option[String]) {\n     |   for (c <- x){\n     |     println(c.length)\n     |   }\n     | }\nprintContentLength: (x: Option[String])Unit\n\nscala> printContentLength(value1)\n6\n\nscala> printContentLength(value2)\n```\nmap\n\nmap()\nOptionmaplength: xxx\n\n Option \n \"length: \" \n\n```scala\nscala> value1.map(_.length).map(\"length: \" + _).foreach(println)\nlength: 6\n\nscala> value1.map(\"length: \" + _.length).foreach(println)\nlength: 6\n```\n","slug":"scala-none","published":1,"updated":"2017-08-31T15:38:26.685Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0qd000p60tui7nopoch","content":"<p>null</p>\n<p>NULLnullc/c++NULLNULL0JavanullJava null c/c++bugNULLjavanullscalaoption<br><a id=\"more\"></a></p>\n<p>ScalaOption</p>\n<p>ScalaOptionNoneOptionSomeSomeOption<br>NonenullNone</p>\n<p>scalasdk<br>OptionScalaList,MapMapget<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> capitals = <span class=\"type\">Map</span>(<span class=\"string\">\"France\"</span>-&gt;<span class=\"string\">\"Paris\"</span>, <span class=\"string\">\"Japan\"</span>-&gt;<span class=\"string\">\"Tokyo\"</span>, <span class=\"string\">\"China\"</span>-&gt;<span class=\"string\">\"Beijing\"</span>)</div><div class=\"line\">capitals: scala.collection.immutable.<span class=\"type\">Map</span>[<span class=\"type\">String</span>,<span class=\"type\">String</span>] = <span class=\"type\">Map</span>(<span class=\"type\">France</span> -&gt; <span class=\"type\">Paris</span>, <span class=\"type\">Japan</span> -&gt; <span class=\"type\">Tokyo</span>, <span class=\"type\">China</span> -&gt; <span class=\"type\">Beijing</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"France\"</span></div><div class=\"line\">res0: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">Some</span>(<span class=\"type\">Paris</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"North Pole\"</span></div><div class=\"line\">res1: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">None</span></div></pre></td></tr></table></figure></p>\n<p>OptionSomeNoneSomeStringget()StringNone<br>NoneStringget() String ScalaNoSuchElementException<br>getOrElseOptionSomeNonegetOrElse<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"North Pole\"</span> get</div><div class=\"line\">warning: there was one feature warning; re-run <span class=\"keyword\">with</span> -feature <span class=\"keyword\">for</span> details</div><div class=\"line\">java.util.<span class=\"type\">NoSuchElementException</span>: <span class=\"type\">None</span>.get</div><div class=\"line\">  at scala.<span class=\"type\">None</span>$.get(<span class=\"type\">Option</span>.scala:<span class=\"number\">347</span>)</div><div class=\"line\">  at scala.<span class=\"type\">None</span>$.get(<span class=\"type\">Option</span>.scala:<span class=\"number\">345</span>)</div><div class=\"line\">  ... <span class=\"number\">33</span> elided</div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"France\"</span> get</div><div class=\"line\">warning: there was one feature warning; re-run <span class=\"keyword\">with</span> -feature <span class=\"keyword\">for</span> details</div><div class=\"line\">res3: <span class=\"type\">String</span> = <span class=\"type\">Paris</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; (capitals get <span class=\"string\">\"North Pole\"</span>) getOrElse <span class=\"string\">\"Oops\"</span></div><div class=\"line\">res7: <span class=\"type\">String</span> = <span class=\"type\">Oops</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"France\"</span> getOrElse <span class=\"string\">\"Oops\"</span></div><div class=\"line\">res8: <span class=\"type\">String</span> = <span class=\"type\">Paris</span></div></pre></td></tr></table></figure></p>\n<p>SomeSomex<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">showCapital</span></span>(x: <span class=\"type\">Option</span>[<span class=\"type\">String</span>]) = x <span class=\"keyword\">match</span> &#123;</div><div class=\"line\">    <span class=\"keyword\">case</span> <span class=\"type\">Some</span>(s) =&gt; s</div><div class=\"line\">    <span class=\"keyword\">case</span> <span class=\"type\">None</span> =&gt; <span class=\"string\">\"?\"</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>ScalaOptionJavanullJavanull,nullNullPointerException<br>ScalaOptionScalaOptionOptionNone</p>\n<p>ScalanullJavaScalaJavanullScalaOption[String]StringOption</p>\n<p>Option[T]</p>\n<p>ScalaOption[T]ListList<br>OptionList1 SomeOption0 None</p>\n<p>for</p>\n<p>OptionListforOptionOptionNoneforOptionNone<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> map1 = <span class=\"type\">Map</span>(<span class=\"string\">\"key1\"</span> -&gt; <span class=\"string\">\"value1\"</span>)</div><div class=\"line\">map1: scala.collection.immutable.<span class=\"type\">Map</span>[<span class=\"type\">String</span>,<span class=\"type\">String</span>] = <span class=\"type\">Map</span>(key1 -&gt; value1)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> value1 = map1.get(<span class=\"string\">\"key1\"</span>)</div><div class=\"line\">value1: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">Some</span>(value1)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> value2 = map1.get(<span class=\"string\">\"key2\"</span>)</div><div class=\"line\">value2: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">None</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printContentLength</span></span>(x: <span class=\"type\">Option</span>[<span class=\"type\">String</span>]) &#123;</div><div class=\"line\">     |   <span class=\"keyword\">for</span> (c &lt;- x)&#123;</div><div class=\"line\">     |     println(c.length)</div><div class=\"line\">     |   &#125;</div><div class=\"line\">     | &#125;</div><div class=\"line\">printContentLength: (x: <span class=\"type\">Option</span>[<span class=\"type\">String</span>])<span class=\"type\">Unit</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; printContentLength(value1)</div><div class=\"line\"><span class=\"number\">6</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; printContentLength(value2)</div></pre></td></tr></table></figure></p>\n<p>map</p>\n<p>map()<br>Optionmaplength: xxx</p>\n<p> Option <br> length:  <br><br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; value1.map(_.length).map(<span class=\"string\">\"length: \"</span> + _).foreach(println)</div><div class=\"line\">length: <span class=\"number\">6</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; value1.map(<span class=\"string\">\"length: \"</span> + _.length).foreach(println)</div><div class=\"line\">length: <span class=\"number\">6</span></div></pre></td></tr></table></figure></p>\n","excerpt":"<p>null</p>\n<p>NULLnullc/c++NULLNULL0JavanullJava null c/c++bugNULLjavanullscalaoption<br>","more":"</p>\n<p>ScalaOption</p>\n<p>ScalaOptionNoneOptionSomeSomeOption<br>NonenullNone</p>\n<p>scalasdk<br>OptionScalaList,MapMapget<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> capitals = <span class=\"type\">Map</span>(<span class=\"string\">\"France\"</span>-&gt;<span class=\"string\">\"Paris\"</span>, <span class=\"string\">\"Japan\"</span>-&gt;<span class=\"string\">\"Tokyo\"</span>, <span class=\"string\">\"China\"</span>-&gt;<span class=\"string\">\"Beijing\"</span>)</div><div class=\"line\">capitals: scala.collection.immutable.<span class=\"type\">Map</span>[<span class=\"type\">String</span>,<span class=\"type\">String</span>] = <span class=\"type\">Map</span>(<span class=\"type\">France</span> -&gt; <span class=\"type\">Paris</span>, <span class=\"type\">Japan</span> -&gt; <span class=\"type\">Tokyo</span>, <span class=\"type\">China</span> -&gt; <span class=\"type\">Beijing</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"France\"</span></div><div class=\"line\">res0: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">Some</span>(<span class=\"type\">Paris</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"North Pole\"</span></div><div class=\"line\">res1: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">None</span></div></pre></td></tr></table></figure></p>\n<p>OptionSomeNoneSomeStringget()StringNone<br>NoneStringget() String ScalaNoSuchElementException<br>getOrElseOptionSomeNonegetOrElse<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"North Pole\"</span> get</div><div class=\"line\">warning: there was one feature warning; re-run <span class=\"keyword\">with</span> -feature <span class=\"keyword\">for</span> details</div><div class=\"line\">java.util.<span class=\"type\">NoSuchElementException</span>: <span class=\"type\">None</span>.get</div><div class=\"line\">  at scala.<span class=\"type\">None</span>$.get(<span class=\"type\">Option</span>.scala:<span class=\"number\">347</span>)</div><div class=\"line\">  at scala.<span class=\"type\">None</span>$.get(<span class=\"type\">Option</span>.scala:<span class=\"number\">345</span>)</div><div class=\"line\">  ... <span class=\"number\">33</span> elided</div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"France\"</span> get</div><div class=\"line\">warning: there was one feature warning; re-run <span class=\"keyword\">with</span> -feature <span class=\"keyword\">for</span> details</div><div class=\"line\">res3: <span class=\"type\">String</span> = <span class=\"type\">Paris</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; (capitals get <span class=\"string\">\"North Pole\"</span>) getOrElse <span class=\"string\">\"Oops\"</span></div><div class=\"line\">res7: <span class=\"type\">String</span> = <span class=\"type\">Oops</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; capitals get <span class=\"string\">\"France\"</span> getOrElse <span class=\"string\">\"Oops\"</span></div><div class=\"line\">res8: <span class=\"type\">String</span> = <span class=\"type\">Paris</span></div></pre></td></tr></table></figure></p>\n<p>SomeSomex<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">showCapital</span></span>(x: <span class=\"type\">Option</span>[<span class=\"type\">String</span>]) = x <span class=\"keyword\">match</span> &#123;</div><div class=\"line\">    <span class=\"keyword\">case</span> <span class=\"type\">Some</span>(s) =&gt; s</div><div class=\"line\">    <span class=\"keyword\">case</span> <span class=\"type\">None</span> =&gt; <span class=\"string\">\"?\"</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>ScalaOptionJavanullJavanull,nullNullPointerException<br>ScalaOptionScalaOptionOptionNone</p>\n<p>ScalanullJavaScalaJavanullScalaOption[String]StringOption</p>\n<p>Option[T]</p>\n<p>ScalaOption[T]ListList<br>OptionList1 SomeOption0 None</p>\n<p>for</p>\n<p>OptionListforOptionOptionNoneforOptionNone<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> map1 = <span class=\"type\">Map</span>(<span class=\"string\">\"key1\"</span> -&gt; <span class=\"string\">\"value1\"</span>)</div><div class=\"line\">map1: scala.collection.immutable.<span class=\"type\">Map</span>[<span class=\"type\">String</span>,<span class=\"type\">String</span>] = <span class=\"type\">Map</span>(key1 -&gt; value1)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> value1 = map1.get(<span class=\"string\">\"key1\"</span>)</div><div class=\"line\">value1: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">Some</span>(value1)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> value2 = map1.get(<span class=\"string\">\"key2\"</span>)</div><div class=\"line\">value2: <span class=\"type\">Option</span>[<span class=\"type\">String</span>] = <span class=\"type\">None</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printContentLength</span></span>(x: <span class=\"type\">Option</span>[<span class=\"type\">String</span>]) &#123;</div><div class=\"line\">     |   <span class=\"keyword\">for</span> (c &lt;- x)&#123;</div><div class=\"line\">     |     println(c.length)</div><div class=\"line\">     |   &#125;</div><div class=\"line\">     | &#125;</div><div class=\"line\">printContentLength: (x: <span class=\"type\">Option</span>[<span class=\"type\">String</span>])<span class=\"type\">Unit</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; printContentLength(value1)</div><div class=\"line\"><span class=\"number\">6</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; printContentLength(value2)</div></pre></td></tr></table></figure></p>\n<p>map</p>\n<p>map()<br>Optionmaplength: xxx</p>\n<p> Option <br> length:  <br><br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; value1.map(_.length).map(<span class=\"string\">\"length: \"</span> + _).foreach(println)</div><div class=\"line\">length: <span class=\"number\">6</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; value1.map(<span class=\"string\">\"length: \"</span> + _.length).foreach(println)</div><div class=\"line\">length: <span class=\"number\">6</span></div></pre></td></tr></table></figure></p>"},{"title":"scalafoldreduce","date":"2017-08-30T12:21:16.000Z","_content":"scala javajavascalascalajavascalascalascalareducefold\n<!-- more -->\nscalalistfoldlistFoldleftFoldrightFold\n```scala\n\ncala> val x = List(1,2,3,4)\nx: List[Int] = List(1, 2, 3, 4)\n\nscala> x.foldLeft(0)((x,y)=>x+y)\nres5: Int = 10\n\ncala> x.fold(0)((x,y)=>x+y)\nres6: Int = 10\n\nscala> x.foldRight(0)((x,y)=>x+y)\nres7: Int = 10\n\n```\n\n\n```scala\n\nscala> val x = List(\"this\",\"is\",\"an\",\"String\",\"Aarray\")\nx: List[String] = List(this, is, an, String, Aarray)\n\nscala> x.fold(\"where is * \")((x,y)=>x+y)\nres8: String = where is * thisisanStringAarray\n\nscala> x.fold(\"where is * \")((x,y)=>x+\",\"+y)\nres9: String = where is * ,this,is,an,String,Aarray\n\nscala> x.foldLeft(\"where is * \")((x,y)=>x+\",\"+y)\nres10: String = where is * ,this,is,an,String,Aarray\n\nscala> x.foldRight(\"where is * \")((x,y)=>x+\",\"+y)\nres11: String = \"this,is,an,String,Aarray,where is * \"\n\n```\nRightleftleft\n\nfold, foldLeft, and foldRight foldfoldLeftfoldRightfoldTraversableOnce\n```scala\ndef fold[A1 >: A](z: A1)(op: (A1, A1) => A1): A1 = foldLeft(z)(op)\n \ndef foldLeft[B](z: B)(op: (B, A) => B): B = {\n var result = z\n this.seq foreach (x => result = op(result, x))\n result\n }\n  \ndef foldRight[B](z: B)(op: (A, B) => B): B =\n    reversed.foldLeft(z)((x, y) => op(y, x))\n```\nfoldfold\n1. listList[Int]foldIntList[Int]\n2. (neutral)01listNil,\n\n\n\nfoldLeftfoldRight\n\n\n```scala\ndef /:[B](z: B)(op: (B, A) => B): B = foldLeft(z)(op)\n\ndef :\\[B](z: B)(op: (A, B) => B): B = foldRight(z)(op)\n\nscala> (0/:(1 to 100))(_+_)  \nres32: Int = 5050\n\nscala> ((1 to 100):\\0)(_+_) \nres24: Int = 5050\n```\n\nreduce reducescalareducefold\n\n```scala\nval list = List(\"A\",\"B\",\"C\",\"D\",\"E\")\nprintln(\"reduce (a+b) \"+list.reduce((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (a+b) \"+list.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (b+a) \"+list.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\n\nprintln(\"reduceRight (a+b) \"+list.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"reduceRight (b+a) \"+list.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \")\nb+a\n}))\n\nprintln(\"scan            \"+list.scan(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\nprintln(\"scanLeft (a+b)  \"+list.scanLeft(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\nprintln(\"scanLeft (b+a)  \"+list.scanLeft(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\nprintln(\"scanRight (a+b) \"+list.scanRight(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\nprintln(\"scanRight (b+a) \"+list.scanRight(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\nval list1 = List(-2,-1,0,1,2)\n\nprintln(\"reduce (a+b) \"+list1.reduce((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (a+b) \"+list1.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (b+a) \"+list1.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\n\nprintln(\"      reduceRight (a+b) \"+list1.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"      reduceRight (b+a) \"+list1.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \")\nb+a\n}))\n\nprintln(\"scan            \"+list1.scan(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"scanLeft (a+b)  \"+list1.scanLeft(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"scanLeft (b+a)  \"+list1.scanLeft(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\n\nprintln(\"scanRight (a+b)         \"+list1.scanRight(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b}))\n\nprintln(\"scanRight (b+a)         \"+list1.scanRight(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\nb+a}))\n```\nreduce fold,\n\n\n```scala\n{A,B}=>AB  {AB,C}=>ABC  {ABC,D}=>ABCD  {ABCD,E}=>ABCDE  reduce (a+b) ABCDE\n{A,B}=>AB  {AB,C}=>ABC  {ABC,D}=>ABCD  {ABCD,E}=>ABCDE  reduceLeft (a+b) ABCDE\n{A,B}=>BA  {BA,C}=>CBA  {CBA,D}=>DCBA  {DCBA,E}=>EDCBA  reduceLeft (b+a) EDCBA\n{D,E}=>DE  {C,DE}=>CDE  {B,CDE}=>BCDE  {A,BCDE}=>ABCDE  reduceRight (a+b) ABCDE\n{D,E}=>ED  {C,ED}=>EDC  {B,EDC}=>EDCB  {A,EDCB}=>EDCBA  reduceRight (b+a) EDCBA\n{[,A}=>[A  {[A,B}=>[AB  {[AB,C}=>[ABC  {[ABC,D}=>[ABCD  {[ABCD,E}=>[ABCDE  scan            List([, [A, [AB, [ABC, [ABCD, [ABCDE)\n{[,A}=>[A  {[A,B}=>[AB  {[AB,C}=>[ABC  {[ABC,D}=>[ABCD  {[ABCD,E}=>[ABCDE  scanLeft (a+b)  List([, [A, [AB, [ABC, [ABCD, [ABCDE)\n{[,A}=>A[  {A[,B}=>BA[  {BA[,C}=>CBA[  {CBA[,D}=>DCBA[  {DCBA[,E}=>EDCBA[  scanLeft (b+a)  List([, A[, BA[, CBA[, DCBA[, EDCBA[)\n{E,[}=>E[  {D,E[}=>DE[  {C,DE[}=>CDE[  {B,CDE[}=>BCDE[  {A,BCDE[}=>ABCDE[  scanRight (a+b) List(ABCDE[, BCDE[, CDE[, DE[, E[, [)\n{E,[}=>[E  {D,[E}=>[ED  {C,[ED}=>[EDC  {B,[EDC}=>[EDCB  {A,[EDCB}=>[EDCBA  scanRight (b+a) List([EDCBA, [EDCB, [EDC, [ED, [E, [)\n{-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  reduce (a+b) 0\n{-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  reduceLeft (a+b) 0\n{-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  reduceLeft (b+a) 0\n{1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0        reduceRight (a+b) 0\n{1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0        reduceRight (b+a) 0\n{0,-2}=>-2  {-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  scan            List(0, -2, -3, -3, -2, 0)\n{0,-2}=>-2  {-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  scanLeft (a+b)  List(0, -2, -3, -3, -2, 0)\n{0,-2}=>-2  {-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  scanLeft (b+a)  List(0, -2, -3, -3, -2, 0)\n{2,0}=>2  {1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0  scanRight (a+b)         List(0, 2, 3, 3, 2, 0)\n{2,0}=>2  {1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0  scanRight (b+a)         List(0, 2, 3, 3, 2, 0)\n\n```\n","source":"_posts/scalaa.md","raw":"---\ntitle: scalafoldreduce\ndate: 2017-08-30 20:21:16\ntags: scala\n---\nscala javajavascalascalajavascalascalascalareducefold\n<!-- more -->\nscalalistfoldlistFoldleftFoldrightFold\n```scala\n\ncala> val x = List(1,2,3,4)\nx: List[Int] = List(1, 2, 3, 4)\n\nscala> x.foldLeft(0)((x,y)=>x+y)\nres5: Int = 10\n\ncala> x.fold(0)((x,y)=>x+y)\nres6: Int = 10\n\nscala> x.foldRight(0)((x,y)=>x+y)\nres7: Int = 10\n\n```\n\n\n```scala\n\nscala> val x = List(\"this\",\"is\",\"an\",\"String\",\"Aarray\")\nx: List[String] = List(this, is, an, String, Aarray)\n\nscala> x.fold(\"where is * \")((x,y)=>x+y)\nres8: String = where is * thisisanStringAarray\n\nscala> x.fold(\"where is * \")((x,y)=>x+\",\"+y)\nres9: String = where is * ,this,is,an,String,Aarray\n\nscala> x.foldLeft(\"where is * \")((x,y)=>x+\",\"+y)\nres10: String = where is * ,this,is,an,String,Aarray\n\nscala> x.foldRight(\"where is * \")((x,y)=>x+\",\"+y)\nres11: String = \"this,is,an,String,Aarray,where is * \"\n\n```\nRightleftleft\n\nfold, foldLeft, and foldRight foldfoldLeftfoldRightfoldTraversableOnce\n```scala\ndef fold[A1 >: A](z: A1)(op: (A1, A1) => A1): A1 = foldLeft(z)(op)\n \ndef foldLeft[B](z: B)(op: (B, A) => B): B = {\n var result = z\n this.seq foreach (x => result = op(result, x))\n result\n }\n  \ndef foldRight[B](z: B)(op: (A, B) => B): B =\n    reversed.foldLeft(z)((x, y) => op(y, x))\n```\nfoldfold\n1. listList[Int]foldIntList[Int]\n2. (neutral)01listNil,\n\n\n\nfoldLeftfoldRight\n\n\n```scala\ndef /:[B](z: B)(op: (B, A) => B): B = foldLeft(z)(op)\n\ndef :\\[B](z: B)(op: (A, B) => B): B = foldRight(z)(op)\n\nscala> (0/:(1 to 100))(_+_)  \nres32: Int = 5050\n\nscala> ((1 to 100):\\0)(_+_) \nres24: Int = 5050\n```\n\nreduce reducescalareducefold\n\n```scala\nval list = List(\"A\",\"B\",\"C\",\"D\",\"E\")\nprintln(\"reduce (a+b) \"+list.reduce((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (a+b) \"+list.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (b+a) \"+list.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\n\nprintln(\"reduceRight (a+b) \"+list.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"reduceRight (b+a) \"+list.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \")\nb+a\n}))\n\nprintln(\"scan            \"+list.scan(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\nprintln(\"scanLeft (a+b)  \"+list.scanLeft(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\nprintln(\"scanLeft (b+a)  \"+list.scanLeft(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\nprintln(\"scanRight (a+b) \"+list.scanRight(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\nprintln(\"scanRight (b+a) \"+list.scanRight(\"[\")((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\nval list1 = List(-2,-1,0,1,2)\n\nprintln(\"reduce (a+b) \"+list1.reduce((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (a+b) \"+list1.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \")\na+b\n}))\n\nprintln(\"reduceLeft (b+a) \"+list1.reduceLeft((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\n\nprintln(\"      reduceRight (a+b) \"+list1.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"      reduceRight (b+a) \"+list1.reduceRight((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \")\nb+a\n}))\n\nprintln(\"scan            \"+list1.scan(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"scanLeft (a+b)  \"+list1.scanLeft(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b\n}))\n\nprintln(\"scanLeft (b+a)  \"+list1.scanLeft(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (b+a)+\"  \" )\nb+a\n}))\n\nprintln(\"scanRight (a+b)         \"+list1.scanRight(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\na+b}))\n\nprintln(\"scanRight (b+a)         \"+list1.scanRight(0)((a,b)=>{\nprint(\"{\"+a+\",\"+b+\"}=>\"+ (a+b)+\"  \" )\nb+a}))\n```\nreduce fold,\n\n\n```scala\n{A,B}=>AB  {AB,C}=>ABC  {ABC,D}=>ABCD  {ABCD,E}=>ABCDE  reduce (a+b) ABCDE\n{A,B}=>AB  {AB,C}=>ABC  {ABC,D}=>ABCD  {ABCD,E}=>ABCDE  reduceLeft (a+b) ABCDE\n{A,B}=>BA  {BA,C}=>CBA  {CBA,D}=>DCBA  {DCBA,E}=>EDCBA  reduceLeft (b+a) EDCBA\n{D,E}=>DE  {C,DE}=>CDE  {B,CDE}=>BCDE  {A,BCDE}=>ABCDE  reduceRight (a+b) ABCDE\n{D,E}=>ED  {C,ED}=>EDC  {B,EDC}=>EDCB  {A,EDCB}=>EDCBA  reduceRight (b+a) EDCBA\n{[,A}=>[A  {[A,B}=>[AB  {[AB,C}=>[ABC  {[ABC,D}=>[ABCD  {[ABCD,E}=>[ABCDE  scan            List([, [A, [AB, [ABC, [ABCD, [ABCDE)\n{[,A}=>[A  {[A,B}=>[AB  {[AB,C}=>[ABC  {[ABC,D}=>[ABCD  {[ABCD,E}=>[ABCDE  scanLeft (a+b)  List([, [A, [AB, [ABC, [ABCD, [ABCDE)\n{[,A}=>A[  {A[,B}=>BA[  {BA[,C}=>CBA[  {CBA[,D}=>DCBA[  {DCBA[,E}=>EDCBA[  scanLeft (b+a)  List([, A[, BA[, CBA[, DCBA[, EDCBA[)\n{E,[}=>E[  {D,E[}=>DE[  {C,DE[}=>CDE[  {B,CDE[}=>BCDE[  {A,BCDE[}=>ABCDE[  scanRight (a+b) List(ABCDE[, BCDE[, CDE[, DE[, E[, [)\n{E,[}=>[E  {D,[E}=>[ED  {C,[ED}=>[EDC  {B,[EDC}=>[EDCB  {A,[EDCB}=>[EDCBA  scanRight (b+a) List([EDCBA, [EDCB, [EDC, [ED, [E, [)\n{-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  reduce (a+b) 0\n{-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  reduceLeft (a+b) 0\n{-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  reduceLeft (b+a) 0\n{1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0        reduceRight (a+b) 0\n{1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0        reduceRight (b+a) 0\n{0,-2}=>-2  {-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  scan            List(0, -2, -3, -3, -2, 0)\n{0,-2}=>-2  {-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  scanLeft (a+b)  List(0, -2, -3, -3, -2, 0)\n{0,-2}=>-2  {-2,-1}=>-3  {-3,0}=>-3  {-3,1}=>-2  {-2,2}=>0  scanLeft (b+a)  List(0, -2, -3, -3, -2, 0)\n{2,0}=>2  {1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0  scanRight (a+b)         List(0, 2, 3, 3, 2, 0)\n{2,0}=>2  {1,2}=>3  {0,3}=>3  {-1,3}=>2  {-2,2}=>0  scanRight (b+a)         List(0, 2, 3, 3, 2, 0)\n\n```\n","slug":"scalaa","published":1,"updated":"2017-08-30T14:14:45.138Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0qi000s60tuo9h0op03","content":"<p>scala javajavascalascalajavascalascalascalareducefold<br><a id=\"more\"></a><br>scalalistfoldlistFoldleftFoldrightFold<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">cala&gt; <span class=\"keyword\">val</span> x = <span class=\"type\">List</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</div><div class=\"line\">x: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldLeft(<span class=\"number\">0</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res5: <span class=\"type\">Int</span> = <span class=\"number\">10</span></div><div class=\"line\"></div><div class=\"line\">cala&gt; x.fold(<span class=\"number\">0</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res6: <span class=\"type\">Int</span> = <span class=\"number\">10</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldRight(<span class=\"number\">0</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res7: <span class=\"type\">Int</span> = <span class=\"number\">10</span></div></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> x = <span class=\"type\">List</span>(<span class=\"string\">\"this\"</span>,<span class=\"string\">\"is\"</span>,<span class=\"string\">\"an\"</span>,<span class=\"string\">\"String\"</span>,<span class=\"string\">\"Aarray\"</span>)</div><div class=\"line\">x: <span class=\"type\">List</span>[<span class=\"type\">String</span>] = <span class=\"type\">List</span>(<span class=\"keyword\">this</span>, is, an, <span class=\"type\">String</span>, <span class=\"type\">Aarray</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; x.fold(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res8: <span class=\"type\">String</span> = where is * thisisanStringAarray</div><div class=\"line\"></div><div class=\"line\">scala&gt; x.fold(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+<span class=\"string\">\",\"</span>+y)</div><div class=\"line\">res9: <span class=\"type\">String</span> = where is * ,<span class=\"keyword\">this</span>,is,an,<span class=\"type\">String</span>,<span class=\"type\">Aarray</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldLeft(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+<span class=\"string\">\",\"</span>+y)</div><div class=\"line\">res10: <span class=\"type\">String</span> = where is * ,<span class=\"keyword\">this</span>,is,an,<span class=\"type\">String</span>,<span class=\"type\">Aarray</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldRight(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+<span class=\"string\">\",\"</span>+y)</div><div class=\"line\">res11: <span class=\"type\">String</span> = <span class=\"string\">\"this,is,an,String,Aarray,where is * \"</span></div></pre></td></tr></table></figure>\n<p>Rightleftleft<br><br>fold, foldLeft, and foldRight foldfoldLeftfoldRightfoldTraversableOnce<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fold</span></span>[<span class=\"type\">A1</span> &gt;: <span class=\"type\">A</span>](z: <span class=\"type\">A1</span>)(op: (<span class=\"type\">A1</span>, <span class=\"type\">A1</span>) =&gt; <span class=\"type\">A1</span>): <span class=\"type\">A1</span> = foldLeft(z)(op)</div><div class=\"line\"> </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foldLeft</span></span>[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">B</span>, <span class=\"type\">A</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> = &#123;</div><div class=\"line\"> <span class=\"keyword\">var</span> result = z</div><div class=\"line\"> <span class=\"keyword\">this</span>.seq foreach (x =&gt; result = op(result, x))</div><div class=\"line\"> result</div><div class=\"line\"> &#125;</div><div class=\"line\">  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foldRight</span></span>[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">A</span>, <span class=\"type\">B</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> =</div><div class=\"line\">    reversed.foldLeft(z)((x, y) =&gt; op(y, x))</div></pre></td></tr></table></figure></p>\n<p>foldfold</p>\n<ol>\n<li>listList[Int]foldIntList[Int]</li>\n<li>(neutral)01listNil,</li>\n</ol>\n<p>foldLeftfoldRight</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">/</span></span>:[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">B</span>, <span class=\"type\">A</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> = foldLeft(z)(op)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> </span>:\\[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">A</span>, <span class=\"type\">B</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> = foldRight(z)(op)</div><div class=\"line\"></div><div class=\"line\">scala&gt; (<span class=\"number\">0</span>/:(<span class=\"number\">1</span> to <span class=\"number\">100</span>))(_+_)  </div><div class=\"line\">res32: <span class=\"type\">Int</span> = <span class=\"number\">5050</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; ((<span class=\"number\">1</span> to <span class=\"number\">100</span>):\\<span class=\"number\">0</span>)(_+_) </div><div class=\"line\">res24: <span class=\"type\">Int</span> = <span class=\"number\">5050</span></div></pre></td></tr></table></figure>\n<p>reduce reducescalareducefold</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">val</span> list = <span class=\"type\">List</span>(<span class=\"string\">\"A\"</span>,<span class=\"string\">\"B\"</span>,<span class=\"string\">\"C\"</span>,<span class=\"string\">\"D\"</span>,<span class=\"string\">\"E\"</span>)</div><div class=\"line\">println(<span class=\"string\">\"reduce (a+b) \"</span>+list.reduce((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (a+b) \"</span>+list.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (b+a) \"</span>+list.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceRight (a+b) \"</span>+list.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceRight (b+a) \"</span>+list.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scan            \"</span>+list.scan(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanLeft (a+b)  \"</span>+list.scanLeft(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanLeft (b+a)  \"</span>+list.scanLeft(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanRight (a+b) \"</span>+list.scanRight(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanRight (b+a) \"</span>+list.scanRight(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"><span class=\"keyword\">val</span> list1 = <span class=\"type\">List</span>(<span class=\"number\">-2</span>,<span class=\"number\">-1</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduce (a+b) \"</span>+list1.reduce((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (a+b) \"</span>+list1.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (b+a) \"</span>+list1.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"      reduceRight (a+b) \"</span>+list1.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"      reduceRight (b+a) \"</span>+list1.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scan            \"</span>+list1.scan(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanLeft (a+b)  \"</span>+list1.scanLeft(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanLeft (b+a)  \"</span>+list1.scanLeft(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanRight (a+b)         \"</span>+list1.scanRight(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanRight (b+a)         \"</span>+list1.scanRight(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a&#125;))</div></pre></td></tr></table></figure>\n<p>reduce fold,</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">AB</span>  &#123;<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">ABC</span>  &#123;<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">ABCD</span>  &#123;<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">ABCDE</span>  reduce (a+b) <span class=\"type\">ABCDE</span></div><div class=\"line\">&#123;<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">AB</span>  &#123;<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">ABC</span>  &#123;<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">ABCD</span>  &#123;<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">ABCDE</span>  reduceLeft (a+b) <span class=\"type\">ABCDE</span></div><div class=\"line\">&#123;<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">BA</span>  &#123;<span class=\"type\">BA</span>,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">CBA</span>  &#123;<span class=\"type\">CBA</span>,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">DCBA</span>  &#123;<span class=\"type\">DCBA</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">EDCBA</span>  reduceLeft (b+a) <span class=\"type\">EDCBA</span></div><div class=\"line\">&#123;<span class=\"type\">D</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">DE</span>  &#123;<span class=\"type\">C</span>,<span class=\"type\">DE</span>&#125;=&gt;<span class=\"type\">CDE</span>  &#123;<span class=\"type\">B</span>,<span class=\"type\">CDE</span>&#125;=&gt;<span class=\"type\">BCDE</span>  &#123;<span class=\"type\">A</span>,<span class=\"type\">BCDE</span>&#125;=&gt;<span class=\"type\">ABCDE</span>  reduceRight (a+b) <span class=\"type\">ABCDE</span></div><div class=\"line\">&#123;<span class=\"type\">D</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">ED</span>  &#123;<span class=\"type\">C</span>,<span class=\"type\">ED</span>&#125;=&gt;<span class=\"type\">EDC</span>  &#123;<span class=\"type\">B</span>,<span class=\"type\">EDC</span>&#125;=&gt;<span class=\"type\">EDCB</span>  &#123;<span class=\"type\">A</span>,<span class=\"type\">EDCB</span>&#125;=&gt;<span class=\"type\">EDCBA</span>  reduceRight (b+a) <span class=\"type\">EDCBA</span></div><div class=\"line\">&#123;[,<span class=\"type\">A</span>&#125;=&gt;[<span class=\"type\">A</span>  &#123;[<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;[<span class=\"type\">AB</span>  &#123;[<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;[<span class=\"type\">ABC</span>  &#123;[<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;[<span class=\"type\">ABCD</span>  &#123;[<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;[<span class=\"type\">ABCDE</span>  scan            <span class=\"type\">List</span>([, [<span class=\"type\">A</span>, [<span class=\"type\">AB</span>, [<span class=\"type\">ABC</span>, [<span class=\"type\">ABCD</span>, [<span class=\"type\">ABCDE</span>)</div><div class=\"line\">&#123;[,<span class=\"type\">A</span>&#125;=&gt;[<span class=\"type\">A</span>  &#123;[<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;[<span class=\"type\">AB</span>  &#123;[<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;[<span class=\"type\">ABC</span>  &#123;[<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;[<span class=\"type\">ABCD</span>  &#123;[<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;[<span class=\"type\">ABCDE</span>  scanLeft (a+b)  <span class=\"type\">List</span>([, [<span class=\"type\">A</span>, [<span class=\"type\">AB</span>, [<span class=\"type\">ABC</span>, [<span class=\"type\">ABCD</span>, [<span class=\"type\">ABCDE</span>)</div><div class=\"line\">&#123;[,<span class=\"type\">A</span>&#125;=&gt;<span class=\"type\">A</span>[  &#123;<span class=\"type\">A</span>[,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">BA</span>[  &#123;<span class=\"type\">BA</span>[,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">CBA</span>[  &#123;<span class=\"type\">CBA</span>[,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">DCBA</span>[  &#123;<span class=\"type\">DCBA</span>[,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">EDCBA</span>[  scanLeft (b+a)  <span class=\"type\">List</span>([, <span class=\"type\">A</span>[, <span class=\"type\">BA</span>[, <span class=\"type\">CBA</span>[, <span class=\"type\">DCBA</span>[, <span class=\"type\">EDCBA</span>[)</div><div class=\"line\">&#123;<span class=\"type\">E</span>,[&#125;=&gt;<span class=\"type\">E</span>[  &#123;<span class=\"type\">D</span>,<span class=\"type\">E</span>[&#125;=&gt;<span class=\"type\">DE</span>[  &#123;<span class=\"type\">C</span>,<span class=\"type\">DE</span>[&#125;=&gt;<span class=\"type\">CDE</span>[  &#123;<span class=\"type\">B</span>,<span class=\"type\">CDE</span>[&#125;=&gt;<span class=\"type\">BCDE</span>[  &#123;<span class=\"type\">A</span>,<span class=\"type\">BCDE</span>[&#125;=&gt;<span class=\"type\">ABCDE</span>[  scanRight (a+b) <span class=\"type\">List</span>(<span class=\"type\">ABCDE</span>[, <span class=\"type\">BCDE</span>[, <span class=\"type\">CDE</span>[, <span class=\"type\">DE</span>[, <span class=\"type\">E</span>[, [)</div><div class=\"line\">&#123;<span class=\"type\">E</span>,[&#125;=&gt;[<span class=\"type\">E</span>  &#123;<span class=\"type\">D</span>,[<span class=\"type\">E</span>&#125;=&gt;[<span class=\"type\">ED</span>  &#123;<span class=\"type\">C</span>,[<span class=\"type\">ED</span>&#125;=&gt;[<span class=\"type\">EDC</span>  &#123;<span class=\"type\">B</span>,[<span class=\"type\">EDC</span>&#125;=&gt;[<span class=\"type\">EDCB</span>  &#123;<span class=\"type\">A</span>,[<span class=\"type\">EDCB</span>&#125;=&gt;[<span class=\"type\">EDCBA</span>  scanRight (b+a) <span class=\"type\">List</span>([<span class=\"type\">EDCBA</span>, [<span class=\"type\">EDCB</span>, [<span class=\"type\">EDC</span>, [<span class=\"type\">ED</span>, [<span class=\"type\">E</span>, [)</div><div class=\"line\">&#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  reduce (a+b) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  reduceLeft (a+b) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  reduceLeft (b+a) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>        reduceRight (a+b) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>        reduceRight (b+a) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">0</span>,<span class=\"number\">-2</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scan            <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">-2</span>, <span class=\"number\">-3</span>, <span class=\"number\">-3</span>, <span class=\"number\">-2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">0</span>,<span class=\"number\">-2</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanLeft (a+b)  <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">-2</span>, <span class=\"number\">-3</span>, <span class=\"number\">-3</span>, <span class=\"number\">-2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">0</span>,<span class=\"number\">-2</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanLeft (b+a)  <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">-2</span>, <span class=\"number\">-3</span>, <span class=\"number\">-3</span>, <span class=\"number\">-2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">2</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanRight (a+b)         <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">2</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanRight (b+a)         <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)</div></pre></td></tr></table></figure>\n","excerpt":"<p>scala javajavascalascalajavascalascalascalareducefold<br>","more":"<br>scalalistfoldlistFoldleftFoldrightFold<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">cala&gt; <span class=\"keyword\">val</span> x = <span class=\"type\">List</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</div><div class=\"line\">x: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldLeft(<span class=\"number\">0</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res5: <span class=\"type\">Int</span> = <span class=\"number\">10</span></div><div class=\"line\"></div><div class=\"line\">cala&gt; x.fold(<span class=\"number\">0</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res6: <span class=\"type\">Int</span> = <span class=\"number\">10</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldRight(<span class=\"number\">0</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res7: <span class=\"type\">Int</span> = <span class=\"number\">10</span></div></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> x = <span class=\"type\">List</span>(<span class=\"string\">\"this\"</span>,<span class=\"string\">\"is\"</span>,<span class=\"string\">\"an\"</span>,<span class=\"string\">\"String\"</span>,<span class=\"string\">\"Aarray\"</span>)</div><div class=\"line\">x: <span class=\"type\">List</span>[<span class=\"type\">String</span>] = <span class=\"type\">List</span>(<span class=\"keyword\">this</span>, is, an, <span class=\"type\">String</span>, <span class=\"type\">Aarray</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; x.fold(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+y)</div><div class=\"line\">res8: <span class=\"type\">String</span> = where is * thisisanStringAarray</div><div class=\"line\"></div><div class=\"line\">scala&gt; x.fold(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+<span class=\"string\">\",\"</span>+y)</div><div class=\"line\">res9: <span class=\"type\">String</span> = where is * ,<span class=\"keyword\">this</span>,is,an,<span class=\"type\">String</span>,<span class=\"type\">Aarray</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldLeft(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+<span class=\"string\">\",\"</span>+y)</div><div class=\"line\">res10: <span class=\"type\">String</span> = where is * ,<span class=\"keyword\">this</span>,is,an,<span class=\"type\">String</span>,<span class=\"type\">Aarray</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; x.foldRight(<span class=\"string\">\"where is * \"</span>)((x,y)=&gt;x+<span class=\"string\">\",\"</span>+y)</div><div class=\"line\">res11: <span class=\"type\">String</span> = <span class=\"string\">\"this,is,an,String,Aarray,where is * \"</span></div></pre></td></tr></table></figure>\n<p>Rightleftleft<br><br>fold, foldLeft, and foldRight foldfoldLeftfoldRightfoldTraversableOnce<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fold</span></span>[<span class=\"type\">A1</span> &gt;: <span class=\"type\">A</span>](z: <span class=\"type\">A1</span>)(op: (<span class=\"type\">A1</span>, <span class=\"type\">A1</span>) =&gt; <span class=\"type\">A1</span>): <span class=\"type\">A1</span> = foldLeft(z)(op)</div><div class=\"line\"> </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foldLeft</span></span>[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">B</span>, <span class=\"type\">A</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> = &#123;</div><div class=\"line\"> <span class=\"keyword\">var</span> result = z</div><div class=\"line\"> <span class=\"keyword\">this</span>.seq foreach (x =&gt; result = op(result, x))</div><div class=\"line\"> result</div><div class=\"line\"> &#125;</div><div class=\"line\">  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foldRight</span></span>[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">A</span>, <span class=\"type\">B</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> =</div><div class=\"line\">    reversed.foldLeft(z)((x, y) =&gt; op(y, x))</div></pre></td></tr></table></figure></p>\n<p>foldfold</p>\n<ol>\n<li>listList[Int]foldIntList[Int]</li>\n<li>(neutral)01listNil,</li>\n</ol>\n<p>foldLeftfoldRight</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">/</span></span>:[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">B</span>, <span class=\"type\">A</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> = foldLeft(z)(op)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> </span>:\\[<span class=\"type\">B</span>](z: <span class=\"type\">B</span>)(op: (<span class=\"type\">A</span>, <span class=\"type\">B</span>) =&gt; <span class=\"type\">B</span>): <span class=\"type\">B</span> = foldRight(z)(op)</div><div class=\"line\"></div><div class=\"line\">scala&gt; (<span class=\"number\">0</span>/:(<span class=\"number\">1</span> to <span class=\"number\">100</span>))(_+_)  </div><div class=\"line\">res32: <span class=\"type\">Int</span> = <span class=\"number\">5050</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; ((<span class=\"number\">1</span> to <span class=\"number\">100</span>):\\<span class=\"number\">0</span>)(_+_) </div><div class=\"line\">res24: <span class=\"type\">Int</span> = <span class=\"number\">5050</span></div></pre></td></tr></table></figure>\n<p>reduce reducescalareducefold</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">val</span> list = <span class=\"type\">List</span>(<span class=\"string\">\"A\"</span>,<span class=\"string\">\"B\"</span>,<span class=\"string\">\"C\"</span>,<span class=\"string\">\"D\"</span>,<span class=\"string\">\"E\"</span>)</div><div class=\"line\">println(<span class=\"string\">\"reduce (a+b) \"</span>+list.reduce((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (a+b) \"</span>+list.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (b+a) \"</span>+list.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceRight (a+b) \"</span>+list.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceRight (b+a) \"</span>+list.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scan            \"</span>+list.scan(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanLeft (a+b)  \"</span>+list.scanLeft(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanLeft (b+a)  \"</span>+list.scanLeft(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanRight (a+b) \"</span>+list.scanRight(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\">println(<span class=\"string\">\"scanRight (b+a) \"</span>+list.scanRight(<span class=\"string\">\"[\"</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"><span class=\"keyword\">val</span> list1 = <span class=\"type\">List</span>(<span class=\"number\">-2</span>,<span class=\"number\">-1</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduce (a+b) \"</span>+list1.reduce((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (a+b) \"</span>+list1.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"reduceLeft (b+a) \"</span>+list1.reduceLeft((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"      reduceRight (a+b) \"</span>+list1.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"      reduceRight (b+a) \"</span>+list1.reduceRight((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span>)</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scan            \"</span>+list1.scan(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanLeft (a+b)  \"</span>+list1.scanLeft(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanLeft (b+a)  \"</span>+list1.scanLeft(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (b+a)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a</div><div class=\"line\">&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanRight (a+b)         \"</span>+list1.scanRight(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">a+b&#125;))</div><div class=\"line\"></div><div class=\"line\">println(<span class=\"string\">\"scanRight (b+a)         \"</span>+list1.scanRight(<span class=\"number\">0</span>)((a,b)=&gt;&#123;</div><div class=\"line\">print(<span class=\"string\">\"&#123;\"</span>+a+<span class=\"string\">\",\"</span>+b+<span class=\"string\">\"&#125;=&gt;\"</span>+ (a+b)+<span class=\"string\">\"  \"</span> )</div><div class=\"line\">b+a&#125;))</div></pre></td></tr></table></figure>\n<p>reduce fold,</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">AB</span>  &#123;<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">ABC</span>  &#123;<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">ABCD</span>  &#123;<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">ABCDE</span>  reduce (a+b) <span class=\"type\">ABCDE</span></div><div class=\"line\">&#123;<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">AB</span>  &#123;<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">ABC</span>  &#123;<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">ABCD</span>  &#123;<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">ABCDE</span>  reduceLeft (a+b) <span class=\"type\">ABCDE</span></div><div class=\"line\">&#123;<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">BA</span>  &#123;<span class=\"type\">BA</span>,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">CBA</span>  &#123;<span class=\"type\">CBA</span>,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">DCBA</span>  &#123;<span class=\"type\">DCBA</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">EDCBA</span>  reduceLeft (b+a) <span class=\"type\">EDCBA</span></div><div class=\"line\">&#123;<span class=\"type\">D</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">DE</span>  &#123;<span class=\"type\">C</span>,<span class=\"type\">DE</span>&#125;=&gt;<span class=\"type\">CDE</span>  &#123;<span class=\"type\">B</span>,<span class=\"type\">CDE</span>&#125;=&gt;<span class=\"type\">BCDE</span>  &#123;<span class=\"type\">A</span>,<span class=\"type\">BCDE</span>&#125;=&gt;<span class=\"type\">ABCDE</span>  reduceRight (a+b) <span class=\"type\">ABCDE</span></div><div class=\"line\">&#123;<span class=\"type\">D</span>,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">ED</span>  &#123;<span class=\"type\">C</span>,<span class=\"type\">ED</span>&#125;=&gt;<span class=\"type\">EDC</span>  &#123;<span class=\"type\">B</span>,<span class=\"type\">EDC</span>&#125;=&gt;<span class=\"type\">EDCB</span>  &#123;<span class=\"type\">A</span>,<span class=\"type\">EDCB</span>&#125;=&gt;<span class=\"type\">EDCBA</span>  reduceRight (b+a) <span class=\"type\">EDCBA</span></div><div class=\"line\">&#123;[,<span class=\"type\">A</span>&#125;=&gt;[<span class=\"type\">A</span>  &#123;[<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;[<span class=\"type\">AB</span>  &#123;[<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;[<span class=\"type\">ABC</span>  &#123;[<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;[<span class=\"type\">ABCD</span>  &#123;[<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;[<span class=\"type\">ABCDE</span>  scan            <span class=\"type\">List</span>([, [<span class=\"type\">A</span>, [<span class=\"type\">AB</span>, [<span class=\"type\">ABC</span>, [<span class=\"type\">ABCD</span>, [<span class=\"type\">ABCDE</span>)</div><div class=\"line\">&#123;[,<span class=\"type\">A</span>&#125;=&gt;[<span class=\"type\">A</span>  &#123;[<span class=\"type\">A</span>,<span class=\"type\">B</span>&#125;=&gt;[<span class=\"type\">AB</span>  &#123;[<span class=\"type\">AB</span>,<span class=\"type\">C</span>&#125;=&gt;[<span class=\"type\">ABC</span>  &#123;[<span class=\"type\">ABC</span>,<span class=\"type\">D</span>&#125;=&gt;[<span class=\"type\">ABCD</span>  &#123;[<span class=\"type\">ABCD</span>,<span class=\"type\">E</span>&#125;=&gt;[<span class=\"type\">ABCDE</span>  scanLeft (a+b)  <span class=\"type\">List</span>([, [<span class=\"type\">A</span>, [<span class=\"type\">AB</span>, [<span class=\"type\">ABC</span>, [<span class=\"type\">ABCD</span>, [<span class=\"type\">ABCDE</span>)</div><div class=\"line\">&#123;[,<span class=\"type\">A</span>&#125;=&gt;<span class=\"type\">A</span>[  &#123;<span class=\"type\">A</span>[,<span class=\"type\">B</span>&#125;=&gt;<span class=\"type\">BA</span>[  &#123;<span class=\"type\">BA</span>[,<span class=\"type\">C</span>&#125;=&gt;<span class=\"type\">CBA</span>[  &#123;<span class=\"type\">CBA</span>[,<span class=\"type\">D</span>&#125;=&gt;<span class=\"type\">DCBA</span>[  &#123;<span class=\"type\">DCBA</span>[,<span class=\"type\">E</span>&#125;=&gt;<span class=\"type\">EDCBA</span>[  scanLeft (b+a)  <span class=\"type\">List</span>([, <span class=\"type\">A</span>[, <span class=\"type\">BA</span>[, <span class=\"type\">CBA</span>[, <span class=\"type\">DCBA</span>[, <span class=\"type\">EDCBA</span>[)</div><div class=\"line\">&#123;<span class=\"type\">E</span>,[&#125;=&gt;<span class=\"type\">E</span>[  &#123;<span class=\"type\">D</span>,<span class=\"type\">E</span>[&#125;=&gt;<span class=\"type\">DE</span>[  &#123;<span class=\"type\">C</span>,<span class=\"type\">DE</span>[&#125;=&gt;<span class=\"type\">CDE</span>[  &#123;<span class=\"type\">B</span>,<span class=\"type\">CDE</span>[&#125;=&gt;<span class=\"type\">BCDE</span>[  &#123;<span class=\"type\">A</span>,<span class=\"type\">BCDE</span>[&#125;=&gt;<span class=\"type\">ABCDE</span>[  scanRight (a+b) <span class=\"type\">List</span>(<span class=\"type\">ABCDE</span>[, <span class=\"type\">BCDE</span>[, <span class=\"type\">CDE</span>[, <span class=\"type\">DE</span>[, <span class=\"type\">E</span>[, [)</div><div class=\"line\">&#123;<span class=\"type\">E</span>,[&#125;=&gt;[<span class=\"type\">E</span>  &#123;<span class=\"type\">D</span>,[<span class=\"type\">E</span>&#125;=&gt;[<span class=\"type\">ED</span>  &#123;<span class=\"type\">C</span>,[<span class=\"type\">ED</span>&#125;=&gt;[<span class=\"type\">EDC</span>  &#123;<span class=\"type\">B</span>,[<span class=\"type\">EDC</span>&#125;=&gt;[<span class=\"type\">EDCB</span>  &#123;<span class=\"type\">A</span>,[<span class=\"type\">EDCB</span>&#125;=&gt;[<span class=\"type\">EDCBA</span>  scanRight (b+a) <span class=\"type\">List</span>([<span class=\"type\">EDCBA</span>, [<span class=\"type\">EDCB</span>, [<span class=\"type\">EDC</span>, [<span class=\"type\">ED</span>, [<span class=\"type\">E</span>, [)</div><div class=\"line\">&#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  reduce (a+b) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  reduceLeft (a+b) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  reduceLeft (b+a) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>        reduceRight (a+b) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>        reduceRight (b+a) <span class=\"number\">0</span></div><div class=\"line\">&#123;<span class=\"number\">0</span>,<span class=\"number\">-2</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scan            <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">-2</span>, <span class=\"number\">-3</span>, <span class=\"number\">-3</span>, <span class=\"number\">-2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">0</span>,<span class=\"number\">-2</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanLeft (a+b)  <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">-2</span>, <span class=\"number\">-3</span>, <span class=\"number\">-3</span>, <span class=\"number\">-2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">0</span>,<span class=\"number\">-2</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">-1</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">-3</span>  &#123;<span class=\"number\">-3</span>,<span class=\"number\">1</span>&#125;=&gt;<span class=\"number\">-2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanLeft (b+a)  <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">-2</span>, <span class=\"number\">-3</span>, <span class=\"number\">-3</span>, <span class=\"number\">-2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">2</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanRight (a+b)         <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)</div><div class=\"line\">&#123;<span class=\"number\">2</span>,<span class=\"number\">0</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">0</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">3</span>  &#123;<span class=\"number\">-1</span>,<span class=\"number\">3</span>&#125;=&gt;<span class=\"number\">2</span>  &#123;<span class=\"number\">-2</span>,<span class=\"number\">2</span>&#125;=&gt;<span class=\"number\">0</span>  scanRight (b+a)         <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)</div></pre></td></tr></table></figure>"},{"title":"Scala 3mapflatMapzipreduce","date":"2017-08-30T23:27:05.000Z","_content":"\nmapflatMapzipreducescalaOption\n<!--more -->\nmapmap\n\n```scala\nscala> list1\nres3: List[Int] = List(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nscala> list1.map(x=>x*x)\nres4: List[Int] = List(0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100)\n```\nOption\n```scala\nscala> val evenify = (x:Int) => if (x % 2 == 0) Some(x) else None\nevenify: Int => Option[Int] = <function1>\n\nscala> list1.map(evenify)\nres6: List[Option[Int]] = List(Some(0), None, Some(2), None, Some(4), None, Some(6), None, Some(8), None, Some(10))\n```\nNoneflatMapflatMap\n```scala\nscala> val list3 = 10 to 20 toList\nlist3: List[Int] = List(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\nscala> val list2 = 1 to 10 toList\nlist2: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nscala> val list4 = List(list2, list3)\nlist4: List[List[Int]] = List(List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), List(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20))\n\nscala> list4.flatMap(x=>x.map(y=>y*2))\nres2: List[Int] = List(2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40) \n```\nlist4flatMapmap\n\nflatMapGenTraversableOnce\n```scala\nscala> List(1,2,3,4,5)\nres0: List[Int] = List(1, 2, 3, 4, 5)\n\nscala> res0.flatMap(x => 1 to x )\nres1: List[Int] = List(1, 1, 2, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5)\n```\nevenifyOption\n```scala\nscala> val list1 = 1 to 10 toList\nlist1: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nscala> list1.map(evenify)\nres3: List[Option[Int]] = List(None, Some(2), None, Some(4), None, Some(6), None, Some(8), None, Some(10))\n\nscala> val list2 = list1.map(evenify)\nlist2: List[Option[Int]] = List(None, Some(2), None, Some(4), None, Some(6), None, Some(8), None, Some(10))\n\nscala> list2.flatMap(x => x)\nres6: List[Int] = List(2, 4, 6, 8, 10)  \n```\n\n```scala\nscala> list1.flatMap(x=>evenify(x))\nres14: List[Int] = List(2, 4, 6, 8, 10)\n```\nzip\n```scala\nscala> val list = \"Hello.World\".toCharArray\nlist: Array[Char] = Array(H, e, l, l, o, ., W, o, r, l, d)\n\nscala> val list1 = 1 to 20 toList\nlist1: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\nscala> list.zip(list1)\nres30: Array[(Char, Int)] = Array((H,1), (e,2), (l,3), (l,4), (o,5), (.,6), (W,7), (o,8), (r,9), (l,10), (d,11))\n\nscala> list1.zip(list)\nres31: List[(Int, Char)] = List((1,H), (2,e), (3,l), (4,l), (5,o), (6,.), (7,W), (8,o), (9,r), (10,l), (11,d))\n```\nzipzipAll\n```scala\nscala> list.zipAll(list1,'a','1')\nres33: Array[(Char, AnyVal)] = Array((H,1), (e,2), (l,3), (l,4), (o,5), (.,6), (W,7), (o,8), (r,9), (l,10), (d,11), (a,12), (a,13), (a,14), (a,15), (a,16), (a,17), (a,18), (a,19), (a,20))\n```\n(1Array[(Char,Int)])  \n'a'1zipzipWithIndex0\n```scala\nscala> list.zipWithIndex\nres36: Array[(Char, Int)] = Array((H,0), (e,1), (l,2), (l,3), (o,4), (.,5), (W,6), (o,7), (r,8), (l,9), (d,10))  \n```\nreducereducereduceLeftreduceRightreduce\nreducefoldreducefoldfoldreducefold\n```scala\nscala> list1\nres51: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\nscala> val sum = (x:Int, y:Int) => {println(x,y) ; x + y}\nsum: (Int, Int) => Int = <function2>\n\nscala> list1.reduce(sum)\n(1,2)\n(3,3)\n(6,4)\n(10,5)\n(15,6)\n(21,7)\n(28,8)\n(36,9)\n(45,10)\n(55,11)\n(66,12)\n(78,13)\n(91,14)\n(105,15)\n(120,16)\n(136,17)\n(153,18)\n(171,19)\n(190,20)\nres52: Int = 210\n\nscala> list1.reduceLeft(sum)\n(1,2)\n(3,3)\n(6,4)\n(10,5)\n(15,6)\n(21,7)\n(28,8)\n(36,9)\n(45,10)\n(55,11)\n(66,12)\n(78,13)\n(91,14)\n(105,15)\n(120,16)\n(136,17)\n(153,18)\n(171,19)\n(190,20)\nres53: Int = 210\n\nscala> list1.reduceRight(sum)\n(19,20)\n(18,39)\n(17,57)\n(16,74)\n(15,90)\n(14,105)\n(13,119)\n(12,132)\n(11,144)\n(10,155)\n(9,165)\n(8,174)\n(7,182)\n(6,189)\n(5,195)\n(4,200)\n(3,204)\n(2,207)\n(1,209)\nres54: Int = 210\n```\nList/CollectionsAPIScalaz\n","source":"_posts/scalab-md.md","raw":"---\ntitle: Scala 3mapflatMapzipreduce\ndate: 2017-08-31 07:27:05\ntags: scala\n---\n\nmapflatMapzipreducescalaOption\n<!--more -->\nmapmap\n\n```scala\nscala> list1\nres3: List[Int] = List(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nscala> list1.map(x=>x*x)\nres4: List[Int] = List(0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100)\n```\nOption\n```scala\nscala> val evenify = (x:Int) => if (x % 2 == 0) Some(x) else None\nevenify: Int => Option[Int] = <function1>\n\nscala> list1.map(evenify)\nres6: List[Option[Int]] = List(Some(0), None, Some(2), None, Some(4), None, Some(6), None, Some(8), None, Some(10))\n```\nNoneflatMapflatMap\n```scala\nscala> val list3 = 10 to 20 toList\nlist3: List[Int] = List(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\nscala> val list2 = 1 to 10 toList\nlist2: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nscala> val list4 = List(list2, list3)\nlist4: List[List[Int]] = List(List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), List(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20))\n\nscala> list4.flatMap(x=>x.map(y=>y*2))\nres2: List[Int] = List(2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40) \n```\nlist4flatMapmap\n\nflatMapGenTraversableOnce\n```scala\nscala> List(1,2,3,4,5)\nres0: List[Int] = List(1, 2, 3, 4, 5)\n\nscala> res0.flatMap(x => 1 to x )\nres1: List[Int] = List(1, 1, 2, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5)\n```\nevenifyOption\n```scala\nscala> val list1 = 1 to 10 toList\nlist1: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nscala> list1.map(evenify)\nres3: List[Option[Int]] = List(None, Some(2), None, Some(4), None, Some(6), None, Some(8), None, Some(10))\n\nscala> val list2 = list1.map(evenify)\nlist2: List[Option[Int]] = List(None, Some(2), None, Some(4), None, Some(6), None, Some(8), None, Some(10))\n\nscala> list2.flatMap(x => x)\nres6: List[Int] = List(2, 4, 6, 8, 10)  \n```\n\n```scala\nscala> list1.flatMap(x=>evenify(x))\nres14: List[Int] = List(2, 4, 6, 8, 10)\n```\nzip\n```scala\nscala> val list = \"Hello.World\".toCharArray\nlist: Array[Char] = Array(H, e, l, l, o, ., W, o, r, l, d)\n\nscala> val list1 = 1 to 20 toList\nlist1: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\nscala> list.zip(list1)\nres30: Array[(Char, Int)] = Array((H,1), (e,2), (l,3), (l,4), (o,5), (.,6), (W,7), (o,8), (r,9), (l,10), (d,11))\n\nscala> list1.zip(list)\nres31: List[(Int, Char)] = List((1,H), (2,e), (3,l), (4,l), (5,o), (6,.), (7,W), (8,o), (9,r), (10,l), (11,d))\n```\nzipzipAll\n```scala\nscala> list.zipAll(list1,'a','1')\nres33: Array[(Char, AnyVal)] = Array((H,1), (e,2), (l,3), (l,4), (o,5), (.,6), (W,7), (o,8), (r,9), (l,10), (d,11), (a,12), (a,13), (a,14), (a,15), (a,16), (a,17), (a,18), (a,19), (a,20))\n```\n(1Array[(Char,Int)])  \n'a'1zipzipWithIndex0\n```scala\nscala> list.zipWithIndex\nres36: Array[(Char, Int)] = Array((H,0), (e,1), (l,2), (l,3), (o,4), (.,5), (W,6), (o,7), (r,8), (l,9), (d,10))  \n```\nreducereducereduceLeftreduceRightreduce\nreducefoldreducefoldfoldreducefold\n```scala\nscala> list1\nres51: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\nscala> val sum = (x:Int, y:Int) => {println(x,y) ; x + y}\nsum: (Int, Int) => Int = <function2>\n\nscala> list1.reduce(sum)\n(1,2)\n(3,3)\n(6,4)\n(10,5)\n(15,6)\n(21,7)\n(28,8)\n(36,9)\n(45,10)\n(55,11)\n(66,12)\n(78,13)\n(91,14)\n(105,15)\n(120,16)\n(136,17)\n(153,18)\n(171,19)\n(190,20)\nres52: Int = 210\n\nscala> list1.reduceLeft(sum)\n(1,2)\n(3,3)\n(6,4)\n(10,5)\n(15,6)\n(21,7)\n(28,8)\n(36,9)\n(45,10)\n(55,11)\n(66,12)\n(78,13)\n(91,14)\n(105,15)\n(120,16)\n(136,17)\n(153,18)\n(171,19)\n(190,20)\nres53: Int = 210\n\nscala> list1.reduceRight(sum)\n(19,20)\n(18,39)\n(17,57)\n(16,74)\n(15,90)\n(14,105)\n(13,119)\n(12,132)\n(11,144)\n(10,155)\n(9,165)\n(8,174)\n(7,182)\n(6,189)\n(5,195)\n(4,200)\n(3,204)\n(2,207)\n(1,209)\nres54: Int = 210\n```\nList/CollectionsAPIScalaz\n","slug":"scalab-md","published":1,"updated":"2017-08-30T23:34:57.748Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0qm000w60tusjmyn6zp","content":"<p>mapflatMapzipreducescalaOption<br><a id=\"more\"></a><br>mapmap<br><br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list1</div><div class=\"line\">res3: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.map(x=&gt;x*x)</div><div class=\"line\">res4: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">9</span>, <span class=\"number\">16</span>, <span class=\"number\">25</span>, <span class=\"number\">36</span>, <span class=\"number\">49</span>, <span class=\"number\">64</span>, <span class=\"number\">81</span>, <span class=\"number\">100</span>)</div></pre></td></tr></table></figure></p>\n<p>Option<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> evenify = (x:<span class=\"type\">Int</span>) =&gt; <span class=\"keyword\">if</span> (x % <span class=\"number\">2</span> == <span class=\"number\">0</span>) <span class=\"type\">Some</span>(x) <span class=\"keyword\">else</span> <span class=\"type\">None</span></div><div class=\"line\">evenify: <span class=\"type\">Int</span> =&gt; <span class=\"type\">Option</span>[<span class=\"type\">Int</span>] = &lt;function1&gt;</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.map(evenify)</div><div class=\"line\">res6: <span class=\"type\">List</span>[<span class=\"type\">Option</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">Some</span>(<span class=\"number\">0</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">2</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">4</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">6</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">8</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">10</span>))</div></pre></td></tr></table></figure></p>\n<p>NoneflatMapflatMap<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list3 = <span class=\"number\">10</span> to <span class=\"number\">20</span> toList</div><div class=\"line\">list3: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list2 = <span class=\"number\">1</span> to <span class=\"number\">10</span> toList</div><div class=\"line\">list2: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list4 = <span class=\"type\">List</span>(list2, list3)</div><div class=\"line\">list4: <span class=\"type\">List</span>[<span class=\"type\">List</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>), <span class=\"type\">List</span>(<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; list4.flatMap(x=&gt;x.map(y=&gt;y*<span class=\"number\">2</span>))</div><div class=\"line\">res2: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>, <span class=\"number\">12</span>, <span class=\"number\">14</span>, <span class=\"number\">16</span>, <span class=\"number\">18</span>, <span class=\"number\">20</span>, <span class=\"number\">20</span>, <span class=\"number\">22</span>, <span class=\"number\">24</span>, <span class=\"number\">26</span>, <span class=\"number\">28</span>, <span class=\"number\">30</span>, <span class=\"number\">32</span>, <span class=\"number\">34</span>, <span class=\"number\">36</span>, <span class=\"number\">38</span>, <span class=\"number\">40</span>)</div></pre></td></tr></table></figure></p>\n<p>list4flatMapmap</p>\n<p>flatMapGenTraversableOnce<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"type\">List</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>)</div><div class=\"line\">res0: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; res0.flatMap(x =&gt; <span class=\"number\">1</span> to x )</div><div class=\"line\">res1: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</div></pre></td></tr></table></figure></p>\n<p>evenifyOption<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list1 = <span class=\"number\">1</span> to <span class=\"number\">10</span> toList</div><div class=\"line\">list1: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.map(evenify)</div><div class=\"line\">res3: <span class=\"type\">List</span>[<span class=\"type\">Option</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">2</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">4</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">6</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">8</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">10</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list2 = list1.map(evenify)</div><div class=\"line\">list2: <span class=\"type\">List</span>[<span class=\"type\">Option</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">2</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">4</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">6</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">8</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">10</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; list2.flatMap(x =&gt; x)</div><div class=\"line\">res6: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>)</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list1.flatMap(x=&gt;evenify(x))</div><div class=\"line\">res14: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>)</div></pre></td></tr></table></figure></p>\n<p>zip<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list = <span class=\"string\">\"Hello.World\"</span>.toCharArray</div><div class=\"line\">list: <span class=\"type\">Array</span>[<span class=\"type\">Char</span>] = <span class=\"type\">Array</span>(<span class=\"type\">H</span>, e, l, l, o, ., <span class=\"type\">W</span>, o, r, l, d)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list1 = <span class=\"number\">1</span> to <span class=\"number\">20</span> toList</div><div class=\"line\">list1: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; list.zip(list1)</div><div class=\"line\">res30: <span class=\"type\">Array</span>[(<span class=\"type\">Char</span>, <span class=\"type\">Int</span>)] = <span class=\"type\">Array</span>((<span class=\"type\">H</span>,<span class=\"number\">1</span>), (e,<span class=\"number\">2</span>), (l,<span class=\"number\">3</span>), (l,<span class=\"number\">4</span>), (o,<span class=\"number\">5</span>), (.,<span class=\"number\">6</span>), (<span class=\"type\">W</span>,<span class=\"number\">7</span>), (o,<span class=\"number\">8</span>), (r,<span class=\"number\">9</span>), (l,<span class=\"number\">10</span>), (d,<span class=\"number\">11</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.zip(list)</div><div class=\"line\">res31: <span class=\"type\">List</span>[(<span class=\"type\">Int</span>, <span class=\"type\">Char</span>)] = <span class=\"type\">List</span>((<span class=\"number\">1</span>,<span class=\"type\">H</span>), (<span class=\"number\">2</span>,e), (<span class=\"number\">3</span>,l), (<span class=\"number\">4</span>,l), (<span class=\"number\">5</span>,o), (<span class=\"number\">6</span>,.), (<span class=\"number\">7</span>,<span class=\"type\">W</span>), (<span class=\"number\">8</span>,o), (<span class=\"number\">9</span>,r), (<span class=\"number\">10</span>,l), (<span class=\"number\">11</span>,d))</div></pre></td></tr></table></figure></p>\n<p>zipzipAll<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list.zipAll(list1,'a','<span class=\"number\">1</span>')</div><div class=\"line\">res33: <span class=\"type\">Array</span>[(<span class=\"type\">Char</span>, <span class=\"type\">AnyVal</span>)] = <span class=\"type\">Array</span>((<span class=\"type\">H</span>,<span class=\"number\">1</span>), (e,<span class=\"number\">2</span>), (l,<span class=\"number\">3</span>), (l,<span class=\"number\">4</span>), (o,<span class=\"number\">5</span>), (.,<span class=\"number\">6</span>), (<span class=\"type\">W</span>,<span class=\"number\">7</span>), (o,<span class=\"number\">8</span>), (r,<span class=\"number\">9</span>), (l,<span class=\"number\">10</span>), (d,<span class=\"number\">11</span>), (a,<span class=\"number\">12</span>), (a,<span class=\"number\">13</span>), (a,<span class=\"number\">14</span>), (a,<span class=\"number\">15</span>), (a,<span class=\"number\">16</span>), (a,<span class=\"number\">17</span>), (a,<span class=\"number\">18</span>), (a,<span class=\"number\">19</span>), (a,<span class=\"number\">20</span>))</div></pre></td></tr></table></figure></p>\n<p>(1Array[(Char,Int)])<br>a1zipzipWithIndex0<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list.zipWithIndex</div><div class=\"line\">res36: <span class=\"type\">Array</span>[(<span class=\"type\">Char</span>, <span class=\"type\">Int</span>)] = <span class=\"type\">Array</span>((<span class=\"type\">H</span>,<span class=\"number\">0</span>), (e,<span class=\"number\">1</span>), (l,<span class=\"number\">2</span>), (l,<span class=\"number\">3</span>), (o,<span class=\"number\">4</span>), (.,<span class=\"number\">5</span>), (<span class=\"type\">W</span>,<span class=\"number\">6</span>), (o,<span class=\"number\">7</span>), (r,<span class=\"number\">8</span>), (l,<span class=\"number\">9</span>), (d,<span class=\"number\">10</span>))</div></pre></td></tr></table></figure></p>\n<p>reducereducereduceLeftreduceRightreduce<br>reducefoldreducefoldfoldreducefold<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list1</div><div class=\"line\">res51: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> sum = (x:<span class=\"type\">Int</span>, y:<span class=\"type\">Int</span>) =&gt; &#123;println(x,y) ; x + y&#125;</div><div class=\"line\">sum: (<span class=\"type\">Int</span>, <span class=\"type\">Int</span>) =&gt; <span class=\"type\">Int</span> = &lt;function2&gt;</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.reduce(sum)</div><div class=\"line\">(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</div><div class=\"line\">(<span class=\"number\">3</span>,<span class=\"number\">3</span>)</div><div class=\"line\">(<span class=\"number\">6</span>,<span class=\"number\">4</span>)</div><div class=\"line\">(<span class=\"number\">10</span>,<span class=\"number\">5</span>)</div><div class=\"line\">(<span class=\"number\">15</span>,<span class=\"number\">6</span>)</div><div class=\"line\">(<span class=\"number\">21</span>,<span class=\"number\">7</span>)</div><div class=\"line\">(<span class=\"number\">28</span>,<span class=\"number\">8</span>)</div><div class=\"line\">(<span class=\"number\">36</span>,<span class=\"number\">9</span>)</div><div class=\"line\">(<span class=\"number\">45</span>,<span class=\"number\">10</span>)</div><div class=\"line\">(<span class=\"number\">55</span>,<span class=\"number\">11</span>)</div><div class=\"line\">(<span class=\"number\">66</span>,<span class=\"number\">12</span>)</div><div class=\"line\">(<span class=\"number\">78</span>,<span class=\"number\">13</span>)</div><div class=\"line\">(<span class=\"number\">91</span>,<span class=\"number\">14</span>)</div><div class=\"line\">(<span class=\"number\">105</span>,<span class=\"number\">15</span>)</div><div class=\"line\">(<span class=\"number\">120</span>,<span class=\"number\">16</span>)</div><div class=\"line\">(<span class=\"number\">136</span>,<span class=\"number\">17</span>)</div><div class=\"line\">(<span class=\"number\">153</span>,<span class=\"number\">18</span>)</div><div class=\"line\">(<span class=\"number\">171</span>,<span class=\"number\">19</span>)</div><div class=\"line\">(<span class=\"number\">190</span>,<span class=\"number\">20</span>)</div><div class=\"line\">res52: <span class=\"type\">Int</span> = <span class=\"number\">210</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.reduceLeft(sum)</div><div class=\"line\">(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</div><div class=\"line\">(<span class=\"number\">3</span>,<span class=\"number\">3</span>)</div><div class=\"line\">(<span class=\"number\">6</span>,<span class=\"number\">4</span>)</div><div class=\"line\">(<span class=\"number\">10</span>,<span class=\"number\">5</span>)</div><div class=\"line\">(<span class=\"number\">15</span>,<span class=\"number\">6</span>)</div><div class=\"line\">(<span class=\"number\">21</span>,<span class=\"number\">7</span>)</div><div class=\"line\">(<span class=\"number\">28</span>,<span class=\"number\">8</span>)</div><div class=\"line\">(<span class=\"number\">36</span>,<span class=\"number\">9</span>)</div><div class=\"line\">(<span class=\"number\">45</span>,<span class=\"number\">10</span>)</div><div class=\"line\">(<span class=\"number\">55</span>,<span class=\"number\">11</span>)</div><div class=\"line\">(<span class=\"number\">66</span>,<span class=\"number\">12</span>)</div><div class=\"line\">(<span class=\"number\">78</span>,<span class=\"number\">13</span>)</div><div class=\"line\">(<span class=\"number\">91</span>,<span class=\"number\">14</span>)</div><div class=\"line\">(<span class=\"number\">105</span>,<span class=\"number\">15</span>)</div><div class=\"line\">(<span class=\"number\">120</span>,<span class=\"number\">16</span>)</div><div class=\"line\">(<span class=\"number\">136</span>,<span class=\"number\">17</span>)</div><div class=\"line\">(<span class=\"number\">153</span>,<span class=\"number\">18</span>)</div><div class=\"line\">(<span class=\"number\">171</span>,<span class=\"number\">19</span>)</div><div class=\"line\">(<span class=\"number\">190</span>,<span class=\"number\">20</span>)</div><div class=\"line\">res53: <span class=\"type\">Int</span> = <span class=\"number\">210</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.reduceRight(sum)</div><div class=\"line\">(<span class=\"number\">19</span>,<span class=\"number\">20</span>)</div><div class=\"line\">(<span class=\"number\">18</span>,<span class=\"number\">39</span>)</div><div class=\"line\">(<span class=\"number\">17</span>,<span class=\"number\">57</span>)</div><div class=\"line\">(<span class=\"number\">16</span>,<span class=\"number\">74</span>)</div><div class=\"line\">(<span class=\"number\">15</span>,<span class=\"number\">90</span>)</div><div class=\"line\">(<span class=\"number\">14</span>,<span class=\"number\">105</span>)</div><div class=\"line\">(<span class=\"number\">13</span>,<span class=\"number\">119</span>)</div><div class=\"line\">(<span class=\"number\">12</span>,<span class=\"number\">132</span>)</div><div class=\"line\">(<span class=\"number\">11</span>,<span class=\"number\">144</span>)</div><div class=\"line\">(<span class=\"number\">10</span>,<span class=\"number\">155</span>)</div><div class=\"line\">(<span class=\"number\">9</span>,<span class=\"number\">165</span>)</div><div class=\"line\">(<span class=\"number\">8</span>,<span class=\"number\">174</span>)</div><div class=\"line\">(<span class=\"number\">7</span>,<span class=\"number\">182</span>)</div><div class=\"line\">(<span class=\"number\">6</span>,<span class=\"number\">189</span>)</div><div class=\"line\">(<span class=\"number\">5</span>,<span class=\"number\">195</span>)</div><div class=\"line\">(<span class=\"number\">4</span>,<span class=\"number\">200</span>)</div><div class=\"line\">(<span class=\"number\">3</span>,<span class=\"number\">204</span>)</div><div class=\"line\">(<span class=\"number\">2</span>,<span class=\"number\">207</span>)</div><div class=\"line\">(<span class=\"number\">1</span>,<span class=\"number\">209</span>)</div><div class=\"line\">res54: <span class=\"type\">Int</span> = <span class=\"number\">210</span></div></pre></td></tr></table></figure></p>\n<p>List/CollectionsAPIScalaz</p>\n","excerpt":"<p>mapflatMapzipreducescalaOption<br>","more":"<br>mapmap<br><br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list1</div><div class=\"line\">res3: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.map(x=&gt;x*x)</div><div class=\"line\">res4: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">9</span>, <span class=\"number\">16</span>, <span class=\"number\">25</span>, <span class=\"number\">36</span>, <span class=\"number\">49</span>, <span class=\"number\">64</span>, <span class=\"number\">81</span>, <span class=\"number\">100</span>)</div></pre></td></tr></table></figure></p>\n<p>Option<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> evenify = (x:<span class=\"type\">Int</span>) =&gt; <span class=\"keyword\">if</span> (x % <span class=\"number\">2</span> == <span class=\"number\">0</span>) <span class=\"type\">Some</span>(x) <span class=\"keyword\">else</span> <span class=\"type\">None</span></div><div class=\"line\">evenify: <span class=\"type\">Int</span> =&gt; <span class=\"type\">Option</span>[<span class=\"type\">Int</span>] = &lt;function1&gt;</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.map(evenify)</div><div class=\"line\">res6: <span class=\"type\">List</span>[<span class=\"type\">Option</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">Some</span>(<span class=\"number\">0</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">2</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">4</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">6</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">8</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">10</span>))</div></pre></td></tr></table></figure></p>\n<p>NoneflatMapflatMap<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list3 = <span class=\"number\">10</span> to <span class=\"number\">20</span> toList</div><div class=\"line\">list3: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list2 = <span class=\"number\">1</span> to <span class=\"number\">10</span> toList</div><div class=\"line\">list2: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list4 = <span class=\"type\">List</span>(list2, list3)</div><div class=\"line\">list4: <span class=\"type\">List</span>[<span class=\"type\">List</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>), <span class=\"type\">List</span>(<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; list4.flatMap(x=&gt;x.map(y=&gt;y*<span class=\"number\">2</span>))</div><div class=\"line\">res2: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>, <span class=\"number\">12</span>, <span class=\"number\">14</span>, <span class=\"number\">16</span>, <span class=\"number\">18</span>, <span class=\"number\">20</span>, <span class=\"number\">20</span>, <span class=\"number\">22</span>, <span class=\"number\">24</span>, <span class=\"number\">26</span>, <span class=\"number\">28</span>, <span class=\"number\">30</span>, <span class=\"number\">32</span>, <span class=\"number\">34</span>, <span class=\"number\">36</span>, <span class=\"number\">38</span>, <span class=\"number\">40</span>)</div></pre></td></tr></table></figure></p>\n<p>list4flatMapmap</p>\n<p>flatMapGenTraversableOnce<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"type\">List</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>)</div><div class=\"line\">res0: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; res0.flatMap(x =&gt; <span class=\"number\">1</span> to x )</div><div class=\"line\">res1: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</div></pre></td></tr></table></figure></p>\n<p>evenifyOption<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list1 = <span class=\"number\">1</span> to <span class=\"number\">10</span> toList</div><div class=\"line\">list1: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.map(evenify)</div><div class=\"line\">res3: <span class=\"type\">List</span>[<span class=\"type\">Option</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">2</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">4</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">6</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">8</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">10</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list2 = list1.map(evenify)</div><div class=\"line\">list2: <span class=\"type\">List</span>[<span class=\"type\">Option</span>[<span class=\"type\">Int</span>]] = <span class=\"type\">List</span>(<span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">2</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">4</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">6</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">8</span>), <span class=\"type\">None</span>, <span class=\"type\">Some</span>(<span class=\"number\">10</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; list2.flatMap(x =&gt; x)</div><div class=\"line\">res6: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>)</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list1.flatMap(x=&gt;evenify(x))</div><div class=\"line\">res14: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>)</div></pre></td></tr></table></figure></p>\n<p>zip<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list = <span class=\"string\">\"Hello.World\"</span>.toCharArray</div><div class=\"line\">list: <span class=\"type\">Array</span>[<span class=\"type\">Char</span>] = <span class=\"type\">Array</span>(<span class=\"type\">H</span>, e, l, l, o, ., <span class=\"type\">W</span>, o, r, l, d)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> list1 = <span class=\"number\">1</span> to <span class=\"number\">20</span> toList</div><div class=\"line\">list1: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; list.zip(list1)</div><div class=\"line\">res30: <span class=\"type\">Array</span>[(<span class=\"type\">Char</span>, <span class=\"type\">Int</span>)] = <span class=\"type\">Array</span>((<span class=\"type\">H</span>,<span class=\"number\">1</span>), (e,<span class=\"number\">2</span>), (l,<span class=\"number\">3</span>), (l,<span class=\"number\">4</span>), (o,<span class=\"number\">5</span>), (.,<span class=\"number\">6</span>), (<span class=\"type\">W</span>,<span class=\"number\">7</span>), (o,<span class=\"number\">8</span>), (r,<span class=\"number\">9</span>), (l,<span class=\"number\">10</span>), (d,<span class=\"number\">11</span>))</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.zip(list)</div><div class=\"line\">res31: <span class=\"type\">List</span>[(<span class=\"type\">Int</span>, <span class=\"type\">Char</span>)] = <span class=\"type\">List</span>((<span class=\"number\">1</span>,<span class=\"type\">H</span>), (<span class=\"number\">2</span>,e), (<span class=\"number\">3</span>,l), (<span class=\"number\">4</span>,l), (<span class=\"number\">5</span>,o), (<span class=\"number\">6</span>,.), (<span class=\"number\">7</span>,<span class=\"type\">W</span>), (<span class=\"number\">8</span>,o), (<span class=\"number\">9</span>,r), (<span class=\"number\">10</span>,l), (<span class=\"number\">11</span>,d))</div></pre></td></tr></table></figure></p>\n<p>zipzipAll<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list.zipAll(list1,'a','<span class=\"number\">1</span>')</div><div class=\"line\">res33: <span class=\"type\">Array</span>[(<span class=\"type\">Char</span>, <span class=\"type\">AnyVal</span>)] = <span class=\"type\">Array</span>((<span class=\"type\">H</span>,<span class=\"number\">1</span>), (e,<span class=\"number\">2</span>), (l,<span class=\"number\">3</span>), (l,<span class=\"number\">4</span>), (o,<span class=\"number\">5</span>), (.,<span class=\"number\">6</span>), (<span class=\"type\">W</span>,<span class=\"number\">7</span>), (o,<span class=\"number\">8</span>), (r,<span class=\"number\">9</span>), (l,<span class=\"number\">10</span>), (d,<span class=\"number\">11</span>), (a,<span class=\"number\">12</span>), (a,<span class=\"number\">13</span>), (a,<span class=\"number\">14</span>), (a,<span class=\"number\">15</span>), (a,<span class=\"number\">16</span>), (a,<span class=\"number\">17</span>), (a,<span class=\"number\">18</span>), (a,<span class=\"number\">19</span>), (a,<span class=\"number\">20</span>))</div></pre></td></tr></table></figure></p>\n<p>(1Array[(Char,Int)])<br>a1zipzipWithIndex0<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list.zipWithIndex</div><div class=\"line\">res36: <span class=\"type\">Array</span>[(<span class=\"type\">Char</span>, <span class=\"type\">Int</span>)] = <span class=\"type\">Array</span>((<span class=\"type\">H</span>,<span class=\"number\">0</span>), (e,<span class=\"number\">1</span>), (l,<span class=\"number\">2</span>), (l,<span class=\"number\">3</span>), (o,<span class=\"number\">4</span>), (.,<span class=\"number\">5</span>), (<span class=\"type\">W</span>,<span class=\"number\">6</span>), (o,<span class=\"number\">7</span>), (r,<span class=\"number\">8</span>), (l,<span class=\"number\">9</span>), (d,<span class=\"number\">10</span>))</div></pre></td></tr></table></figure></p>\n<p>reducereducereduceLeftreduceRightreduce<br>reducefoldreducefoldfoldreducefold<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div></pre></td><td class=\"code\"><pre><div class=\"line\">scala&gt; list1</div><div class=\"line\">res51: <span class=\"type\">List</span>[<span class=\"type\">Int</span>] = <span class=\"type\">List</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>, <span class=\"number\">13</span>, <span class=\"number\">14</span>, <span class=\"number\">15</span>, <span class=\"number\">16</span>, <span class=\"number\">17</span>, <span class=\"number\">18</span>, <span class=\"number\">19</span>, <span class=\"number\">20</span>)</div><div class=\"line\"></div><div class=\"line\">scala&gt; <span class=\"keyword\">val</span> sum = (x:<span class=\"type\">Int</span>, y:<span class=\"type\">Int</span>) =&gt; &#123;println(x,y) ; x + y&#125;</div><div class=\"line\">sum: (<span class=\"type\">Int</span>, <span class=\"type\">Int</span>) =&gt; <span class=\"type\">Int</span> = &lt;function2&gt;</div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.reduce(sum)</div><div class=\"line\">(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</div><div class=\"line\">(<span class=\"number\">3</span>,<span class=\"number\">3</span>)</div><div class=\"line\">(<span class=\"number\">6</span>,<span class=\"number\">4</span>)</div><div class=\"line\">(<span class=\"number\">10</span>,<span class=\"number\">5</span>)</div><div class=\"line\">(<span class=\"number\">15</span>,<span class=\"number\">6</span>)</div><div class=\"line\">(<span class=\"number\">21</span>,<span class=\"number\">7</span>)</div><div class=\"line\">(<span class=\"number\">28</span>,<span class=\"number\">8</span>)</div><div class=\"line\">(<span class=\"number\">36</span>,<span class=\"number\">9</span>)</div><div class=\"line\">(<span class=\"number\">45</span>,<span class=\"number\">10</span>)</div><div class=\"line\">(<span class=\"number\">55</span>,<span class=\"number\">11</span>)</div><div class=\"line\">(<span class=\"number\">66</span>,<span class=\"number\">12</span>)</div><div class=\"line\">(<span class=\"number\">78</span>,<span class=\"number\">13</span>)</div><div class=\"line\">(<span class=\"number\">91</span>,<span class=\"number\">14</span>)</div><div class=\"line\">(<span class=\"number\">105</span>,<span class=\"number\">15</span>)</div><div class=\"line\">(<span class=\"number\">120</span>,<span class=\"number\">16</span>)</div><div class=\"line\">(<span class=\"number\">136</span>,<span class=\"number\">17</span>)</div><div class=\"line\">(<span class=\"number\">153</span>,<span class=\"number\">18</span>)</div><div class=\"line\">(<span class=\"number\">171</span>,<span class=\"number\">19</span>)</div><div class=\"line\">(<span class=\"number\">190</span>,<span class=\"number\">20</span>)</div><div class=\"line\">res52: <span class=\"type\">Int</span> = <span class=\"number\">210</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.reduceLeft(sum)</div><div class=\"line\">(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</div><div class=\"line\">(<span class=\"number\">3</span>,<span class=\"number\">3</span>)</div><div class=\"line\">(<span class=\"number\">6</span>,<span class=\"number\">4</span>)</div><div class=\"line\">(<span class=\"number\">10</span>,<span class=\"number\">5</span>)</div><div class=\"line\">(<span class=\"number\">15</span>,<span class=\"number\">6</span>)</div><div class=\"line\">(<span class=\"number\">21</span>,<span class=\"number\">7</span>)</div><div class=\"line\">(<span class=\"number\">28</span>,<span class=\"number\">8</span>)</div><div class=\"line\">(<span class=\"number\">36</span>,<span class=\"number\">9</span>)</div><div class=\"line\">(<span class=\"number\">45</span>,<span class=\"number\">10</span>)</div><div class=\"line\">(<span class=\"number\">55</span>,<span class=\"number\">11</span>)</div><div class=\"line\">(<span class=\"number\">66</span>,<span class=\"number\">12</span>)</div><div class=\"line\">(<span class=\"number\">78</span>,<span class=\"number\">13</span>)</div><div class=\"line\">(<span class=\"number\">91</span>,<span class=\"number\">14</span>)</div><div class=\"line\">(<span class=\"number\">105</span>,<span class=\"number\">15</span>)</div><div class=\"line\">(<span class=\"number\">120</span>,<span class=\"number\">16</span>)</div><div class=\"line\">(<span class=\"number\">136</span>,<span class=\"number\">17</span>)</div><div class=\"line\">(<span class=\"number\">153</span>,<span class=\"number\">18</span>)</div><div class=\"line\">(<span class=\"number\">171</span>,<span class=\"number\">19</span>)</div><div class=\"line\">(<span class=\"number\">190</span>,<span class=\"number\">20</span>)</div><div class=\"line\">res53: <span class=\"type\">Int</span> = <span class=\"number\">210</span></div><div class=\"line\"></div><div class=\"line\">scala&gt; list1.reduceRight(sum)</div><div class=\"line\">(<span class=\"number\">19</span>,<span class=\"number\">20</span>)</div><div class=\"line\">(<span class=\"number\">18</span>,<span class=\"number\">39</span>)</div><div class=\"line\">(<span class=\"number\">17</span>,<span class=\"number\">57</span>)</div><div class=\"line\">(<span class=\"number\">16</span>,<span class=\"number\">74</span>)</div><div class=\"line\">(<span class=\"number\">15</span>,<span class=\"number\">90</span>)</div><div class=\"line\">(<span class=\"number\">14</span>,<span class=\"number\">105</span>)</div><div class=\"line\">(<span class=\"number\">13</span>,<span class=\"number\">119</span>)</div><div class=\"line\">(<span class=\"number\">12</span>,<span class=\"number\">132</span>)</div><div class=\"line\">(<span class=\"number\">11</span>,<span class=\"number\">144</span>)</div><div class=\"line\">(<span class=\"number\">10</span>,<span class=\"number\">155</span>)</div><div class=\"line\">(<span class=\"number\">9</span>,<span class=\"number\">165</span>)</div><div class=\"line\">(<span class=\"number\">8</span>,<span class=\"number\">174</span>)</div><div class=\"line\">(<span class=\"number\">7</span>,<span class=\"number\">182</span>)</div><div class=\"line\">(<span class=\"number\">6</span>,<span class=\"number\">189</span>)</div><div class=\"line\">(<span class=\"number\">5</span>,<span class=\"number\">195</span>)</div><div class=\"line\">(<span class=\"number\">4</span>,<span class=\"number\">200</span>)</div><div class=\"line\">(<span class=\"number\">3</span>,<span class=\"number\">204</span>)</div><div class=\"line\">(<span class=\"number\">2</span>,<span class=\"number\">207</span>)</div><div class=\"line\">(<span class=\"number\">1</span>,<span class=\"number\">209</span>)</div><div class=\"line\">res54: <span class=\"type\">Int</span> = <span class=\"number\">210</span></div></pre></td></tr></table></figure></p>\n<p>List/CollectionsAPIScalaz</p>"},{"title":"linux ","date":"2017-02-22T15:57:54.000Z","_content":"linuxlinuxlinux/unixjoincut,sort,paste,uniq,split \n<!--more-->\nlinuxfind,findgrep awk join cut find awk grep\n# join\njoin \njoin\n```\njoin --help\nUsage: join [OPTION]... FILE1 FILE2\nFor each pair of input lines with identical join fields, write a line to\nstandard output.  The default join field is the first, delimited\nby whitespace.  When FILE1 or FILE2 (not both) is -, read standard input.\n\n  -a FILENUM        also print unpairable lines from file FILENUM, where\n                      FILENUM is 1 or 2, corresponding to FILE1 or FILE2\n  -e EMPTY          replace missing input fields with EMPTY\n  -i, --ignore-case  ignore differences in case when comparing fields\n  -j FIELD          equivalent to '-1 FIELD -2 FIELD'\n  -o FORMAT         obey FORMAT while constructing output line\n  -t CHAR           use CHAR as input and output field separator\n  -v FILENUM        like -a FILENUM, but suppress joined output lines\n  -1 FIELD          join on this FIELD of file 1\n  -2 FIELD          join on this FIELD of file 2\n  --check-order     check that the input is correctly sorted, even\n                      if all input lines are pairable\n  --nocheck-order   do not check that the input is correctly sorted\n  --header          treat the first line in each file as field headers,\n                      print them without trying to pair them\n      --help     display this help and exit\n      --version  output version information and exit\n```\n -1 -2 KEY-j\na.txt,b.txt\na.txt           \n1 22            \n2 33            \n3 44            \n\n\n b.txt\n 1   a\n 2   b\n 3   c\n\n\n\n```\njoin  a.txt b.txt\n\n1 22 a\n2 33 b\n3 44 c\n```\n\n\n# paste \n\npaste\n```\npaste a.txt b.txt\n\n1 22     1   a\n2 33     2   b\n3 44     3   c\n```\npaste-s\n```\npaste -s a.txt  b.txt \n1 22    2 33    3 44\n1 a     2 b     3 c\n```\npaste--\njoinpaste\n\n```\npaste -d: a.txt b.txt\n\n1 22:1   a\n2 33:2   b\n3 44:3   c\n```\n\n# cut \n```\ncut -d\" \" -f 1 a.txt \n1 \n2 \n3 \n```\nfd\n# sort \nsort \nc.txt\n1\n3\n5\n7\n11\n2\n4\n6\n10\n8\n9\n```\nsort c.txt \n1\n10\n11\n2\n3\n4\n5\n6\n7\n8\n9\n```\n\n```\nsort -n c.txt \n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n```\nsort r\n:\n-k\n-t\n-f\n-c1\n-C1\n-MJANFEB\n-b\n\nuniq  sortu.\n# split  dd \nsplit,\n\ndd ,dockerdd\n```\n#dd if=ubunt.tar bs=1024 count=97000 skip=0  of=ubuntu.tar.1\n#dd if=ubunt.tar bs=1024 count=97000 skip=97000  of=ubuntu.tar.2\n#cat ubuntu.tar.1 ubuntu.tar.2 > ubuntu.tar\ndd if=f21.tar bs=1024 count=97000 skip=0  of=fedora.tar.1\ndd if=f21.tar bs=1024 count=97000 skip=97000  of=fedora.tar.2\ndd if=f21.tar bs=1024 count=97000 skip=194000  of=fedora.tar.3\ndd if=mysql.tar bs=1024 count=97000 skip=0  of=mysql.tar.1\ndd if=mysql.tar bs=1024 count=97000 skip=97000  of=mysql.tar.2\ndd if=mysql.tar bs=1024 count=97000 skip=194000  of=mysql.tar.\n```\nbscountskipofif.\n\n","source":"_posts/test.md","raw":"---\ntitle: linux \ndate: 2017-02-22 23:57:54\ntags: linux\n---\nlinuxlinuxlinux/unixjoincut,sort,paste,uniq,split \n<!--more-->\nlinuxfind,findgrep awk join cut find awk grep\n# join\njoin \njoin\n```\njoin --help\nUsage: join [OPTION]... FILE1 FILE2\nFor each pair of input lines with identical join fields, write a line to\nstandard output.  The default join field is the first, delimited\nby whitespace.  When FILE1 or FILE2 (not both) is -, read standard input.\n\n  -a FILENUM        also print unpairable lines from file FILENUM, where\n                      FILENUM is 1 or 2, corresponding to FILE1 or FILE2\n  -e EMPTY          replace missing input fields with EMPTY\n  -i, --ignore-case  ignore differences in case when comparing fields\n  -j FIELD          equivalent to '-1 FIELD -2 FIELD'\n  -o FORMAT         obey FORMAT while constructing output line\n  -t CHAR           use CHAR as input and output field separator\n  -v FILENUM        like -a FILENUM, but suppress joined output lines\n  -1 FIELD          join on this FIELD of file 1\n  -2 FIELD          join on this FIELD of file 2\n  --check-order     check that the input is correctly sorted, even\n                      if all input lines are pairable\n  --nocheck-order   do not check that the input is correctly sorted\n  --header          treat the first line in each file as field headers,\n                      print them without trying to pair them\n      --help     display this help and exit\n      --version  output version information and exit\n```\n -1 -2 KEY-j\na.txt,b.txt\na.txt           \n1 22            \n2 33            \n3 44            \n\n\n b.txt\n 1   a\n 2   b\n 3   c\n\n\n\n```\njoin  a.txt b.txt\n\n1 22 a\n2 33 b\n3 44 c\n```\n\n\n# paste \n\npaste\n```\npaste a.txt b.txt\n\n1 22     1   a\n2 33     2   b\n3 44     3   c\n```\npaste-s\n```\npaste -s a.txt  b.txt \n1 22    2 33    3 44\n1 a     2 b     3 c\n```\npaste--\njoinpaste\n\n```\npaste -d: a.txt b.txt\n\n1 22:1   a\n2 33:2   b\n3 44:3   c\n```\n\n# cut \n```\ncut -d\" \" -f 1 a.txt \n1 \n2 \n3 \n```\nfd\n# sort \nsort \nc.txt\n1\n3\n5\n7\n11\n2\n4\n6\n10\n8\n9\n```\nsort c.txt \n1\n10\n11\n2\n3\n4\n5\n6\n7\n8\n9\n```\n\n```\nsort -n c.txt \n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n```\nsort r\n:\n-k\n-t\n-f\n-c1\n-C1\n-MJANFEB\n-b\n\nuniq  sortu.\n# split  dd \nsplit,\n\ndd ,dockerdd\n```\n#dd if=ubunt.tar bs=1024 count=97000 skip=0  of=ubuntu.tar.1\n#dd if=ubunt.tar bs=1024 count=97000 skip=97000  of=ubuntu.tar.2\n#cat ubuntu.tar.1 ubuntu.tar.2 > ubuntu.tar\ndd if=f21.tar bs=1024 count=97000 skip=0  of=fedora.tar.1\ndd if=f21.tar bs=1024 count=97000 skip=97000  of=fedora.tar.2\ndd if=f21.tar bs=1024 count=97000 skip=194000  of=fedora.tar.3\ndd if=mysql.tar bs=1024 count=97000 skip=0  of=mysql.tar.1\ndd if=mysql.tar bs=1024 count=97000 skip=97000  of=mysql.tar.2\ndd if=mysql.tar bs=1024 count=97000 skip=194000  of=mysql.tar.\n```\nbscountskipofif.\n\n","slug":"test","published":1,"updated":"2017-02-24T17:56:06.762Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt0qo000y60tulzcbcag5","content":"<p>linuxlinuxlinux/unixjoincut,sort,paste,uniq,split <br><a id=\"more\"></a><br>linuxfind,findgrep awk join cut find awk grep</p>\n<h1 id=\"join\"><a href=\"#join\" class=\"headerlink\" title=\"join\"></a>join</h1><p>join <br>join<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">join --help</div><div class=\"line\">Usage: join [OPTION]... FILE1 FILE2</div><div class=\"line\">For each pair of input lines with identical join fields, write a line to</div><div class=\"line\">standard output.  The default join field is the first, delimited</div><div class=\"line\">by whitespace.  When FILE1 or FILE2 (not both) is -, read standard input.</div><div class=\"line\"></div><div class=\"line\">  -a FILENUM        also print unpairable lines from file FILENUM, where</div><div class=\"line\">                      FILENUM is 1 or 2, corresponding to FILE1 or FILE2</div><div class=\"line\">  -e EMPTY          replace missing input fields with EMPTY</div><div class=\"line\">  -i, --ignore-case  ignore differences in case when comparing fields</div><div class=\"line\">  -j FIELD          equivalent to &apos;-1 FIELD -2 FIELD&apos;</div><div class=\"line\">  -o FORMAT         obey FORMAT while constructing output line</div><div class=\"line\">  -t CHAR           use CHAR as input and output field separator</div><div class=\"line\">  -v FILENUM        like -a FILENUM, but suppress joined output lines</div><div class=\"line\">  -1 FIELD          join on this FIELD of file 1</div><div class=\"line\">  -2 FIELD          join on this FIELD of file 2</div><div class=\"line\">  --check-order     check that the input is correctly sorted, even</div><div class=\"line\">                      if all input lines are pairable</div><div class=\"line\">  --nocheck-order   do not check that the input is correctly sorted</div><div class=\"line\">  --header          treat the first line in each file as field headers,</div><div class=\"line\">                      print them without trying to pair them</div><div class=\"line\">      --help     display this help and exit</div><div class=\"line\">      --version  output version information and exit</div></pre></td></tr></table></figure></p>\n<p> -1 -2 KEY-j<br>a.txt,b.txt<br>a.txt<br>1 22<br>2 33<br>3 44            </p>\n<p> b.txt<br> 1   a<br> 2   b<br> 3   c</p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">join  a.txt b.txt</div><div class=\"line\"></div><div class=\"line\">1 22 a</div><div class=\"line\">2 33 b</div><div class=\"line\">3 44 c</div></pre></td></tr></table></figure></p>\n<p></p>\n<h1 id=\"paste-\"><a href=\"#paste-\" class=\"headerlink\" title=\"paste \"></a>paste </h1><p>paste<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">paste a.txt b.txt</div><div class=\"line\"></div><div class=\"line\">1 22     1   a</div><div class=\"line\">2 33     2   b</div><div class=\"line\">3 44     3   c</div></pre></td></tr></table></figure></p>\n<p>paste-s<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">paste -s a.txt  b.txt </div><div class=\"line\">1 22    2 33    3 44</div><div class=\"line\">1 a     2 b     3 c</div></pre></td></tr></table></figure></p>\n<p>paste--<br>joinpaste</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">paste -d: a.txt b.txt</div><div class=\"line\"></div><div class=\"line\">1 22:1   a</div><div class=\"line\">2 33:2   b</div><div class=\"line\">3 44:3   c</div></pre></td></tr></table></figure>\n<h1 id=\"cut-\"><a href=\"#cut-\" class=\"headerlink\" title=\"cut \"></a>cut </h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cut -d&quot; &quot; -f 1 a.txt </div><div class=\"line\">1 </div><div class=\"line\">2 </div><div class=\"line\">3</div></pre></td></tr></table></figure>\n<p>fd</p>\n<h1 id=\"sort-\"><a href=\"#sort-\" class=\"headerlink\" title=\"sort \"></a>sort </h1><p>sort <br>c.txt<br>1<br>3<br>5<br>7<br>11<br>2<br>4<br>6<br>10<br>8<br>9<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">sort c.txt </div><div class=\"line\">1</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">sort -n c.txt </div><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td></tr></table></figure></p>\n<p>sort r<br>:<br>-k<br>-t<br>-f<br>-c1<br>-C1<br>-MJANFEB<br>-b</p>\n<p>uniq  sortu.</p>\n<h1 id=\"split--dd-\"><a href=\"#split--dd-\" class=\"headerlink\" title=\"split  dd \"></a>split  dd </h1><p>split,</p>\n<p>dd ,dockerdd<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">#dd if=ubunt.tar bs=1024 count=97000 skip=0  of=ubuntu.tar.1</div><div class=\"line\">#dd if=ubunt.tar bs=1024 count=97000 skip=97000  of=ubuntu.tar.2</div><div class=\"line\">#cat ubuntu.tar.1 ubuntu.tar.2 &gt; ubuntu.tar</div><div class=\"line\">dd if=f21.tar bs=1024 count=97000 skip=0  of=fedora.tar.1</div><div class=\"line\">dd if=f21.tar bs=1024 count=97000 skip=97000  of=fedora.tar.2</div><div class=\"line\">dd if=f21.tar bs=1024 count=97000 skip=194000  of=fedora.tar.3</div><div class=\"line\">dd if=mysql.tar bs=1024 count=97000 skip=0  of=mysql.tar.1</div><div class=\"line\">dd if=mysql.tar bs=1024 count=97000 skip=97000  of=mysql.tar.2</div><div class=\"line\">dd if=mysql.tar bs=1024 count=97000 skip=194000  of=mysql.tar.</div></pre></td></tr></table></figure></p>\n<p>bscountskipofif.<br></p>\n","excerpt":"<p>linuxlinuxlinux/unixjoincut,sort,paste,uniq,split <br>","more":"<br>linuxfind,findgrep awk join cut find awk grep</p>\n<h1 id=\"join\"><a href=\"#join\" class=\"headerlink\" title=\"join\"></a>join</h1><p>join <br>join<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">join --help</div><div class=\"line\">Usage: join [OPTION]... FILE1 FILE2</div><div class=\"line\">For each pair of input lines with identical join fields, write a line to</div><div class=\"line\">standard output.  The default join field is the first, delimited</div><div class=\"line\">by whitespace.  When FILE1 or FILE2 (not both) is -, read standard input.</div><div class=\"line\"></div><div class=\"line\">  -a FILENUM        also print unpairable lines from file FILENUM, where</div><div class=\"line\">                      FILENUM is 1 or 2, corresponding to FILE1 or FILE2</div><div class=\"line\">  -e EMPTY          replace missing input fields with EMPTY</div><div class=\"line\">  -i, --ignore-case  ignore differences in case when comparing fields</div><div class=\"line\">  -j FIELD          equivalent to &apos;-1 FIELD -2 FIELD&apos;</div><div class=\"line\">  -o FORMAT         obey FORMAT while constructing output line</div><div class=\"line\">  -t CHAR           use CHAR as input and output field separator</div><div class=\"line\">  -v FILENUM        like -a FILENUM, but suppress joined output lines</div><div class=\"line\">  -1 FIELD          join on this FIELD of file 1</div><div class=\"line\">  -2 FIELD          join on this FIELD of file 2</div><div class=\"line\">  --check-order     check that the input is correctly sorted, even</div><div class=\"line\">                      if all input lines are pairable</div><div class=\"line\">  --nocheck-order   do not check that the input is correctly sorted</div><div class=\"line\">  --header          treat the first line in each file as field headers,</div><div class=\"line\">                      print them without trying to pair them</div><div class=\"line\">      --help     display this help and exit</div><div class=\"line\">      --version  output version information and exit</div></pre></td></tr></table></figure></p>\n<p> -1 -2 KEY-j<br>a.txt,b.txt<br>a.txt<br>1 22<br>2 33<br>3 44            </p>\n<p> b.txt<br> 1   a<br> 2   b<br> 3   c</p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">join  a.txt b.txt</div><div class=\"line\"></div><div class=\"line\">1 22 a</div><div class=\"line\">2 33 b</div><div class=\"line\">3 44 c</div></pre></td></tr></table></figure></p>\n<p></p>\n<h1 id=\"paste-\"><a href=\"#paste-\" class=\"headerlink\" title=\"paste \"></a>paste </h1><p>paste<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">paste a.txt b.txt</div><div class=\"line\"></div><div class=\"line\">1 22     1   a</div><div class=\"line\">2 33     2   b</div><div class=\"line\">3 44     3   c</div></pre></td></tr></table></figure></p>\n<p>paste-s<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">paste -s a.txt  b.txt </div><div class=\"line\">1 22    2 33    3 44</div><div class=\"line\">1 a     2 b     3 c</div></pre></td></tr></table></figure></p>\n<p>paste--<br>joinpaste</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">paste -d: a.txt b.txt</div><div class=\"line\"></div><div class=\"line\">1 22:1   a</div><div class=\"line\">2 33:2   b</div><div class=\"line\">3 44:3   c</div></pre></td></tr></table></figure>\n<h1 id=\"cut-\"><a href=\"#cut-\" class=\"headerlink\" title=\"cut \"></a>cut </h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cut -d&quot; &quot; -f 1 a.txt </div><div class=\"line\">1 </div><div class=\"line\">2 </div><div class=\"line\">3</div></pre></td></tr></table></figure>\n<p>fd</p>\n<h1 id=\"sort-\"><a href=\"#sort-\" class=\"headerlink\" title=\"sort \"></a>sort </h1><p>sort <br>c.txt<br>1<br>3<br>5<br>7<br>11<br>2<br>4<br>6<br>10<br>8<br>9<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">sort c.txt </div><div class=\"line\">1</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">sort -n c.txt </div><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td></tr></table></figure></p>\n<p>sort r<br>:<br>-k<br>-t<br>-f<br>-c1<br>-C1<br>-MJANFEB<br>-b</p>\n<p>uniq  sortu.</p>\n<h1 id=\"split--dd-\"><a href=\"#split--dd-\" class=\"headerlink\" title=\"split  dd \"></a>split  dd </h1><p>split,</p>\n<p>dd ,dockerdd<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">#dd if=ubunt.tar bs=1024 count=97000 skip=0  of=ubuntu.tar.1</div><div class=\"line\">#dd if=ubunt.tar bs=1024 count=97000 skip=97000  of=ubuntu.tar.2</div><div class=\"line\">#cat ubuntu.tar.1 ubuntu.tar.2 &gt; ubuntu.tar</div><div class=\"line\">dd if=f21.tar bs=1024 count=97000 skip=0  of=fedora.tar.1</div><div class=\"line\">dd if=f21.tar bs=1024 count=97000 skip=97000  of=fedora.tar.2</div><div class=\"line\">dd if=f21.tar bs=1024 count=97000 skip=194000  of=fedora.tar.3</div><div class=\"line\">dd if=mysql.tar bs=1024 count=97000 skip=0  of=mysql.tar.1</div><div class=\"line\">dd if=mysql.tar bs=1024 count=97000 skip=97000  of=mysql.tar.2</div><div class=\"line\">dd if=mysql.tar bs=1024 count=97000 skip=194000  of=mysql.tar.</div></pre></td></tr></table></figure></p>\n<p>bscountskipofif.<br></p>"},{"title":"spark  sparksql DataSet","date":"2017-03-10T16:00:00.000Z","_content":"sparksqldataframe sparkspark,.\n:spark 2.0.1\n<!-- more -->\n## \nshowString sparkshowshowString\n```\n  /**\n   * Compose the string representing rows for output\n   *\n   * @param _numRows Number of rows to show\n   * @param truncate If set to more than 0, truncates strings to `truncate` characters and\n   *                   all cells will be aligned right.\n   */\n  private[sql] def showString(_numRows: Int, truncate: Int = 20): String \n```\n## dataSetdataFrame\n   dataframdataset\n```\n  /**\n   * Converts this strongly typed collection of data to generic `DataFrame` with columns renamed.\n   * This can be quite convenient in conversion from an RDD of tuples into a `DataFrame` with\n   * meaningful names. For example:\n   * {{{\n   *   val rdd: RDD[(Int, String)] = ...\n   *   rdd.toDF()  // this implicit conversion creates a DataFrame with column name `_1` and `_2`\n   *   rdd.toDF(\"id\", \"name\")  // this creates a DataFrame with column name \"id\" and \"name\"\n   * }}}\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def toDF(colNames: String*): DataFrame = {\n    require(schema.size == colNames.size,\n      \"The number of columns doesn't match.\\n\" +\n        s\"Old column names (${schema.size}): \" + schema.fields.map(_.name).mkString(\", \") + \"\\n\" +\n        s\"New column names (${colNames.size}): \" + colNames.mkString(\", \"))\n\n    val newCols = logicalPlan.output.zip(colNames).map { case (oldAttribute, newName) =>\n      Column(oldAttribute).as(newName)\n    }\n    select(newCols : _*)\n  }\n```\ndataset\n```\n  /**\n   * Returns the schema of this Dataset.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def schema: StructType = queryExecution.analyzed.schema\n\n  /**\n   * Prints the schema to the console in a nice tree format.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  // scalastyle:off println\n  def printSchema(): Unit = println(schema.treeString)\n  // scalastyle:on println\n```\n\n```\n  /**\n   * Prints the plans (logical and physical) to the console for debugging purposes.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def explain(extended: Boolean): Unit = {\n    val explain = ExplainCommand(queryExecution.logical, extended = extended)\n    sparkSession.sessionState.executePlan(explain).executedPlan.executeCollect().foreach {\n      // scalastyle:off println\n      r => println(r.getString(0))\n      // scalastyle:on println\n    }\n  }\n\n  /**\n   * Prints the physical plan to the console for debugging purposes.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def explain(): Unit = explain(extended = false)\n```\n\n```\n  /**\n   * Returns all column names and their data types as an array.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def dtypes: Array[(String, String)] = schema.fields.map { field =>\n    (field.name, field.dataType.toString)\n  }\n\n  /**\n   * Returns all column names as an array.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def columns: Array[String] = schema.fields.map(_.name)\n```\n\n```\n  /**\n   * Returns true if the `collect` and `take` methods can be run locally\n   * (without any Spark executors).\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def isLocal: Boolean = logicalPlan.isInstanceOf[LocalRelation]\n\n  /**\n   * Returns true if this Dataset contains one or more sources that continuously\n   * return data as it arrives. A Dataset that reads data from a streaming source\n   * must be executed as a `StreamingQuery` using the `start()` method in\n   * `DataStreamWriter`. Methods that return a single answer, e.g. `count()` or\n   * `collect()`, will throw an [[AnalysisException]] when there is a streaming\n   * source present.\n   *\n   * @group streaming\n   * @since 2.0.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def isStreaming: Boolean = logicalPlan.isStreaming\n```\n****\n```\n  /**\n   * Eagerly checkpoint a Dataset and return the new Dataset. Checkpointing can be used to truncate\n   * the logical plan of this Dataset, which is especially useful in iterative algorithms where the\n   * plan may grow exponentially. It will be saved to files inside the checkpoint\n   * directory set with `SparkContext#setCheckpointDir`.\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def checkpoint(): Dataset[T] = checkpoint(eager = true)\n\n  /**\n   * Returns a checkpointed version of this Dataset. Checkpointing can be used to truncate the\n   * logical plan of this Dataset, which is especially useful in iterative algorithms where the\n   * plan may grow exponentially. It will be saved to files inside the checkpoint\n   * directory set with `SparkContext#setCheckpointDir`.\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def checkpoint(eager: Boolean): Dataset[T] = {\n    val internalRdd = queryExecution.toRdd.map(_.copy())\n    internalRdd.checkpoint()\n\n    if (eager) {\n      internalRdd.count()\n    }\n\n    val physicalPlan = queryExecution.executedPlan\n```\n\n```\n    // Takes the first leaf partitioning whenever we see a `PartitioningCollection`. Otherwise the\n    // size of `PartitioningCollection` may grow exponentially for queries involving deep inner\n    // joins.\n    def firstLeafPartitioning(partitioning: Partitioning): Partitioning = {\n      partitioning match {\n        case p: PartitioningCollection => firstLeafPartitioning(p.partitionings.head)\n        case p => p\n      }\n    }\n\n    val outputPartitioning = firstLeafPartitioning(physicalPlan.outputPartitioning)\n\n    Dataset.ofRows(\n      sparkSession,\n      LogicalRDD(\n        logicalPlan.output,\n        internalRdd,\n        outputPartitioning,\n        physicalPlan.outputOrdering\n      )(sparkSession)).as[T]\n  }\n```\n\n```\n  /**\n   * :: Experimental ::\n   * Defines an event time watermark for this [[Dataset]]. A watermark tracks a point in time\n   * before which we assume no more late data is going to arrive.\n   *\n   * Spark will use this watermark for several purposes:\n   *  - To know when a given time window aggregation can be finalized and thus can be emitted when\n   *    using output modes that do not allow updates.\n   *  - To minimize the amount of state that we need to keep for on-going aggregations,\n   *    `mapGroupsWithState` and `dropDuplicates` operators.\n   *\n   *  The current watermark is computed by looking at the `MAX(eventTime)` seen across\n   *  all of the partitions in the query minus a user specified `delayThreshold`.  Due to the cost\n   *  of coordinating this value across partitions, the actual watermark used is only guaranteed\n   *  to be at least `delayThreshold` behind the actual event time.  In some cases we may still\n   *  process records that arrive more than `delayThreshold` late.\n   *\n   * @param eventTime the name of the column that contains the event time of the row.\n   * @param delayThreshold the minimum delay to wait to data to arrive late, relative to the latest\n   *                       record that has been processed in the form of an interval\n   *                       (e.g. \"1 minute\" or \"5 hours\").\n   *\n   * @group streaming\n   * @since 2.1.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  // We only accept an existing column name, not a derived column here as a watermark that is\n  // defined on a derived column cannot referenced elsewhere in the plan.\n  def withWatermark(eventTime: String, delayThreshold: String): Dataset[T] = withTypedPlan {\n    val parsedDelay =\n      Option(CalendarInterval.fromString(\"interval \" + delayThreshold))\n        .getOrElse(throw new AnalysisException(s\"Unable to parse time delay '$delayThreshold'\"))\n    EventTimeWatermark(UnresolvedAttribute(eventTime), parsedDelay, logicalPlan)\n  }\n```\n## \n```\n  /**\n   * Displays the Dataset in a tabular form. Strings more than 20 characters will be truncated,\n   * and all cells will be aligned right. For example:\n   * {{{\n   *   year  month AVG('Adj Close) MAX('Adj Close)\n   *   1980  12    0.503218        0.595103\n   *   1981  01    0.523289        0.570307\n   *   1982  02    0.436504        0.475256\n   *   1983  03    0.410516        0.442194\n   *   1984  04    0.450090        0.483521\n   * }}}\n   *\n   * @param numRows Number of rows to show\n   *\n   * @group action\n   * @since 1.6.0\n   */\ndatafram20\n  def show(numRows: Int): Unit = show(numRows, truncate = true)\n\ndatafram2020\n  \n  def show(): Unit = show(20)\n\ndatafram20truncate\n  def show(truncate: Boolean): Unit = show(20, truncate)\n\ndataframnumRowstruncate\n  def show(numRows: Int, truncate: Boolean): Unit = if (truncate) {\n  def show(numRows: Int, truncate: Int): Unit = println(showString(numRows, truncate))\n```\n## \n```\n\ndataset\n  def na: DataFrameNaFunctions = new DataFrameNaFunctions(toDF())\n\ndataset\n  def stat: DataFrameStatFunctions = new DataFrameStatFunctions(toDF())\ndataframe\n  def join(right: Dataset[_]): DataFrame = withPlan {\n    Join(logicalPlan, right.logicalPlan, joinType = Inner, None)\n  }\n\n  /**\n   * Inner equi-join with another `DataFrame` using the given column.\n   *\n   * Different from other join functions, the join column will only appear once in the output,\n   * i.e. similar to SQL's `JOIN USING` syntax.\n   *\n   * {{{\n   *   // Joining df1 and df2 using the column \"user_id\"\n   *   df1.join(df2, \"user_id\")\n   * }}}\n   *\n   * @param right Right side of the join operation.\n   * @param usingColumn Name of the column to join on. This column must exist on both sides.\n   *\n   * @note If you perform a self-join using this function without aliasing the input\n   * `DataFrame`s, you will NOT be able to reference any columns after the join, since\n   * there is no way to disambiguate which side of the join you would like to reference.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], usingColumn: String): DataFrame = {\n    join(right, Seq(usingColumn))\n  }\n\n  /**\n   * Inner equi-join with another `DataFrame` using the given columns.\n   *\n   * Different from other join functions, the join columns will only appear once in the output,\n   * i.e. similar to SQL's `JOIN USING` syntax.\n   *\n   * {{{\n   *   // Joining df1 and df2 using the columns \"user_id\" and \"user_name\"\n   *   df1.join(df2, Seq(\"user_id\", \"user_name\"))\n   * }}}\n   *\n   * @param right Right side of the join operation.\n   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.\n   *\n   * @note If you perform a self-join using this function without aliasing the input\n   * `DataFrame`s, you will NOT be able to reference any columns after the join, since\n   * there is no way to disambiguate which side of the join you would like to reference.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\ndataframekey\n  def join(right: Dataset[_], usingColumns: Seq[String]): DataFrame = {\n    join(right, usingColumns, \"inner\")\n  }\n\n  /**\n   * Equi-join with another `DataFrame` using the given columns. A cross join with a predicate\n   * is specified as an inner join. If you would explicitly like to perform a cross join use the\n   * `crossJoin` method.\n   *\n   * Different from other join functions, the join columns will only appear once in the output,\n   * i.e. similar to SQL's `JOIN USING` syntax.\n   *\n   * @param right Right side of the join operation.\n   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.\n   * @param joinType Type of join to perform. Default `inner`. Must be one of:\n   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,\n   *                 `right`, `right_outer`, `left_semi`, `left_anti`.\n   *\n   * @note If you perform a self-join using this function without aliasing the input\n   * `DataFrame`s, you will NOT be able to reference any columns after the join, since\n   * there is no way to disambiguate which side of the join you would like to reference.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], usingColumns: Seq[String], joinType: String): DataFrame = {\n    // Analyze the self join. The assumption is that the analyzer will disambiguate left vs right\n    // by creating a new instance for one of the branch.\n    val joined = sparkSession.sessionState.executePlan(\n      Join(logicalPlan, right.logicalPlan, joinType = JoinType(joinType), None))\n      .analyzed.asInstanceOf[Join]\n\n    withPlan {\n      Join(\n        joined.left,\n        joined.right,\n        UsingJoin(JoinType(joinType), usingColumns),\n        None)\n    }\n  }\n\n  /**\n   * Inner join with another `DataFrame`, using the given join expression.\n   *\n   * {{{\n   *   // The following two are equivalent:\n   *   df1.join(df2, $\"df1Key\" === $\"df2Key\")\n   *   df1.join(df2).where($\"df1Key\" === $\"df2Key\")\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], joinExprs: Column): DataFrame = join(right, joinExprs, \"inner\")\n\n  /**\n   * Join with another `DataFrame`, using the given join expression. The following performs\n   * a full outer join between `df1` and `df2`.\n   *\n   * {{{\n   *   // Scala:\n   *   import org.apache.spark.sql.functions._\n   *   df1.join(df2, $\"df1Key\" === $\"df2Key\", \"outer\")\n   *\n   *   // Java:\n   *   import static org.apache.spark.sql.functions.*;\n   *   df1.join(df2, col(\"df1Key\").equalTo(col(\"df2Key\")), \"outer\");\n   * }}}\n   *\n   * @param right Right side of the join.\n   * @param joinExprs Join expression.\n   * @param joinType Type of join to perform. Default `inner`. Must be one of:\n   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,\n   *                 `right`, `right_outer`, `left_semi`, `left_anti`.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame = {\n    // Note that in this function, we introduce a hack in the case of self-join to automatically\n    // resolve ambiguous join conditions into ones that might make sense [SPARK-6231].\n    // Consider this case: df.join(df, df(\"key\") === df(\"key\"))\n    // Since df(\"key\") === df(\"key\") is a trivially true condition, this actually becomes a\n    // cartesian join. However, most likely users expect to perform a self join using \"key\".\n    // With that assumption, this hack turns the trivially true condition into equality on join\n    // keys that are resolved to both sides.\n\n    // Trigger analysis so in the case of self-join, the analyzer will clone the plan.\n    // After the cloning, left and right side will have distinct expression ids.\n    val plan = withPlan(\n      Join(logicalPlan, right.logicalPlan, JoinType(joinType), Some(joinExprs.expr)))\n      .queryExecution.analyzed.asInstanceOf[Join]\n\n    // If auto self join alias is disabled, return the plan.\n    if (!sparkSession.sessionState.conf.dataFrameSelfJoinAutoResolveAmbiguity) {\n      return withPlan(plan)\n    }\n\n    // If left/right have no output set intersection, return the plan.\n    val lanalyzed = withPlan(this.logicalPlan).queryExecution.analyzed\n    val ranalyzed = withPlan(right.logicalPlan).queryExecution.analyzed\n    if (lanalyzed.outputSet.intersect(ranalyzed.outputSet).isEmpty) {\n      return withPlan(plan)\n    }\n\n    // Otherwise, find the trivially true predicates and automatically resolves them to both sides.\n    // By the time we get here, since we have already run analysis, all attributes should've been\n    // resolved and become AttributeReference.\n    val cond = plan.condition.map { _.transform {\n      case catalyst.expressions.EqualTo(a: AttributeReference, b: AttributeReference)\n          if a.sameRef(b) =>\n        catalyst.expressions.EqualTo(\n          withPlan(plan.left).resolve(a.name),\n          withPlan(plan.right).resolve(b.name))\n    }}\n\n    withPlan {\n      plan.copy(condition = cond)\n    }\n  }\n\n  /**\n   * Explicit cartesian join with another `DataFrame`.\n   *\n   * @param right Right side of the join operation.\n   *\n   * @note Cartesian joins are very expensive without an extra filter that can be pushed down.\n   *\n   * @group untypedrel\n   * @since 2.1.0\n   */\n\n  def crossJoin(right: Dataset[_]): DataFrame = withPlan {\n    Join(logicalPlan, right.logicalPlan, joinType = Cross, None)\n  }\n\n  /**\n   * :: Experimental ::\n   * Joins this Dataset returning a `Tuple2` for each pair where `condition` evaluates to\n   * true.\n   *\n   * This is similar to the relation `join` function with one important difference in the\n   * result schema. Since `joinWith` preserves objects present on either side of the join, the\n   * result schema is similarly nested into a tuple under the column names `_1` and `_2`.\n   *\n   * This type of join can be useful both for preserving type-safety with the original object\n   * types as well as working with relational data where either side of the join has column\n   * names in common.\n   *\n   * @param other Right side of the join.\n   * @param condition Join expression.\n   * @param joinType Type of join to perform. Default `inner`. Must be one of:\n   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,\n   *                 `right`, `right_outer`, `left_semi`, `left_anti`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n\n  @Experimental\n  @InterfaceStability.Evolving\n  def joinWith[U](other: Dataset[U], condition: Column, joinType: String): Dataset[(T, U)] = {\n    // Creates a Join node and resolve it first, to get join condition resolved, self-join resolved,\n    // etc.\n    val joined = sparkSession.sessionState.executePlan(\n      Join(\n        this.logicalPlan,\n        other.logicalPlan,\n        JoinType(joinType),\n        Some(condition.expr))).analyzed.asInstanceOf[Join]\n\n    // For both join side, combine all outputs into a single column and alias it with \"_1\" or \"_2\",\n    // to match the schema for the encoder of the join result.\n    // Note that we do this before joining them, to enable the join operator to return null for one\n    // side, in cases like outer-join.\n    val left = {\n      val combined = if (this.exprEnc.flat) {\n        assert(joined.left.output.length == 1)\n        Alias(joined.left.output.head, \"_1\")()\n      } else {\n        Alias(CreateStruct(joined.left.output), \"_1\")()\n      }\n      Project(combined :: Nil, joined.left)\n    }\n\n    val right = {\n      val combined = if (other.exprEnc.flat) {\n        assert(joined.right.output.length == 1)\n        Alias(joined.right.output.head, \"_2\")()\n      } else {\n        Alias(CreateStruct(joined.right.output), \"_2\")()\n      }\n      Project(combined :: Nil, joined.right)\n    }\n\n    // Rewrites the join condition to make the attribute point to correct column/field, after we\n    // combine the outputs of each join side.\n    val conditionExpr = joined.condition.get transformUp {\n      case a: Attribute if joined.left.outputSet.contains(a) =>\n        if (this.exprEnc.flat) {\n          left.output.head\n        } else {\n          val index = joined.left.output.indexWhere(_.exprId == a.exprId)\n          GetStructField(left.output.head, index)\n        }\n      case a: Attribute if joined.right.outputSet.contains(a) =>\n        if (other.exprEnc.flat) {\n          right.output.head\n        } else {\n          val index = joined.right.output.indexWhere(_.exprId == a.exprId)\n          GetStructField(right.output.head, index)\n        }\n    }\n\n    implicit val tuple2Encoder: Encoder[(T, U)] =\n      ExpressionEncoder.tuple(this.exprEnc, other.exprEnc)\n\n    withTypedPlan(Join(left, right, joined.joinType, Some(conditionExpr)))\n  }\n\n  /**\n   * :: Experimental ::\n   * Using inner equi-join to join this Dataset returning a `Tuple2` for each pair\n   * where `condition` evaluates to true.\n   *\n   * @param other Right side of the join.\n   * @param condition Join expression.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def joinWith[U](other: Dataset[U], condition: Column): Dataset[(T, U)] = {\n    joinWith(other, condition, \"inner\")\n  }\n```\n## \n```\n  /**\n   * Returns a new Dataset with each partition sorted by the given expressions.\n   *\n   * This is the same operation as \"SORT BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n\n  @scala.annotation.varargs\n  def sortWithinPartitions(sortCol: String, sortCols: String*): Dataset[T] = {\n    sortWithinPartitions((sortCol +: sortCols).map(Column(_)) : _*)\n  }\n\n  /**\n   * Returns a new Dataset with each partition sorted by the given expressions.\n   *\n   * This is the same operation as \"SORT BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n\n\n  @scala.annotation.varargs\n  def sortWithinPartitions(sortExprs: Column*): Dataset[T] = {\n    sortInternal(global = false, sortExprs)\n  }\n\n  /**\n   * Returns a new Dataset sorted by the specified column, all in ascending order.\n   * {{{\n   *   // The following 3 are equivalent\n   *   ds.sort(\"sortcol\")\n   *   ds.sort($\"sortcol\")\n   *   ds.sort($\"sortcol\".asc)\n   * }}}\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def sort(sortCol: String, sortCols: String*): Dataset[T] = {\n    sort((sortCol +: sortCols).map(apply) : _*)\n  }\n\n  /**\n   * Returns a new Dataset sorted by the given expressions. For example:\n   * {{{\n   *   ds.sort($\"col1\", $\"col2\".desc)\n   * }}}\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def sort(sortExprs: Column*): Dataset[T] = {\n    sortInternal(global = true, sortExprs)\n  }\n\n  /**\n   * Returns a new Dataset sorted by the given expressions.\n   * This is an alias of the `sort` function.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def orderBy(sortCol: String, sortCols: String*): Dataset[T] = sort(sortCol, sortCols : _*)\n\n  /**\n   * Returns a new Dataset sorted by the given expressions.\n   * This is an alias of the `sort` function.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def orderBy(sortExprs: Column*): Dataset[T] = sort(sortExprs : _*)\n```\n\n```\n  /**\n   * Selects column based on the column name and return it as a [[Column]].\n   *\n   * @note The column name can also reference to a nested column like `a.b`.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def apply(colName: String): Column = col(colName)\n  /**\n   * Selects column based on the column name and return it as a [[Column]].\n   *\n   * @note The column name can also reference to a nested column like `a.b`.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def col(colName: String): Column = colName match {\n    case \"*\" =>\n      Column(ResolvedStar(queryExecution.analyzed.output))\n    case _ =>\n      val expr = resolve(colName)\n      Column(expr)\n  }\n\n```\n## \ndatasetdataset\n ```\n\n  /**\n   * Returns a new Dataset with an alias set.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def as(alias: String): Dataset[T] = withTypedPlan {\n    SubqueryAlias(alias, logicalPlan, None)\n  }\n\n  /**\n   * (Scala-specific) Returns a new Dataset with an alias set.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def as(alias: Symbol): Dataset[T] = as(alias.name)\n\n  /**\n   * Returns a new Dataset with an alias set. Same as `as`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def alias(alias: String): Dataset[T] = as(alias)\n\n  /**\n   * (Scala-specific) Returns a new Dataset with an alias set. Same as `as`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def alias(alias: Symbol): Dataset[T] = as(alias)\n```\n## \n\n```\n  /**\n   * Selects a set of column based expressions.\n   * {{{\n   *   ds.select($\"colA\", $\"colB\" + 1)\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def select(cols: Column*): DataFrame = withPlan {\n    Project(cols.map(_.named), logicalPlan)\n  }\n\n  /**\n   * Selects a set of columns. This is a variant of `select` that can only select\n   * existing columns using column names (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // The following two are equivalent:\n   *   ds.select(\"colA\", \"colB\")\n   *   ds.select($\"colA\", $\"colB\")\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def select(col: String, cols: String*): DataFrame = select((col +: cols).map(Column(_)) : _*)\n\n  /**\n   * Selects a set of SQL expressions. This is a variant of `select` that accepts\n   * SQL expressions.\n   *\n   * {{{\n   *   // The following are equivalent:\n   *   ds.selectExpr(\"colA\", \"colB as newName\", \"abs(colC)\")\n   *   ds.select(expr(\"colA\"), expr(\"colB as newName\"), expr(\"abs(colC)\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  @scala.annotation.varargs\n  def selectExpr(exprs: String*): DataFrame = {\n    select(exprs.map { expr =>\n      Column(sparkSession.sessionState.sqlParser.parseExpression(expr))\n    }: _*)\n  }\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expression for each element.\n   *\n   * {{{\n   *   val ds = Seq(1, 2, 3).toDS()\n   *   val newDS = ds.select(expr(\"value + 1\").as[Int])\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1](c1: TypedColumn[T, U1]): Dataset[U1] = {\n    implicit val encoder = c1.encoder\n    val project = Project(c1.withInputType(exprEnc, logicalPlan.output).named :: Nil,\n      logicalPlan)\n\n    if (encoder.flat) {\n      new Dataset[U1](sparkSession, project, encoder)\n    } else {\n      // Flattens inner fields of U1\n      new Dataset[Tuple1[U1]](sparkSession, project, ExpressionEncoder.tuple(encoder)).map(_._1)\n    }\n  }\n\n  /**\n   * Internal helper function for building typed selects that return tuples. For simplicity and\n   * code reuse, we do this without the help of the type system and then use helper functions\n   * that cast appropriately for the user facing interface.\n   */\n  ???\n  protected def selectUntyped(columns: TypedColumn[_, _]*): Dataset[_] = {\n    val encoders = columns.map(_.encoder)\n    val namedColumns =\n      columns.map(_.withInputType(exprEnc, logicalPlan.output).named)\n    val execution = new QueryExecution(sparkSession, Project(namedColumns, logicalPlan))\n    new Dataset(sparkSession, execution, ExpressionEncoder.tuple(encoders))\n  }\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2](c1: TypedColumn[T, U1], c2: TypedColumn[T, U2]): Dataset[(U1, U2)] =\n    selectUntyped(c1, c2).asInstanceOf[Dataset[(U1, U2)]]\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2, U3](\n      c1: TypedColumn[T, U1],\n      c2: TypedColumn[T, U2],\n      c3: TypedColumn[T, U3]): Dataset[(U1, U2, U3)] =\n    selectUntyped(c1, c2, c3).asInstanceOf[Dataset[(U1, U2, U3)]]\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2, U3, U4](\n      c1: TypedColumn[T, U1],\n      c2: TypedColumn[T, U2],\n      c3: TypedColumn[T, U3],\n      c4: TypedColumn[T, U4]): Dataset[(U1, U2, U3, U4)] =\n    selectUntyped(c1, c2, c3, c4).asInstanceOf[Dataset[(U1, U2, U3, U4)]]\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2, U3, U4, U5](\n      c1: TypedColumn[T, U1],\n      c2: TypedColumn[T, U2],\n      c3: TypedColumn[T, U3],\n      c4: TypedColumn[T, U4],\n      c5: TypedColumn[T, U5]): Dataset[(U1, U2, U3, U4, U5)] =\n    selectUntyped(c1, c2, c3, c4, c5).asInstanceOf[Dataset[(U1, U2, U3, U4, U5)]]\n```\n## \nsqlwhere\n```\n  /**\n   * Filters rows using the given condition.\n   * {{{\n   *   // The following are equivalent:\n   *   peopleDs.filter($\"age\" > 15)\n   *   peopleDs.where($\"age\" > 15)\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def filter(condition: Column): Dataset[T] = withTypedPlan {\n    Filter(condition.expr, logicalPlan)\n  }\n\n  /**\n   * Filters rows using the given SQL expression.\n   * {{{\n   *   peopleDs.filter(\"age > 15\")\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def filter(conditionExpr: String): Dataset[T] = {\n    filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))\n  }\n\n  /**\n   * Filters rows using the given condition. This is an alias for `filter`.\n   * {{{\n   *   // The following are equivalent:\n   *   peopleDs.filter($\"age\" > 15)\n   *   peopleDs.where($\"age\" > 15)\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def where(condition: Column): Dataset[T] = filter(condition)\n\n  /**\n   * Filters rows using the given SQL expression.\n   * {{{\n   *   peopleDs.where(\"age > 15\")\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def where(conditionExpr: String): Dataset[T] = {\n    filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))\n  }\n```\n## \n\n```\n  /**\n   * Groups the Dataset using the specified columns, so we can run aggregation on them. See\n   * [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * {{{\n   *   // Compute the average for all numeric columns grouped by department.\n   *   ds.groupBy($\"department\").avg()\n   *\n   *   // Compute the max age and average salary, grouped by department and gender.\n   *   ds.groupBy($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def groupBy(cols: Column*): RelationalGroupedDataset = {\n    RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.GroupByType)\n  }\n\n  /**\n   * Create a multi-dimensional rollup for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * {{{\n   *   // Compute the average for all numeric columns rolluped by department and group.\n   *   ds.rollup($\"department\", $\"group\").avg()\n   *\n   *   // Compute the max age and average salary, rolluped by department and gender.\n   *   ds.rollup($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  @scala.annotation.varargs\n  def rollup(cols: Column*): RelationalGroupedDataset = {\n    RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.RollupType)\n  }\n\n  /**\n   * Create a multi-dimensional cube for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * {{{\n   *   // Compute the average for all numeric columns cubed by department and group.\n   *   ds.cube($\"department\", $\"group\").avg()\n   *\n   *   // Compute the max age and average salary, cubed by department and gender.\n   *   ds.cube($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def cube(cols: Column*): RelationalGroupedDataset = {\n    RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.CubeType)\n  }\n\n  /**\n   * Groups the Dataset using the specified columns, so that we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * This is a variant of groupBy that can only group by existing columns using column names\n   * (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // Compute the average for all numeric columns grouped by department.\n   *   ds.groupBy(\"department\").avg()\n   *\n   *   // Compute the max age and average salary, grouped by department and gender.\n   *   ds.groupBy($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def groupBy(col1: String, cols: String*): RelationalGroupedDataset = {\n    val colNames: Seq[String] = col1 +: cols\n    RelationalGroupedDataset(\n      toDF(), colNames.map(colName => resolve(colName)), RelationalGroupedDataset.GroupByType)\n  }\n```\n## reduce\n\n  ```\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Reduces the elements of this Dataset using the specified binary function. The given `func`\n   * must be commutative and associative or the result may be non-deterministic.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  \n  @Experimental\n  @InterfaceStability.Evolving\n  def reduce(func: (T, T) => T): T = rdd.reduce(func)\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Reduces the elements of this Dataset using the specified binary function. The given `func`\n   * must be commutative and associative or the result may be non-deterministic.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def reduce(func: ReduceFunction[T]): T = reduce(func.call(_, _))\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n                                    \n  @Experimental\n  @InterfaceStability.Evolving\n  def groupByKey[K: Encoder](func: T => K): KeyValueGroupedDataset[K, T] = {\n    val inputPlan = logicalPlan\n    val withGroupingKey = AppendColumns(func, inputPlan)\n    val executed = sparkSession.sessionState.executePlan(withGroupingKey)\n\n    new KeyValueGroupedDataset(\n      encoderFor[K],\n      encoderFor[T],\n      executed,\n      inputPlan.output,\n      withGroupingKey.newColumns)\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def groupByKey[K](func: MapFunction[T, K], encoder: Encoder[K]): KeyValueGroupedDataset[K, T] =\n    groupByKey(func.call(_))(encoder)\n```\n## \n```\n  /**\n   * Create a multi-dimensional rollup for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * This is a variant of rollup that can only group by existing columns using column names\n   * (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // Compute the average for all numeric columns rolluped by department and group.\n   *   ds.rollup(\"department\", \"group\").avg()\n   *\n   *   // Compute the max age and average salary, rolluped by department and gender.\n   *   ds.rollup($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def rollup(col1: String, cols: String*): RelationalGroupedDataset = {\n    val colNames: Seq[String] = col1 +: cols\n    RelationalGroupedDataset(\n      toDF(), colNames.map(colName => resolve(colName)), RelationalGroupedDataset.RollupType)\n  }\n\n  /**\n   * Create a multi-dimensional cube for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * This is a variant of cube that can only group by existing columns using column names\n   * (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // Compute the average for all numeric columns cubed by department and group.\n   *   ds.cube(\"department\", \"group\").avg()\n   *\n   *   // Compute the max age and average salary, cubed by department and gender.\n   *   ds.cube($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def cube(col1: String, cols: String*): RelationalGroupedDataset = {\n    val colNames: Seq[String] = col1 +: cols\n    RelationalGroupedDataset(\n      toDF(), colNames.map(colName => resolve(colName)), RelationalGroupedDataset.CubeType)\n  }\n\n  /**\n   * (Scala-specific) Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(\"age\" -> \"max\", \"salary\" -> \"avg\")\n   *   ds.groupBy().agg(\"age\" -> \"max\", \"salary\" -> \"avg\")\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def agg(aggExpr: (String, String), aggExprs: (String, String)*): DataFrame = {\n    groupBy().agg(aggExpr, aggExprs : _*)\n  }\n\n  /**\n   * (Scala-specific) Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   *   ds.groupBy().agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def agg(exprs: Map[String, String]): DataFrame = groupBy().agg(exprs)\n\n  /**\n   * (Java-specific) Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   *   ds.groupBy().agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def agg(exprs: java.util.Map[String, String]): DataFrame = groupBy().agg(exprs)\n\n  /**\n   * Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(max($\"age\"), avg($\"salary\"))\n   *   ds.groupBy().agg(max($\"age\"), avg($\"salary\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def agg(expr: Column, exprs: Column*): DataFrame = groupBy().agg(expr, exprs : _*)\n\n  /**\n   * Returns a new Dataset by taking the first `n` rows. The difference between this function\n   * and `head` is that `head` is an action and returns an array (by triggering query execution)\n   * while `limit` returns a new Dataset.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def limit(n: Int): Dataset[T] = withTypedPlan {\n    Limit(Literal(n), logicalPlan)\n  }\n```\n## \n```\n  /**\n   * Returns a new Dataset containing union of rows in this Dataset and another Dataset.\n   * This is equivalent to `UNION ALL` in SQL.\n   *\n   * To do a SQL-style set union (that does deduplication of elements), use this function followed\n   * by a [[distinct]].\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @deprecated(\"use union()\", \"2.0.0\")\n  def unionAll(other: Dataset[T]): Dataset[T] = union(other)\n\n  /**\n   * Returns a new Dataset containing union of rows in this Dataset and another Dataset.\n   * This is equivalent to `UNION ALL` in SQL.\n   *\n   * To do a SQL-style set union (that does deduplication of elements), use this function followed\n   * by a [[distinct]].\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def union(other: Dataset[T]): Dataset[T] = withSetOperator {\n    // This breaks caching, but it's usually ok because it addresses a very specific use case:\n    // using union to union many files or partitions.\n    CombineUnions(Union(logicalPlan, other.logicalPlan))\n  }\n\n  /**\n   * Returns a new Dataset containing rows only in both this Dataset and another Dataset.\n   * This is equivalent to `INTERSECT` in SQL.\n   *\n   * @note Equality checking is performed directly on the encoded representation of the data\n   * and thus is not affected by a custom `equals` function defined on `T`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def intersect(other: Dataset[T]): Dataset[T] = withSetOperator {\n    Intersect(logicalPlan, other.logicalPlan)\n  }\n\n  /**\n   * Returns a new Dataset containing rows in this Dataset but not in another Dataset.\n   * This is equivalent to `EXCEPT` in SQL.\n   *\n   * @note Equality checking is performed directly on the encoded representation of the data\n   * and thus is not affected by a custom `equals` function defined on `T`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  \n  def except(other: Dataset[T]): Dataset[T] = withSetOperator {\n    Except(logicalPlan, other.logicalPlan)\n  }\n```\n## \n```\n  /**\n   * Returns a new [[Dataset]] by sampling a fraction of rows, using a user-supplied seed.\n   *\n   * @param withReplacement Sample with replacement or not.\n   * @param fraction Fraction of rows to generate.\n   * @param seed Seed for sampling.\n   *\n   * @note This is NOT guaranteed to provide exactly the fraction of the count\n   * of the given [[Dataset]].\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def sample(withReplacement: Boolean, fraction: Double, seed: Long): Dataset[T] = {\n    require(fraction >= 0,\n      s\"Fraction must be nonnegative, but got ${fraction}\")\n\n    withTypedPlan {\n      Sample(0.0, fraction, withReplacement, seed, logicalPlan)()\n    }\n  }\n\n  /**\n   * Returns a new [[Dataset]] by sampling a fraction of rows, using a random seed.\n   *\n   * @param withReplacement Sample with replacement or not.\n   * @param fraction Fraction of rows to generate.\n   *\n   * @note This is NOT guaranteed to provide exactly the fraction of the total count\n   * of the given [[Dataset]].\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  def sample(withReplacement: Boolean, fraction: Double): Dataset[T] = {\n    sample(withReplacement, fraction, Utils.random.nextLong)\n  }\n\n  /**\n   * Randomly splits this Dataset with the provided weights.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @param seed Seed for sampling.\n   *\n   * For Java API, use [[randomSplitAsList]].\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  ???\n  def randomSplit(weights: Array[Double], seed: Long): Array[Dataset[T]] = {\n    require(weights.forall(_ >= 0),\n      s\"Weights must be nonnegative, but got ${weights.mkString(\"[\", \",\", \"]\")}\")\n    require(weights.sum > 0,\n      s\"Sum of weights must be positive, but got ${weights.mkString(\"[\", \",\", \"]\")}\")\n\n    // It is possible that the underlying dataframe doesn't guarantee the ordering of rows in its\n    // constituent partitions each time a split is materialized which could result in\n    // overlapping splits. To prevent this, we explicitly sort each input partition to make the\n    // ordering deterministic.\n    // MapType cannot be sorted.\n    val sorted = Sort(logicalPlan.output.filterNot(_.dataType.isInstanceOf[MapType])\n      .map(SortOrder(_, Ascending)), global = false, logicalPlan)\n    val sum = weights.sum\n    val normalizedCumWeights = weights.map(_ / sum).scanLeft(0.0d)(_ + _)\n    normalizedCumWeights.sliding(2).map { x =>\n      new Dataset[T](\n        sparkSession, Sample(x(0), x(1), withReplacement = false, seed, sorted)(), encoder)\n    }.toArray\n  }\n\n  /**\n   * Returns a Java list that contains randomly split Dataset with the provided weights.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @param seed Seed for sampling.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def randomSplitAsList(weights: Array[Double], seed: Long): java.util.List[Dataset[T]] = {\n    val values = randomSplit(weights, seed)\n    java.util.Arrays.asList(values : _*)\n  }\n\n  /**\n   * Randomly splits this Dataset with the provided weights.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def randomSplit(weights: Array[Double]): Array[Dataset[T]] = {\n    randomSplit(weights, Utils.random.nextLong)\n  }\n\n  /**\n   * Randomly splits this Dataset with the provided weights. Provided for the Python Api.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @param seed Seed for sampling.\n   */\n  private[spark] def randomSplit(weights: List[Double], seed: Long): Array[Dataset[T]] = {\n    randomSplit(weights.toArray, seed)\n  }\n\n  /**\n   * (Scala-specific) Returns a new Dataset where each row has been expanded to zero or more\n   * rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. The columns of\n   * the input row are implicitly joined with each row that is output by the function.\n   *\n   * Given that this is deprecated, as an alternative, you can explode columns either using\n   * `functions.explode()` or `flatMap()`. The following example uses these alternatives to count\n   * the number of books that contain a given word:\n   *\n   * {{{\n   *   case class Book(title: String, words: String)\n   *   val ds: Dataset[Book]\n   *\n   *   val allWords = ds.select('title, explode(split('words, \" \")).as(\"word\"))\n   *\n   *   val bookCountPerWord = allWords.groupBy(\"word\").agg(countDistinct(\"title\"))\n   * }}}\n   *\n   * Using `flatMap()` this can similarly be exploded as:\n   *\n   * {{{\n   *   ds.flatMap(_.words.split(\" \"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  @deprecated(\"use flatMap() or select() with functions.explode() instead\", \"2.0.0\")\n  def explode[A <: Product : TypeTag](input: Column*)(f: Row => TraversableOnce[A]): DataFrame = {\n    val elementSchema = ScalaReflection.schemaFor[A].dataType.asInstanceOf[StructType]\n\n    val convert = CatalystTypeConverters.createToCatalystConverter(elementSchema)\n\n    val rowFunction =\n      f.andThen(_.map(convert(_).asInstanceOf[InternalRow]))\n    val generator = UserDefinedGenerator(elementSchema, rowFunction, input.map(_.expr))\n\n    withPlan {\n      Generate(generator, join = true, outer = false,\n        qualifier = None, generatorOutput = Nil, logicalPlan)\n    }\n  }\n\n  /**\n   * (Scala-specific) Returns a new Dataset where a single column has been expanded to zero\n   * or more rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. All\n   * columns of the input row are implicitly joined with each value that is output by the function.\n   *\n   * Given that this is deprecated, as an alternative, you can explode columns either using\n   * `functions.explode()`:\n   *\n   * {{{\n   *   ds.select(explode(split('words, \" \")).as(\"word\"))\n   * }}}\n   *\n   * or `flatMap()`:\n   *\n   * {{{\n   *   ds.flatMap(_.words.split(\" \"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @deprecated(\"use flatMap() or select() with functions.explode() instead\", \"2.0.0\")\n  def explode[A, B : TypeTag](inputColumn: String, outputColumn: String)(f: A => TraversableOnce[B])\n    : DataFrame = {\n    val dataType = ScalaReflection.schemaFor[B].dataType\n    val attributes = AttributeReference(outputColumn, dataType)() :: Nil\n    // TODO handle the metadata?\n    val elementSchema = attributes.toStructType\n\n    def rowFunction(row: Row): TraversableOnce[InternalRow] = {\n      val convert = CatalystTypeConverters.createToCatalystConverter(dataType)\n      f(row(0).asInstanceOf[A]).map(o => InternalRow(convert(o)))\n    }\n    val generator = UserDefinedGenerator(elementSchema, rowFunction, apply(inputColumn).expr :: Nil)\n\n    withPlan {\n      Generate(generator, join = true, outer = false,\n        qualifier = None, generatorOutput = Nil, logicalPlan)\n    }\n  }\n## \n  /**\n   * Returns a new Dataset by adding a column or replacing the existing column that has\n   * the same name.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  def withColumn(colName: String, col: Column): DataFrame = {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val output = queryExecution.analyzed.output\n    val shouldReplace = output.exists(f => resolver(f.name, colName))\n    if (shouldReplace) {\n      val columns = output.map { field =>\n        if (resolver(field.name, colName)) {\n          col.as(colName)\n        } else {\n          Column(field)\n        }\n      }\n      select(columns : _*)\n    } else {\n      select(Column(\"*\"), col.as(colName))\n    }\n  }\n\n  /**\n   * Returns a new Dataset by adding a column with metadata.\n   */\n  private[spark] def withColumn(colName: String, col: Column, metadata: Metadata): DataFrame = {\n    withColumn(colName, col.as(colName, metadata))\n  }\n\n  /**\n   * Returns a new Dataset with a column renamed.\n   * This is a no-op if schema doesn't contain existingName.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def withColumnRenamed(existingName: String, newName: String): DataFrame = {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val output = queryExecution.analyzed.output\n    val shouldRename = output.exists(f => resolver(f.name, existingName))\n    if (shouldRename) {\n      val columns = output.map { col =>\n        if (resolver(col.name, existingName)) {\n          Column(col).as(newName)\n        } else {\n          Column(col)\n        }\n      }\n      select(columns : _*)\n    } else {\n      toDF()\n    }\n  }\n\n  /**\n   * Returns a new Dataset with a column dropped. This is a no-op if schema doesn't contain\n   * column name.\n   *\n   * This method can only be used to drop top level columns. the colName string is treated\n   * literally without further interpretation.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  def drop(colName: String): DataFrame = {\n    drop(Seq(colName) : _*)\n  }\n\n  /**\n   * Returns a new Dataset with columns dropped.\n   * This is a no-op if schema doesn't contain column name(s).\n   *\n   * This method can only be used to drop top level columns. the colName string is treated literally\n   * without further interpretation.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def drop(colNames: String*): DataFrame = {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val allColumns = queryExecution.analyzed.output\n    val remainingCols = allColumns.filter { attribute =>\n      colNames.forall(n => !resolver(attribute.name, n))\n    }.map(attribute => Column(attribute))\n    if (remainingCols.size == allColumns.size) {\n      toDF()\n    } else {\n      this.select(remainingCols: _*)\n    }\n  }\n\n  /**\n   * Returns a new Dataset with a column dropped.\n   * This version of drop accepts a [[Column]] rather than a name.\n   * This is a no-op if the Dataset doesn't have a column\n   * with an equivalent expression.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def drop(col: Column): DataFrame = {\n    val expression = col match {\n      case Column(u: UnresolvedAttribute) =>\n        queryExecution.analyzed.resolveQuoted(\n          u.name, sparkSession.sessionState.analyzer.resolver).getOrElse(u)\n      case Column(expr: Expression) => expr\n    }\n    val attrs = this.logicalPlan.output\n    val colsAfterDrop = attrs.filter { attr =>\n      attr != expression\n    }.map(attr => Column(attr))\n    select(colsAfterDrop : _*)\n  }\n```\n## \n```\n  /**\n   * Returns a new Dataset that contains only the unique rows from this Dataset.\n   * This is an alias for `distinct`.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  \n  def dropDuplicates(): Dataset[T] = dropDuplicates(this.columns)\n\n  /**\n   * (Scala-specific) Returns a new Dataset with duplicate rows removed, considering only\n   * the subset of columns.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def dropDuplicates(colNames: Seq[String]): Dataset[T] = withTypedPlan {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val allColumns = queryExecution.analyzed.output\n    val groupCols = colNames.toSet.toSeq.flatMap { (colName: String) =>\n      // It is possibly there are more than one columns with the same name,\n      // so we call filter instead of find.\n      val cols = allColumns.filter(col => resolver(col.name, colName))\n      if (cols.isEmpty) {\n        throw new AnalysisException(\n          s\"\"\"Cannot resolve column name \"$colName\" among (${schema.fieldNames.mkString(\", \")})\"\"\")\n      }\n      cols\n    }\n    Deduplicate(groupCols, logicalPlan, isStreaming)\n  }\n\n  /**\n   * Returns a new Dataset with duplicate rows removed, considering only\n   * the subset of columns.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def dropDuplicates(colNames: Array[String]): Dataset[T] = dropDuplicates(colNames.toSeq)\n\n  /**\n   * Returns a new [[Dataset]] with duplicate rows removed, considering only\n   * the subset of columns.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def dropDuplicates(col1: String, cols: String*): Dataset[T] = {\n    val colNames: Seq[String] = col1 +: cols\n    dropDuplicates(colNames)\n  }\n  ```\n## \n    ```\n  /**\n   * Computes statistics for numeric and string columns, including count, mean, stddev, min, and\n   * max. If no columns are given, this function computes statistics for all numerical or string\n   * columns.\n   *\n   * This function is meant for exploratory data analysis, as we make no guarantee about the\n   * backward compatibility of the schema of the resulting Dataset. If you want to\n   * programmatically compute summary statistics, use the `agg` function instead.\n   *\n   * {{{\n   *   ds.describe(\"age\", \"height\").show()\n   *\n   *   // output:\n   *   // summary age   height\n   *   // count   10.0  10.0\n   *   // mean    53.3  178.05\n   *   // stddev  11.6  15.7\n   *   // min     18.0  163.0\n   *   // max     92.0  192.0\n   * }}}\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  \n  @scala.annotation.varargs\n  def describe(cols: String*): DataFrame = withPlan {\n\n    // The list of summary statistics to compute, in the form of expressions.\n    val statistics = List[(String, Expression => Expression)](\n      \"count\" -> ((child: Expression) => Count(child).toAggregateExpression()),\n      \"mean\" -> ((child: Expression) => Average(child).toAggregateExpression()),\n      \"stddev\" -> ((child: Expression) => StddevSamp(child).toAggregateExpression()),\n      \"min\" -> ((child: Expression) => Min(child).toAggregateExpression()),\n      \"max\" -> ((child: Expression) => Max(child).toAggregateExpression()))\n\n    val outputCols =\n      (if (cols.isEmpty) aggregatableColumns.map(usePrettyExpression(_).sql) else cols).toList\n\n    val ret: Seq[Row] = if (outputCols.nonEmpty) {\n      val aggExprs = statistics.flatMap { case (_, colToAgg) =>\n        outputCols.map(c => Column(Cast(colToAgg(Column(c).expr), StringType)).as(c))\n      }\n\n      val row = groupBy().agg(aggExprs.head, aggExprs.tail: _*).head().toSeq\n\n      // Pivot the data so each summary is one row\n      row.grouped(outputCols.size).toSeq.zip(statistics).map { case (aggregation, (statistic, _)) =>\n        Row(statistic :: aggregation.toList: _*)\n      }\n    } else {\n      // If there are no output columns, just output a single column that contains the stats.\n      statistics.map { case (name, _) => Row(name) }\n    }\n\n    // All columns are string type\n    val schema = StructType(\n      StructField(\"summary\", StringType) :: outputCols.map(StructField(_, StringType))).toAttributes\n    // `toArray` forces materialization to make the seq serializable\n    LocalRelation.fromExternalRows(schema, ret.toArray.toSeq)\n  }\n\n  /**\n   * Returns the first `n` rows.\n   *\n   * @note this method should only be used if the resulting array is expected to be small, as\n   * all the data is loaded into the driver's memory.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  n\n  def head(n: Int): Array[T] = withAction(\"head\", limit(n).queryExecution)(collectFromPlan)\n\n  /**\n   * Returns the first row.\n   * @group action\n   * @since 1.6.0\n   */\n  def head(): T = head(1).head\n\n  /**\n   * Returns the first row. Alias for head().\n   * @group action\n   * @since 1.6.0\n   */\n  def first(): T = head()\n\n  /**\n   * Concise syntax for chaining custom transformations.\n   * {{{\n   *   def featurize(ds: Dataset[T]): Dataset[U] = ...\n   *\n   *   ds\n   *     .transform(featurize)\n   *     .transform(...)\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  def transform[U](t: Dataset[T] => Dataset[U]): Dataset[U] = t(this)\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset that only contains elements where `func` returns `true`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  @Experimental\n  @InterfaceStability.Evolving\n  def filter(func: T => Boolean): Dataset[T] = {\n    withTypedPlan(TypedFilter(func, logicalPlan))\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset that only contains elements where `func` returns `true`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def filter(func: FilterFunction[T]): Dataset[T] = {\n    withTypedPlan(TypedFilter(func, logicalPlan))\n  }\n```\n## \n  ```\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset that contains the result of applying `func` to each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  @Experimental\n  @InterfaceStability.Evolving\n  def map[U : Encoder](func: T => U): Dataset[U] = withTypedPlan {\n    MapElements[T, U](func, logicalPlan)\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset that contains the result of applying `func` to each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def map[U](func: MapFunction[T, U], encoder: Encoder[U]): Dataset[U] = {\n    implicit val uEnc = encoder\n    withTypedPlan(MapElements[T, U](func, logicalPlan))\n  }\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset that contains the result of applying `func` to each partition.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def mapPartitions[U : Encoder](func: Iterator[T] => Iterator[U]): Dataset[U] = {\n    new Dataset[U](\n      sparkSession,\n      MapPartitions[T, U](func, logicalPlan),\n      implicitly[Encoder[U]])\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset that contains the result of applying `f` to each partition.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def mapPartitions[U](f: MapPartitionsFunction[T, U], encoder: Encoder[U]): Dataset[U] = {\n    val func: (Iterator[T]) => Iterator[U] = x => f.call(x.asJava).asScala\n    mapPartitions(func)(encoder)\n  }\n\n  /**\n   * Returns a new `DataFrame` that contains the result of applying a serialized R function\n   * `func` to each partition.\n   */\n  private[sql] def mapPartitionsInR(\n      func: Array[Byte],\n      packageNames: Array[Byte],\n      broadcastVars: Array[Broadcast[Object]],\n      schema: StructType): DataFrame = {\n    val rowEncoder = encoder.asInstanceOf[ExpressionEncoder[Row]]\n    Dataset.ofRows(\n      sparkSession,\n      MapPartitionsInR(func, packageNames, broadcastVars, schema, rowEncoder, logicalPlan))\n  }\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset by first applying a function to all elements of this Dataset,\n   * and then flattening the results.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def flatMap[U : Encoder](func: T => TraversableOnce[U]): Dataset[U] =\n    mapPartitions(_.flatMap(func))\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset by first applying a function to all elements of this Dataset,\n   * and then flattening the results.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def flatMap[U](f: FlatMapFunction[T, U], encoder: Encoder[U]): Dataset[U] = {\n    val func: (T) => Iterator[U] = x => f.call(x).asScala\n    flatMap(func)(encoder)\n  }\n\n  /**\n   * Applies a function `f` to all rows.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreach(f: T => Unit): Unit = withNewExecutionId {\n    rdd.foreach(f)\n  }\n\n  /**\n   * (Java-specific)\n   * Runs `func` on each element of this Dataset.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreach(func: ForeachFunction[T]): Unit = foreach(func.call(_))\n\n  /**\n   * Applies a function `f` to each partition of this Dataset.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreachPartition(f: Iterator[T] => Unit): Unit = withNewExecutionId {\n    rdd.foreachPartition(f)\n  }\n```\n## \n  ```\n  /**\n   * (Java-specific)\n   * Runs `func` on each partition of this Dataset.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreachPartition(func: ForeachPartitionFunction[T]): Unit =\n    foreachPartition(it => func.call(it.asJava))\n\n  /**\n   * Returns the first `n` rows in the Dataset.\n   *\n   * Running take requires moving data into the application's driver process, and doing so with\n   * a very large `n` can crash the driver process with OutOfMemoryError.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def take(n: Int): Array[T] = head(n)\n\n  /**\n   * Returns the first `n` rows in the Dataset as a list.\n   *\n   * Running take requires moving data into the application's driver process, and doing so with\n   * a very large `n` can crash the driver process with OutOfMemoryError.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n    \n  def takeAsList(n: Int): java.util.List[T] = java.util.Arrays.asList(take(n) : _*)\n\n  /**\n   * Returns an array that contains all rows in this Dataset.\n   *\n   * Running collect requires moving all the data into the application's driver process, and\n   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.\n   *\n   * For Java API, use [[collectAsList]].\n   *\n   * @group action\n   * @since 1.6.0\n   */\n\n\n  def collect(): Array[T] = withAction(\"collect\", queryExecution)(collectFromPlan)\n\n  /**\n   * Returns a Java list that contains all rows in this Dataset.\n   *\n   * Running collect requires moving all the data into the application's driver process, and\n   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def collectAsList(): java.util.List[T] = withAction(\"collectAsList\", queryExecution) { plan =>\n    val values = collectFromPlan(plan)\n    java.util.Arrays.asList(values : _*)\n  }\n\n  /**\n   * Return an iterator that contains all rows in this Dataset.\n   *\n   * The iterator will consume as much memory as the largest partition in this Dataset.\n   *\n   * @note this results in multiple Spark jobs, and if the input Dataset is the result\n   * of a wide transformation (e.g. join with different partitioners), to avoid\n   * recomputing the input Dataset should be cached first.\n   *\n   * @group action\n   * @since 2.0.0\n   */\n  def toLocalIterator(): java.util.Iterator[T] = {\n    withAction(\"toLocalIterator\", queryExecution) { plan =>\n      plan.executeToIterator().map(boundEnc.fromRow).asJava\n    }\n  }\n\n  /**\n   * Returns the number of rows in the Dataset.\n   * @group action\n   * @since 1.6.0\n   */\n  \n  def count(): Long = withAction(\"count\", groupBy().count().queryExecution) { plan =>\n    plan.executeCollect().head.getLong(0)\n  }\n  ```\n## \n    ```\n  /**\n   * Returns a new Dataset that has exactly `numPartitions` partitions.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  def repartition(numPartitions: Int): Dataset[T] = withTypedPlan {\n    Repartition(numPartitions, shuffle = true, logicalPlan)\n  }\n\n  /**\n   * Returns a new Dataset partitioned by the given partitioning expressions into\n   * `numPartitions`. The resulting Dataset is hash partitioned.\n   *\n   * This is the same operation as \"DISTRIBUTE BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def repartition(numPartitions: Int, partitionExprs: Column*): Dataset[T] = withTypedPlan {\n    RepartitionByExpression(partitionExprs.map(_.expr), logicalPlan, numPartitions)\n  }\n\n  /**\n   * Returns a new Dataset partitioned by the given partitioning expressions, using\n   * `spark.sql.shuffle.partitions` as number of partitions.\n   * The resulting Dataset is hash partitioned.\n   *\n   * This is the same operation as \"DISTRIBUTE BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def repartition(partitionExprs: Column*): Dataset[T] = withTypedPlan {\n    RepartitionByExpression(\n      partitionExprs.map(_.expr), logicalPlan, sparkSession.sessionState.conf.numShufflePartitions)\n  }\n\n  /**\n   * Returns a new Dataset that has exactly `numPartitions` partitions.\n   * Similar to coalesce defined on an `RDD`, this operation results in a narrow dependency, e.g.\n   * if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of\n   * the 100 new partitions will claim 10 of the current partitions.  If a larger number of\n   * partitions is requested, it will stay at the current number of partitions.\n   *\n   * However, if you're doing a drastic coalesce, e.g. to numPartitions = 1,\n   * this may result in your computation taking place on fewer nodes than\n   * you like (e.g. one node in the case of numPartitions = 1). To avoid this,\n   * you can call repartition. This will add a shuffle step, but means the\n   * current upstream partitions will be executed in parallel (per whatever\n   * the current partitioning is).\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def coalesce(numPartitions: Int): Dataset[T] = withTypedPlan {\n    Repartition(numPartitions, shuffle = false, logicalPlan)\n  }\n\n  /**\n   * Returns a new Dataset that contains only the unique rows from this Dataset.\n   * This is an alias for `dropDuplicates`.\n   *\n   * @note Equality checking is performed directly on the encoded representation of the data\n   * and thus is not affected by a custom `equals` function defined on `T`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def distinct(): Dataset[T] = dropDuplicates()\n\n```\n## \n  rddrdd\n\n```\n  /**\n   * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n                  \n  def persist(): this.type = {\n    sparkSession.sharedState.cacheManager.cacheQuery(this)\n    this\n  }\n\n  /**\n   * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def cache(): this.type = persist()\n\n  /**\n   * Persist this Dataset with the given storage level.\n   * @param newLevel One of: `MEMORY_ONLY`, `MEMORY_AND_DISK`, `MEMORY_ONLY_SER`,\n   *                 `MEMORY_AND_DISK_SER`, `DISK_ONLY`, `MEMORY_ONLY_2`,\n   *                 `MEMORY_AND_DISK_2`, etc.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def persist(newLevel: StorageLevel): this.type = {\n    sparkSession.sharedState.cacheManager.cacheQuery(this, None, newLevel)\n    this\n  }\n\n  /**\n   * Get the Dataset's current storage level, or StorageLevel.NONE if not persisted.\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  def storageLevel: StorageLevel = {\n    sparkSession.sharedState.cacheManager.lookupCachedData(this).map { cachedData =>\n      cachedData.cachedRepresentation.storageLevel\n    }.getOrElse(StorageLevel.NONE)\n  }\n\n  /**\n   * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.\n   *\n   * @param blocking Whether to block until all blocks are deleted.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def unpersist(blocking: Boolean): this.type = {\n    sparkSession.sharedState.cacheManager.uncacheQuery(this, blocking)\n    this\n  }\n\n  /**\n   * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def unpersist(): this.type = unpersist(blocking = false)\n\n  /**\n   * Represents the content of the Dataset as an `RDD` of `T`.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  lazy val rdd: RDD[T] = {\n    val objectType = exprEnc.deserializer.dataType\n    val deserialized = CatalystSerde.deserialize[T](logicalPlan)\n    sparkSession.sessionState.executePlan(deserialized).toRdd.mapPartitions { rows =>\n      rows.map(_.get(0, objectType).asInstanceOf[T])\n    }\n  }\n\n  /**\n   * Returns the content of the Dataset as a `JavaRDD` of `T`s.\n   * @group basic\n   * @since 1.6.0\n   */\n  def toJavaRDD: JavaRDD[T] = rdd.toJavaRDD()\n\n  /**\n   * Returns the content of the Dataset as a `JavaRDD` of `T`s.\n   * @group basic\n   * @since 1.6.0\n   */\n  def javaRDD: JavaRDD[T] = toJavaRDD\n```\n## \ndatasetsqldataset\n```\n  /**\n   * Registers this Dataset as a temporary table using the given name. The lifetime of this\n   * temporary table is tied to the [[SparkSession]] that was used to create this Dataset.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  \n  @deprecated(\"Use createOrReplaceTempView(viewName) instead.\", \"2.0.0\")\n  def registerTempTable(tableName: String): Unit = {\n    createOrReplaceTempView(tableName)\n  }\n\n  /**\n   * Creates a local temporary view using the given name. The lifetime of this\n   * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.\n   *\n   * Local temporary view is session-scoped. Its lifetime is the lifetime of the session that\n   * created it, i.e. it will be automatically dropped when the session terminates. It's not\n   * tied to any databases, i.e. we can't use `db1.view1` to reference a local temporary view.\n   *\n   * @throws AnalysisException if the view name is invalid or already exists\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  \n  @throws[AnalysisException]\n  def createTempView(viewName: String): Unit = withPlan {\n    createTempViewCommand(viewName, replace = false, global = false)\n  }\n\n\n\n  /**\n   * Creates a local temporary view using the given name. The lifetime of this\n   * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  def createOrReplaceTempView(viewName: String): Unit = withPlan {\n    createTempViewCommand(viewName, replace = true, global = false)\n  }\n\n  /**\n   * Creates a global temporary view using the given name. The lifetime of this\n   * temporary view is tied to this Spark application.\n   *\n   * Global temporary view is cross-session. Its lifetime is the lifetime of the Spark application,\n   * i.e. it will be automatically dropped when the application terminates. It's tied to a system\n   * preserved database `global_temp`, and we must use the qualified name to refer a global temp\n   * view, e.g. `SELECT * FROM global_temp.view1`.\n   *\n   * @throws AnalysisException if the view name is invalid or already exists\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  @throws[AnalysisException]\n  def createGlobalTempView(viewName: String): Unit = withPlan {\n    createTempViewCommand(viewName, replace = false, global = true)\n  }\n\n  private def createTempViewCommand(\n      viewName: String,\n      replace: Boolean,\n      global: Boolean): CreateViewCommand = {\n    val viewType = if (global) GlobalTempView else LocalTempView\n\n    val tableIdentifier = try {\n      sparkSession.sessionState.sqlParser.parseTableIdentifier(viewName)\n    } catch {\n      case _: ParseException => throw new AnalysisException(s\"Invalid view name: $viewName\")\n    }\n    CreateViewCommand(\n      name = tableIdentifier,\n      userSpecifiedColumns = Nil,\n      comment = None,\n      properties = Map.empty,\n      originalText = None,\n      child = logicalPlan,\n      allowExisting = false,\n      replace = replace,\n      viewType = viewType)\n  }\n  ```\n## \n    writewritewrite\n```\n  /**\n   * Interface for saving the content of the non-streaming Dataset out into external storage.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def write: DataFrameWriter[T] = {\n    if (isStreaming) {\n      logicalPlan.failAnalysis(\n        \"'write' can not be called on streaming Dataset/DataFrame\")\n    }\n    new DataFrameWriter[T](this)\n  }\n\n  /**\n   * :: Experimental ::\n   * Interface for saving the content of the streaming Dataset out into external storage.\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def writeStream: DataStreamWriter[T] = {\n    if (!isStreaming) {\n      logicalPlan.failAnalysis(\n        \"'writeStream' can be called only on streaming Dataset/DataFrame\")\n    }\n    new DataStreamWriter[T](this)\n  }\n\n```\n## json\n```\n  /**\n   * Returns the content of the Dataset as a Dataset of JSON strings.\n   * @since 2.0.0\n   */\n  def toJSON: Dataset[String] = {\n    val rowSchema = this.schema\n    val sessionLocalTimeZone = sparkSession.sessionState.conf.sessionLocalTimeZone\n    val rdd: RDD[String] = queryExecution.toRdd.mapPartitions { iter =>\n      val writer = new CharArrayWriter()\n      // create the Generator without separator inserted between 2 records\n      val gen = new JacksonGenerator(rowSchema, writer,\n        new JSONOptions(Map.empty[String, String], sessionLocalTimeZone))\n\n      new Iterator[String] {\n        override def hasNext: Boolean = iter.hasNext\n        override def next(): String = {\n          gen.write(iter.next())\n          gen.flush()\n\n          val json = writer.toString\n          if (hasNext) {\n            writer.reset()\n          } else {\n            gen.close()\n          }\n\n          json\n        }\n      }\n    }\n    import sparkSession.implicits.newStringEncoder\n    sparkSession.createDataset(rdd)\n  }\n  ```\n##  \n  dataSet\n  ```\n  /**\n   * Returns a best-effort snapshot of the files that compose this Dataset. This method simply\n   * asks each constituent BaseRelation for its respective files and takes the union of all results.\n   * Depending on the source relations, this may not find all input files. Duplicates are removed.\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  def inputFiles: Array[String] = {\n    val files: Seq[String] = queryExecution.optimizedPlan.collect {\n      case LogicalRelation(fsBasedRelation: FileRelation, _, _) =>\n        fsBasedRelation.inputFiles\n      case fr: FileRelation =>\n        fr.inputFiles\n    }.flatten\n    files.toSet.toArray\n  }\n```\n","source":"_posts/spark1.md","raw":"---\ntitle: spark  sparksql DataSet\ndate: 2017-03-11\ncategory: spark\ntags: \n  - spark\n  - \n---\nsparksqldataframe sparkspark,.\n:spark 2.0.1\n<!-- more -->\n## \nshowString sparkshowshowString\n```\n  /**\n   * Compose the string representing rows for output\n   *\n   * @param _numRows Number of rows to show\n   * @param truncate If set to more than 0, truncates strings to `truncate` characters and\n   *                   all cells will be aligned right.\n   */\n  private[sql] def showString(_numRows: Int, truncate: Int = 20): String \n```\n## dataSetdataFrame\n   dataframdataset\n```\n  /**\n   * Converts this strongly typed collection of data to generic `DataFrame` with columns renamed.\n   * This can be quite convenient in conversion from an RDD of tuples into a `DataFrame` with\n   * meaningful names. For example:\n   * {{{\n   *   val rdd: RDD[(Int, String)] = ...\n   *   rdd.toDF()  // this implicit conversion creates a DataFrame with column name `_1` and `_2`\n   *   rdd.toDF(\"id\", \"name\")  // this creates a DataFrame with column name \"id\" and \"name\"\n   * }}}\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def toDF(colNames: String*): DataFrame = {\n    require(schema.size == colNames.size,\n      \"The number of columns doesn't match.\\n\" +\n        s\"Old column names (${schema.size}): \" + schema.fields.map(_.name).mkString(\", \") + \"\\n\" +\n        s\"New column names (${colNames.size}): \" + colNames.mkString(\", \"))\n\n    val newCols = logicalPlan.output.zip(colNames).map { case (oldAttribute, newName) =>\n      Column(oldAttribute).as(newName)\n    }\n    select(newCols : _*)\n  }\n```\ndataset\n```\n  /**\n   * Returns the schema of this Dataset.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def schema: StructType = queryExecution.analyzed.schema\n\n  /**\n   * Prints the schema to the console in a nice tree format.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  // scalastyle:off println\n  def printSchema(): Unit = println(schema.treeString)\n  // scalastyle:on println\n```\n\n```\n  /**\n   * Prints the plans (logical and physical) to the console for debugging purposes.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def explain(extended: Boolean): Unit = {\n    val explain = ExplainCommand(queryExecution.logical, extended = extended)\n    sparkSession.sessionState.executePlan(explain).executedPlan.executeCollect().foreach {\n      // scalastyle:off println\n      r => println(r.getString(0))\n      // scalastyle:on println\n    }\n  }\n\n  /**\n   * Prints the physical plan to the console for debugging purposes.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def explain(): Unit = explain(extended = false)\n```\n\n```\n  /**\n   * Returns all column names and their data types as an array.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def dtypes: Array[(String, String)] = schema.fields.map { field =>\n    (field.name, field.dataType.toString)\n  }\n\n  /**\n   * Returns all column names as an array.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def columns: Array[String] = schema.fields.map(_.name)\n```\n\n```\n  /**\n   * Returns true if the `collect` and `take` methods can be run locally\n   * (without any Spark executors).\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def isLocal: Boolean = logicalPlan.isInstanceOf[LocalRelation]\n\n  /**\n   * Returns true if this Dataset contains one or more sources that continuously\n   * return data as it arrives. A Dataset that reads data from a streaming source\n   * must be executed as a `StreamingQuery` using the `start()` method in\n   * `DataStreamWriter`. Methods that return a single answer, e.g. `count()` or\n   * `collect()`, will throw an [[AnalysisException]] when there is a streaming\n   * source present.\n   *\n   * @group streaming\n   * @since 2.0.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def isStreaming: Boolean = logicalPlan.isStreaming\n```\n****\n```\n  /**\n   * Eagerly checkpoint a Dataset and return the new Dataset. Checkpointing can be used to truncate\n   * the logical plan of this Dataset, which is especially useful in iterative algorithms where the\n   * plan may grow exponentially. It will be saved to files inside the checkpoint\n   * directory set with `SparkContext#setCheckpointDir`.\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def checkpoint(): Dataset[T] = checkpoint(eager = true)\n\n  /**\n   * Returns a checkpointed version of this Dataset. Checkpointing can be used to truncate the\n   * logical plan of this Dataset, which is especially useful in iterative algorithms where the\n   * plan may grow exponentially. It will be saved to files inside the checkpoint\n   * directory set with `SparkContext#setCheckpointDir`.\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def checkpoint(eager: Boolean): Dataset[T] = {\n    val internalRdd = queryExecution.toRdd.map(_.copy())\n    internalRdd.checkpoint()\n\n    if (eager) {\n      internalRdd.count()\n    }\n\n    val physicalPlan = queryExecution.executedPlan\n```\n\n```\n    // Takes the first leaf partitioning whenever we see a `PartitioningCollection`. Otherwise the\n    // size of `PartitioningCollection` may grow exponentially for queries involving deep inner\n    // joins.\n    def firstLeafPartitioning(partitioning: Partitioning): Partitioning = {\n      partitioning match {\n        case p: PartitioningCollection => firstLeafPartitioning(p.partitionings.head)\n        case p => p\n      }\n    }\n\n    val outputPartitioning = firstLeafPartitioning(physicalPlan.outputPartitioning)\n\n    Dataset.ofRows(\n      sparkSession,\n      LogicalRDD(\n        logicalPlan.output,\n        internalRdd,\n        outputPartitioning,\n        physicalPlan.outputOrdering\n      )(sparkSession)).as[T]\n  }\n```\n\n```\n  /**\n   * :: Experimental ::\n   * Defines an event time watermark for this [[Dataset]]. A watermark tracks a point in time\n   * before which we assume no more late data is going to arrive.\n   *\n   * Spark will use this watermark for several purposes:\n   *  - To know when a given time window aggregation can be finalized and thus can be emitted when\n   *    using output modes that do not allow updates.\n   *  - To minimize the amount of state that we need to keep for on-going aggregations,\n   *    `mapGroupsWithState` and `dropDuplicates` operators.\n   *\n   *  The current watermark is computed by looking at the `MAX(eventTime)` seen across\n   *  all of the partitions in the query minus a user specified `delayThreshold`.  Due to the cost\n   *  of coordinating this value across partitions, the actual watermark used is only guaranteed\n   *  to be at least `delayThreshold` behind the actual event time.  In some cases we may still\n   *  process records that arrive more than `delayThreshold` late.\n   *\n   * @param eventTime the name of the column that contains the event time of the row.\n   * @param delayThreshold the minimum delay to wait to data to arrive late, relative to the latest\n   *                       record that has been processed in the form of an interval\n   *                       (e.g. \"1 minute\" or \"5 hours\").\n   *\n   * @group streaming\n   * @since 2.1.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  // We only accept an existing column name, not a derived column here as a watermark that is\n  // defined on a derived column cannot referenced elsewhere in the plan.\n  def withWatermark(eventTime: String, delayThreshold: String): Dataset[T] = withTypedPlan {\n    val parsedDelay =\n      Option(CalendarInterval.fromString(\"interval \" + delayThreshold))\n        .getOrElse(throw new AnalysisException(s\"Unable to parse time delay '$delayThreshold'\"))\n    EventTimeWatermark(UnresolvedAttribute(eventTime), parsedDelay, logicalPlan)\n  }\n```\n## \n```\n  /**\n   * Displays the Dataset in a tabular form. Strings more than 20 characters will be truncated,\n   * and all cells will be aligned right. For example:\n   * {{{\n   *   year  month AVG('Adj Close) MAX('Adj Close)\n   *   1980  12    0.503218        0.595103\n   *   1981  01    0.523289        0.570307\n   *   1982  02    0.436504        0.475256\n   *   1983  03    0.410516        0.442194\n   *   1984  04    0.450090        0.483521\n   * }}}\n   *\n   * @param numRows Number of rows to show\n   *\n   * @group action\n   * @since 1.6.0\n   */\ndatafram20\n  def show(numRows: Int): Unit = show(numRows, truncate = true)\n\ndatafram2020\n  \n  def show(): Unit = show(20)\n\ndatafram20truncate\n  def show(truncate: Boolean): Unit = show(20, truncate)\n\ndataframnumRowstruncate\n  def show(numRows: Int, truncate: Boolean): Unit = if (truncate) {\n  def show(numRows: Int, truncate: Int): Unit = println(showString(numRows, truncate))\n```\n## \n```\n\ndataset\n  def na: DataFrameNaFunctions = new DataFrameNaFunctions(toDF())\n\ndataset\n  def stat: DataFrameStatFunctions = new DataFrameStatFunctions(toDF())\ndataframe\n  def join(right: Dataset[_]): DataFrame = withPlan {\n    Join(logicalPlan, right.logicalPlan, joinType = Inner, None)\n  }\n\n  /**\n   * Inner equi-join with another `DataFrame` using the given column.\n   *\n   * Different from other join functions, the join column will only appear once in the output,\n   * i.e. similar to SQL's `JOIN USING` syntax.\n   *\n   * {{{\n   *   // Joining df1 and df2 using the column \"user_id\"\n   *   df1.join(df2, \"user_id\")\n   * }}}\n   *\n   * @param right Right side of the join operation.\n   * @param usingColumn Name of the column to join on. This column must exist on both sides.\n   *\n   * @note If you perform a self-join using this function without aliasing the input\n   * `DataFrame`s, you will NOT be able to reference any columns after the join, since\n   * there is no way to disambiguate which side of the join you would like to reference.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], usingColumn: String): DataFrame = {\n    join(right, Seq(usingColumn))\n  }\n\n  /**\n   * Inner equi-join with another `DataFrame` using the given columns.\n   *\n   * Different from other join functions, the join columns will only appear once in the output,\n   * i.e. similar to SQL's `JOIN USING` syntax.\n   *\n   * {{{\n   *   // Joining df1 and df2 using the columns \"user_id\" and \"user_name\"\n   *   df1.join(df2, Seq(\"user_id\", \"user_name\"))\n   * }}}\n   *\n   * @param right Right side of the join operation.\n   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.\n   *\n   * @note If you perform a self-join using this function without aliasing the input\n   * `DataFrame`s, you will NOT be able to reference any columns after the join, since\n   * there is no way to disambiguate which side of the join you would like to reference.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\ndataframekey\n  def join(right: Dataset[_], usingColumns: Seq[String]): DataFrame = {\n    join(right, usingColumns, \"inner\")\n  }\n\n  /**\n   * Equi-join with another `DataFrame` using the given columns. A cross join with a predicate\n   * is specified as an inner join. If you would explicitly like to perform a cross join use the\n   * `crossJoin` method.\n   *\n   * Different from other join functions, the join columns will only appear once in the output,\n   * i.e. similar to SQL's `JOIN USING` syntax.\n   *\n   * @param right Right side of the join operation.\n   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.\n   * @param joinType Type of join to perform. Default `inner`. Must be one of:\n   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,\n   *                 `right`, `right_outer`, `left_semi`, `left_anti`.\n   *\n   * @note If you perform a self-join using this function without aliasing the input\n   * `DataFrame`s, you will NOT be able to reference any columns after the join, since\n   * there is no way to disambiguate which side of the join you would like to reference.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], usingColumns: Seq[String], joinType: String): DataFrame = {\n    // Analyze the self join. The assumption is that the analyzer will disambiguate left vs right\n    // by creating a new instance for one of the branch.\n    val joined = sparkSession.sessionState.executePlan(\n      Join(logicalPlan, right.logicalPlan, joinType = JoinType(joinType), None))\n      .analyzed.asInstanceOf[Join]\n\n    withPlan {\n      Join(\n        joined.left,\n        joined.right,\n        UsingJoin(JoinType(joinType), usingColumns),\n        None)\n    }\n  }\n\n  /**\n   * Inner join with another `DataFrame`, using the given join expression.\n   *\n   * {{{\n   *   // The following two are equivalent:\n   *   df1.join(df2, $\"df1Key\" === $\"df2Key\")\n   *   df1.join(df2).where($\"df1Key\" === $\"df2Key\")\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], joinExprs: Column): DataFrame = join(right, joinExprs, \"inner\")\n\n  /**\n   * Join with another `DataFrame`, using the given join expression. The following performs\n   * a full outer join between `df1` and `df2`.\n   *\n   * {{{\n   *   // Scala:\n   *   import org.apache.spark.sql.functions._\n   *   df1.join(df2, $\"df1Key\" === $\"df2Key\", \"outer\")\n   *\n   *   // Java:\n   *   import static org.apache.spark.sql.functions.*;\n   *   df1.join(df2, col(\"df1Key\").equalTo(col(\"df2Key\")), \"outer\");\n   * }}}\n   *\n   * @param right Right side of the join.\n   * @param joinExprs Join expression.\n   * @param joinType Type of join to perform. Default `inner`. Must be one of:\n   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,\n   *                 `right`, `right_outer`, `left_semi`, `left_anti`.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  def join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame = {\n    // Note that in this function, we introduce a hack in the case of self-join to automatically\n    // resolve ambiguous join conditions into ones that might make sense [SPARK-6231].\n    // Consider this case: df.join(df, df(\"key\") === df(\"key\"))\n    // Since df(\"key\") === df(\"key\") is a trivially true condition, this actually becomes a\n    // cartesian join. However, most likely users expect to perform a self join using \"key\".\n    // With that assumption, this hack turns the trivially true condition into equality on join\n    // keys that are resolved to both sides.\n\n    // Trigger analysis so in the case of self-join, the analyzer will clone the plan.\n    // After the cloning, left and right side will have distinct expression ids.\n    val plan = withPlan(\n      Join(logicalPlan, right.logicalPlan, JoinType(joinType), Some(joinExprs.expr)))\n      .queryExecution.analyzed.asInstanceOf[Join]\n\n    // If auto self join alias is disabled, return the plan.\n    if (!sparkSession.sessionState.conf.dataFrameSelfJoinAutoResolveAmbiguity) {\n      return withPlan(plan)\n    }\n\n    // If left/right have no output set intersection, return the plan.\n    val lanalyzed = withPlan(this.logicalPlan).queryExecution.analyzed\n    val ranalyzed = withPlan(right.logicalPlan).queryExecution.analyzed\n    if (lanalyzed.outputSet.intersect(ranalyzed.outputSet).isEmpty) {\n      return withPlan(plan)\n    }\n\n    // Otherwise, find the trivially true predicates and automatically resolves them to both sides.\n    // By the time we get here, since we have already run analysis, all attributes should've been\n    // resolved and become AttributeReference.\n    val cond = plan.condition.map { _.transform {\n      case catalyst.expressions.EqualTo(a: AttributeReference, b: AttributeReference)\n          if a.sameRef(b) =>\n        catalyst.expressions.EqualTo(\n          withPlan(plan.left).resolve(a.name),\n          withPlan(plan.right).resolve(b.name))\n    }}\n\n    withPlan {\n      plan.copy(condition = cond)\n    }\n  }\n\n  /**\n   * Explicit cartesian join with another `DataFrame`.\n   *\n   * @param right Right side of the join operation.\n   *\n   * @note Cartesian joins are very expensive without an extra filter that can be pushed down.\n   *\n   * @group untypedrel\n   * @since 2.1.0\n   */\n\n  def crossJoin(right: Dataset[_]): DataFrame = withPlan {\n    Join(logicalPlan, right.logicalPlan, joinType = Cross, None)\n  }\n\n  /**\n   * :: Experimental ::\n   * Joins this Dataset returning a `Tuple2` for each pair where `condition` evaluates to\n   * true.\n   *\n   * This is similar to the relation `join` function with one important difference in the\n   * result schema. Since `joinWith` preserves objects present on either side of the join, the\n   * result schema is similarly nested into a tuple under the column names `_1` and `_2`.\n   *\n   * This type of join can be useful both for preserving type-safety with the original object\n   * types as well as working with relational data where either side of the join has column\n   * names in common.\n   *\n   * @param other Right side of the join.\n   * @param condition Join expression.\n   * @param joinType Type of join to perform. Default `inner`. Must be one of:\n   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,\n   *                 `right`, `right_outer`, `left_semi`, `left_anti`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n\n  @Experimental\n  @InterfaceStability.Evolving\n  def joinWith[U](other: Dataset[U], condition: Column, joinType: String): Dataset[(T, U)] = {\n    // Creates a Join node and resolve it first, to get join condition resolved, self-join resolved,\n    // etc.\n    val joined = sparkSession.sessionState.executePlan(\n      Join(\n        this.logicalPlan,\n        other.logicalPlan,\n        JoinType(joinType),\n        Some(condition.expr))).analyzed.asInstanceOf[Join]\n\n    // For both join side, combine all outputs into a single column and alias it with \"_1\" or \"_2\",\n    // to match the schema for the encoder of the join result.\n    // Note that we do this before joining them, to enable the join operator to return null for one\n    // side, in cases like outer-join.\n    val left = {\n      val combined = if (this.exprEnc.flat) {\n        assert(joined.left.output.length == 1)\n        Alias(joined.left.output.head, \"_1\")()\n      } else {\n        Alias(CreateStruct(joined.left.output), \"_1\")()\n      }\n      Project(combined :: Nil, joined.left)\n    }\n\n    val right = {\n      val combined = if (other.exprEnc.flat) {\n        assert(joined.right.output.length == 1)\n        Alias(joined.right.output.head, \"_2\")()\n      } else {\n        Alias(CreateStruct(joined.right.output), \"_2\")()\n      }\n      Project(combined :: Nil, joined.right)\n    }\n\n    // Rewrites the join condition to make the attribute point to correct column/field, after we\n    // combine the outputs of each join side.\n    val conditionExpr = joined.condition.get transformUp {\n      case a: Attribute if joined.left.outputSet.contains(a) =>\n        if (this.exprEnc.flat) {\n          left.output.head\n        } else {\n          val index = joined.left.output.indexWhere(_.exprId == a.exprId)\n          GetStructField(left.output.head, index)\n        }\n      case a: Attribute if joined.right.outputSet.contains(a) =>\n        if (other.exprEnc.flat) {\n          right.output.head\n        } else {\n          val index = joined.right.output.indexWhere(_.exprId == a.exprId)\n          GetStructField(right.output.head, index)\n        }\n    }\n\n    implicit val tuple2Encoder: Encoder[(T, U)] =\n      ExpressionEncoder.tuple(this.exprEnc, other.exprEnc)\n\n    withTypedPlan(Join(left, right, joined.joinType, Some(conditionExpr)))\n  }\n\n  /**\n   * :: Experimental ::\n   * Using inner equi-join to join this Dataset returning a `Tuple2` for each pair\n   * where `condition` evaluates to true.\n   *\n   * @param other Right side of the join.\n   * @param condition Join expression.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def joinWith[U](other: Dataset[U], condition: Column): Dataset[(T, U)] = {\n    joinWith(other, condition, \"inner\")\n  }\n```\n## \n```\n  /**\n   * Returns a new Dataset with each partition sorted by the given expressions.\n   *\n   * This is the same operation as \"SORT BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n\n  @scala.annotation.varargs\n  def sortWithinPartitions(sortCol: String, sortCols: String*): Dataset[T] = {\n    sortWithinPartitions((sortCol +: sortCols).map(Column(_)) : _*)\n  }\n\n  /**\n   * Returns a new Dataset with each partition sorted by the given expressions.\n   *\n   * This is the same operation as \"SORT BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n\n\n  @scala.annotation.varargs\n  def sortWithinPartitions(sortExprs: Column*): Dataset[T] = {\n    sortInternal(global = false, sortExprs)\n  }\n\n  /**\n   * Returns a new Dataset sorted by the specified column, all in ascending order.\n   * {{{\n   *   // The following 3 are equivalent\n   *   ds.sort(\"sortcol\")\n   *   ds.sort($\"sortcol\")\n   *   ds.sort($\"sortcol\".asc)\n   * }}}\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def sort(sortCol: String, sortCols: String*): Dataset[T] = {\n    sort((sortCol +: sortCols).map(apply) : _*)\n  }\n\n  /**\n   * Returns a new Dataset sorted by the given expressions. For example:\n   * {{{\n   *   ds.sort($\"col1\", $\"col2\".desc)\n   * }}}\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def sort(sortExprs: Column*): Dataset[T] = {\n    sortInternal(global = true, sortExprs)\n  }\n\n  /**\n   * Returns a new Dataset sorted by the given expressions.\n   * This is an alias of the `sort` function.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def orderBy(sortCol: String, sortCols: String*): Dataset[T] = sort(sortCol, sortCols : _*)\n\n  /**\n   * Returns a new Dataset sorted by the given expressions.\n   * This is an alias of the `sort` function.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def orderBy(sortExprs: Column*): Dataset[T] = sort(sortExprs : _*)\n```\n\n```\n  /**\n   * Selects column based on the column name and return it as a [[Column]].\n   *\n   * @note The column name can also reference to a nested column like `a.b`.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def apply(colName: String): Column = col(colName)\n  /**\n   * Selects column based on the column name and return it as a [[Column]].\n   *\n   * @note The column name can also reference to a nested column like `a.b`.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def col(colName: String): Column = colName match {\n    case \"*\" =>\n      Column(ResolvedStar(queryExecution.analyzed.output))\n    case _ =>\n      val expr = resolve(colName)\n      Column(expr)\n  }\n\n```\n## \ndatasetdataset\n ```\n\n  /**\n   * Returns a new Dataset with an alias set.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def as(alias: String): Dataset[T] = withTypedPlan {\n    SubqueryAlias(alias, logicalPlan, None)\n  }\n\n  /**\n   * (Scala-specific) Returns a new Dataset with an alias set.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def as(alias: Symbol): Dataset[T] = as(alias.name)\n\n  /**\n   * Returns a new Dataset with an alias set. Same as `as`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def alias(alias: String): Dataset[T] = as(alias)\n\n  /**\n   * (Scala-specific) Returns a new Dataset with an alias set. Same as `as`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def alias(alias: Symbol): Dataset[T] = as(alias)\n```\n## \n\n```\n  /**\n   * Selects a set of column based expressions.\n   * {{{\n   *   ds.select($\"colA\", $\"colB\" + 1)\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def select(cols: Column*): DataFrame = withPlan {\n    Project(cols.map(_.named), logicalPlan)\n  }\n\n  /**\n   * Selects a set of columns. This is a variant of `select` that can only select\n   * existing columns using column names (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // The following two are equivalent:\n   *   ds.select(\"colA\", \"colB\")\n   *   ds.select($\"colA\", $\"colB\")\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def select(col: String, cols: String*): DataFrame = select((col +: cols).map(Column(_)) : _*)\n\n  /**\n   * Selects a set of SQL expressions. This is a variant of `select` that accepts\n   * SQL expressions.\n   *\n   * {{{\n   *   // The following are equivalent:\n   *   ds.selectExpr(\"colA\", \"colB as newName\", \"abs(colC)\")\n   *   ds.select(expr(\"colA\"), expr(\"colB as newName\"), expr(\"abs(colC)\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n\n  @scala.annotation.varargs\n  def selectExpr(exprs: String*): DataFrame = {\n    select(exprs.map { expr =>\n      Column(sparkSession.sessionState.sqlParser.parseExpression(expr))\n    }: _*)\n  }\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expression for each element.\n   *\n   * {{{\n   *   val ds = Seq(1, 2, 3).toDS()\n   *   val newDS = ds.select(expr(\"value + 1\").as[Int])\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1](c1: TypedColumn[T, U1]): Dataset[U1] = {\n    implicit val encoder = c1.encoder\n    val project = Project(c1.withInputType(exprEnc, logicalPlan.output).named :: Nil,\n      logicalPlan)\n\n    if (encoder.flat) {\n      new Dataset[U1](sparkSession, project, encoder)\n    } else {\n      // Flattens inner fields of U1\n      new Dataset[Tuple1[U1]](sparkSession, project, ExpressionEncoder.tuple(encoder)).map(_._1)\n    }\n  }\n\n  /**\n   * Internal helper function for building typed selects that return tuples. For simplicity and\n   * code reuse, we do this without the help of the type system and then use helper functions\n   * that cast appropriately for the user facing interface.\n   */\n  ???\n  protected def selectUntyped(columns: TypedColumn[_, _]*): Dataset[_] = {\n    val encoders = columns.map(_.encoder)\n    val namedColumns =\n      columns.map(_.withInputType(exprEnc, logicalPlan.output).named)\n    val execution = new QueryExecution(sparkSession, Project(namedColumns, logicalPlan))\n    new Dataset(sparkSession, execution, ExpressionEncoder.tuple(encoders))\n  }\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2](c1: TypedColumn[T, U1], c2: TypedColumn[T, U2]): Dataset[(U1, U2)] =\n    selectUntyped(c1, c2).asInstanceOf[Dataset[(U1, U2)]]\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2, U3](\n      c1: TypedColumn[T, U1],\n      c2: TypedColumn[T, U2],\n      c3: TypedColumn[T, U3]): Dataset[(U1, U2, U3)] =\n    selectUntyped(c1, c2, c3).asInstanceOf[Dataset[(U1, U2, U3)]]\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2, U3, U4](\n      c1: TypedColumn[T, U1],\n      c2: TypedColumn[T, U2],\n      c3: TypedColumn[T, U3],\n      c4: TypedColumn[T, U4]): Dataset[(U1, U2, U3, U4)] =\n    selectUntyped(c1, c2, c3, c4).asInstanceOf[Dataset[(U1, U2, U3, U4)]]\n\n  /**\n   * :: Experimental ::\n   * Returns a new Dataset by computing the given [[Column]] expressions for each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def select[U1, U2, U3, U4, U5](\n      c1: TypedColumn[T, U1],\n      c2: TypedColumn[T, U2],\n      c3: TypedColumn[T, U3],\n      c4: TypedColumn[T, U4],\n      c5: TypedColumn[T, U5]): Dataset[(U1, U2, U3, U4, U5)] =\n    selectUntyped(c1, c2, c3, c4, c5).asInstanceOf[Dataset[(U1, U2, U3, U4, U5)]]\n```\n## \nsqlwhere\n```\n  /**\n   * Filters rows using the given condition.\n   * {{{\n   *   // The following are equivalent:\n   *   peopleDs.filter($\"age\" > 15)\n   *   peopleDs.where($\"age\" > 15)\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def filter(condition: Column): Dataset[T] = withTypedPlan {\n    Filter(condition.expr, logicalPlan)\n  }\n\n  /**\n   * Filters rows using the given SQL expression.\n   * {{{\n   *   peopleDs.filter(\"age > 15\")\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def filter(conditionExpr: String): Dataset[T] = {\n    filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))\n  }\n\n  /**\n   * Filters rows using the given condition. This is an alias for `filter`.\n   * {{{\n   *   // The following are equivalent:\n   *   peopleDs.filter($\"age\" > 15)\n   *   peopleDs.where($\"age\" > 15)\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def where(condition: Column): Dataset[T] = filter(condition)\n\n  /**\n   * Filters rows using the given SQL expression.\n   * {{{\n   *   peopleDs.where(\"age > 15\")\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def where(conditionExpr: String): Dataset[T] = {\n    filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))\n  }\n```\n## \n\n```\n  /**\n   * Groups the Dataset using the specified columns, so we can run aggregation on them. See\n   * [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * {{{\n   *   // Compute the average for all numeric columns grouped by department.\n   *   ds.groupBy($\"department\").avg()\n   *\n   *   // Compute the max age and average salary, grouped by department and gender.\n   *   ds.groupBy($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def groupBy(cols: Column*): RelationalGroupedDataset = {\n    RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.GroupByType)\n  }\n\n  /**\n   * Create a multi-dimensional rollup for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * {{{\n   *   // Compute the average for all numeric columns rolluped by department and group.\n   *   ds.rollup($\"department\", $\"group\").avg()\n   *\n   *   // Compute the max age and average salary, rolluped by department and gender.\n   *   ds.rollup($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  @scala.annotation.varargs\n  def rollup(cols: Column*): RelationalGroupedDataset = {\n    RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.RollupType)\n  }\n\n  /**\n   * Create a multi-dimensional cube for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * {{{\n   *   // Compute the average for all numeric columns cubed by department and group.\n   *   ds.cube($\"department\", $\"group\").avg()\n   *\n   *   // Compute the max age and average salary, cubed by department and gender.\n   *   ds.cube($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def cube(cols: Column*): RelationalGroupedDataset = {\n    RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.CubeType)\n  }\n\n  /**\n   * Groups the Dataset using the specified columns, so that we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * This is a variant of groupBy that can only group by existing columns using column names\n   * (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // Compute the average for all numeric columns grouped by department.\n   *   ds.groupBy(\"department\").avg()\n   *\n   *   // Compute the max age and average salary, grouped by department and gender.\n   *   ds.groupBy($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def groupBy(col1: String, cols: String*): RelationalGroupedDataset = {\n    val colNames: Seq[String] = col1 +: cols\n    RelationalGroupedDataset(\n      toDF(), colNames.map(colName => resolve(colName)), RelationalGroupedDataset.GroupByType)\n  }\n```\n## reduce\n\n  ```\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Reduces the elements of this Dataset using the specified binary function. The given `func`\n   * must be commutative and associative or the result may be non-deterministic.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  \n  @Experimental\n  @InterfaceStability.Evolving\n  def reduce(func: (T, T) => T): T = rdd.reduce(func)\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Reduces the elements of this Dataset using the specified binary function. The given `func`\n   * must be commutative and associative or the result may be non-deterministic.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def reduce(func: ReduceFunction[T]): T = reduce(func.call(_, _))\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n                                    \n  @Experimental\n  @InterfaceStability.Evolving\n  def groupByKey[K: Encoder](func: T => K): KeyValueGroupedDataset[K, T] = {\n    val inputPlan = logicalPlan\n    val withGroupingKey = AppendColumns(func, inputPlan)\n    val executed = sparkSession.sessionState.executePlan(withGroupingKey)\n\n    new KeyValueGroupedDataset(\n      encoderFor[K],\n      encoderFor[T],\n      executed,\n      inputPlan.output,\n      withGroupingKey.newColumns)\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def groupByKey[K](func: MapFunction[T, K], encoder: Encoder[K]): KeyValueGroupedDataset[K, T] =\n    groupByKey(func.call(_))(encoder)\n```\n## \n```\n  /**\n   * Create a multi-dimensional rollup for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * This is a variant of rollup that can only group by existing columns using column names\n   * (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // Compute the average for all numeric columns rolluped by department and group.\n   *   ds.rollup(\"department\", \"group\").avg()\n   *\n   *   // Compute the max age and average salary, rolluped by department and gender.\n   *   ds.rollup($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def rollup(col1: String, cols: String*): RelationalGroupedDataset = {\n    val colNames: Seq[String] = col1 +: cols\n    RelationalGroupedDataset(\n      toDF(), colNames.map(colName => resolve(colName)), RelationalGroupedDataset.RollupType)\n  }\n\n  /**\n   * Create a multi-dimensional cube for the current Dataset using the specified columns,\n   * so we can run aggregation on them.\n   * See [[RelationalGroupedDataset]] for all the available aggregate functions.\n   *\n   * This is a variant of cube that can only group by existing columns using column names\n   * (i.e. cannot construct expressions).\n   *\n   * {{{\n   *   // Compute the average for all numeric columns cubed by department and group.\n   *   ds.cube(\"department\", \"group\").avg()\n   *\n   *   // Compute the max age and average salary, cubed by department and gender.\n   *   ds.cube($\"department\", $\"gender\").agg(Map(\n   *     \"salary\" -> \"avg\",\n   *     \"age\" -> \"max\"\n   *   ))\n   * }}}\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def cube(col1: String, cols: String*): RelationalGroupedDataset = {\n    val colNames: Seq[String] = col1 +: cols\n    RelationalGroupedDataset(\n      toDF(), colNames.map(colName => resolve(colName)), RelationalGroupedDataset.CubeType)\n  }\n\n  /**\n   * (Scala-specific) Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(\"age\" -> \"max\", \"salary\" -> \"avg\")\n   *   ds.groupBy().agg(\"age\" -> \"max\", \"salary\" -> \"avg\")\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def agg(aggExpr: (String, String), aggExprs: (String, String)*): DataFrame = {\n    groupBy().agg(aggExpr, aggExprs : _*)\n  }\n\n  /**\n   * (Scala-specific) Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   *   ds.groupBy().agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def agg(exprs: Map[String, String]): DataFrame = groupBy().agg(exprs)\n\n  /**\n   * (Java-specific) Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   *   ds.groupBy().agg(Map(\"age\" -> \"max\", \"salary\" -> \"avg\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def agg(exprs: java.util.Map[String, String]): DataFrame = groupBy().agg(exprs)\n\n  /**\n   * Aggregates on the entire Dataset without groups.\n   * {{{\n   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)\n   *   ds.agg(max($\"age\"), avg($\"salary\"))\n   *   ds.groupBy().agg(max($\"age\"), avg($\"salary\"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def agg(expr: Column, exprs: Column*): DataFrame = groupBy().agg(expr, exprs : _*)\n\n  /**\n   * Returns a new Dataset by taking the first `n` rows. The difference between this function\n   * and `head` is that `head` is an action and returns an array (by triggering query execution)\n   * while `limit` returns a new Dataset.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def limit(n: Int): Dataset[T] = withTypedPlan {\n    Limit(Literal(n), logicalPlan)\n  }\n```\n## \n```\n  /**\n   * Returns a new Dataset containing union of rows in this Dataset and another Dataset.\n   * This is equivalent to `UNION ALL` in SQL.\n   *\n   * To do a SQL-style set union (that does deduplication of elements), use this function followed\n   * by a [[distinct]].\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @deprecated(\"use union()\", \"2.0.0\")\n  def unionAll(other: Dataset[T]): Dataset[T] = union(other)\n\n  /**\n   * Returns a new Dataset containing union of rows in this Dataset and another Dataset.\n   * This is equivalent to `UNION ALL` in SQL.\n   *\n   * To do a SQL-style set union (that does deduplication of elements), use this function followed\n   * by a [[distinct]].\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def union(other: Dataset[T]): Dataset[T] = withSetOperator {\n    // This breaks caching, but it's usually ok because it addresses a very specific use case:\n    // using union to union many files or partitions.\n    CombineUnions(Union(logicalPlan, other.logicalPlan))\n  }\n\n  /**\n   * Returns a new Dataset containing rows only in both this Dataset and another Dataset.\n   * This is equivalent to `INTERSECT` in SQL.\n   *\n   * @note Equality checking is performed directly on the encoded representation of the data\n   * and thus is not affected by a custom `equals` function defined on `T`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def intersect(other: Dataset[T]): Dataset[T] = withSetOperator {\n    Intersect(logicalPlan, other.logicalPlan)\n  }\n\n  /**\n   * Returns a new Dataset containing rows in this Dataset but not in another Dataset.\n   * This is equivalent to `EXCEPT` in SQL.\n   *\n   * @note Equality checking is performed directly on the encoded representation of the data\n   * and thus is not affected by a custom `equals` function defined on `T`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  \n  def except(other: Dataset[T]): Dataset[T] = withSetOperator {\n    Except(logicalPlan, other.logicalPlan)\n  }\n```\n## \n```\n  /**\n   * Returns a new [[Dataset]] by sampling a fraction of rows, using a user-supplied seed.\n   *\n   * @param withReplacement Sample with replacement or not.\n   * @param fraction Fraction of rows to generate.\n   * @param seed Seed for sampling.\n   *\n   * @note This is NOT guaranteed to provide exactly the fraction of the count\n   * of the given [[Dataset]].\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def sample(withReplacement: Boolean, fraction: Double, seed: Long): Dataset[T] = {\n    require(fraction >= 0,\n      s\"Fraction must be nonnegative, but got ${fraction}\")\n\n    withTypedPlan {\n      Sample(0.0, fraction, withReplacement, seed, logicalPlan)()\n    }\n  }\n\n  /**\n   * Returns a new [[Dataset]] by sampling a fraction of rows, using a random seed.\n   *\n   * @param withReplacement Sample with replacement or not.\n   * @param fraction Fraction of rows to generate.\n   *\n   * @note This is NOT guaranteed to provide exactly the fraction of the total count\n   * of the given [[Dataset]].\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  def sample(withReplacement: Boolean, fraction: Double): Dataset[T] = {\n    sample(withReplacement, fraction, Utils.random.nextLong)\n  }\n\n  /**\n   * Randomly splits this Dataset with the provided weights.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @param seed Seed for sampling.\n   *\n   * For Java API, use [[randomSplitAsList]].\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  ???\n  def randomSplit(weights: Array[Double], seed: Long): Array[Dataset[T]] = {\n    require(weights.forall(_ >= 0),\n      s\"Weights must be nonnegative, but got ${weights.mkString(\"[\", \",\", \"]\")}\")\n    require(weights.sum > 0,\n      s\"Sum of weights must be positive, but got ${weights.mkString(\"[\", \",\", \"]\")}\")\n\n    // It is possible that the underlying dataframe doesn't guarantee the ordering of rows in its\n    // constituent partitions each time a split is materialized which could result in\n    // overlapping splits. To prevent this, we explicitly sort each input partition to make the\n    // ordering deterministic.\n    // MapType cannot be sorted.\n    val sorted = Sort(logicalPlan.output.filterNot(_.dataType.isInstanceOf[MapType])\n      .map(SortOrder(_, Ascending)), global = false, logicalPlan)\n    val sum = weights.sum\n    val normalizedCumWeights = weights.map(_ / sum).scanLeft(0.0d)(_ + _)\n    normalizedCumWeights.sliding(2).map { x =>\n      new Dataset[T](\n        sparkSession, Sample(x(0), x(1), withReplacement = false, seed, sorted)(), encoder)\n    }.toArray\n  }\n\n  /**\n   * Returns a Java list that contains randomly split Dataset with the provided weights.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @param seed Seed for sampling.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def randomSplitAsList(weights: Array[Double], seed: Long): java.util.List[Dataset[T]] = {\n    val values = randomSplit(weights, seed)\n    java.util.Arrays.asList(values : _*)\n  }\n\n  /**\n   * Randomly splits this Dataset with the provided weights.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def randomSplit(weights: Array[Double]): Array[Dataset[T]] = {\n    randomSplit(weights, Utils.random.nextLong)\n  }\n\n  /**\n   * Randomly splits this Dataset with the provided weights. Provided for the Python Api.\n   *\n   * @param weights weights for splits, will be normalized if they don't sum to 1.\n   * @param seed Seed for sampling.\n   */\n  private[spark] def randomSplit(weights: List[Double], seed: Long): Array[Dataset[T]] = {\n    randomSplit(weights.toArray, seed)\n  }\n\n  /**\n   * (Scala-specific) Returns a new Dataset where each row has been expanded to zero or more\n   * rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. The columns of\n   * the input row are implicitly joined with each row that is output by the function.\n   *\n   * Given that this is deprecated, as an alternative, you can explode columns either using\n   * `functions.explode()` or `flatMap()`. The following example uses these alternatives to count\n   * the number of books that contain a given word:\n   *\n   * {{{\n   *   case class Book(title: String, words: String)\n   *   val ds: Dataset[Book]\n   *\n   *   val allWords = ds.select('title, explode(split('words, \" \")).as(\"word\"))\n   *\n   *   val bookCountPerWord = allWords.groupBy(\"word\").agg(countDistinct(\"title\"))\n   * }}}\n   *\n   * Using `flatMap()` this can similarly be exploded as:\n   *\n   * {{{\n   *   ds.flatMap(_.words.split(\" \"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  @deprecated(\"use flatMap() or select() with functions.explode() instead\", \"2.0.0\")\n  def explode[A <: Product : TypeTag](input: Column*)(f: Row => TraversableOnce[A]): DataFrame = {\n    val elementSchema = ScalaReflection.schemaFor[A].dataType.asInstanceOf[StructType]\n\n    val convert = CatalystTypeConverters.createToCatalystConverter(elementSchema)\n\n    val rowFunction =\n      f.andThen(_.map(convert(_).asInstanceOf[InternalRow]))\n    val generator = UserDefinedGenerator(elementSchema, rowFunction, input.map(_.expr))\n\n    withPlan {\n      Generate(generator, join = true, outer = false,\n        qualifier = None, generatorOutput = Nil, logicalPlan)\n    }\n  }\n\n  /**\n   * (Scala-specific) Returns a new Dataset where a single column has been expanded to zero\n   * or more rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. All\n   * columns of the input row are implicitly joined with each value that is output by the function.\n   *\n   * Given that this is deprecated, as an alternative, you can explode columns either using\n   * `functions.explode()`:\n   *\n   * {{{\n   *   ds.select(explode(split('words, \" \")).as(\"word\"))\n   * }}}\n   *\n   * or `flatMap()`:\n   *\n   * {{{\n   *   ds.flatMap(_.words.split(\" \"))\n   * }}}\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @deprecated(\"use flatMap() or select() with functions.explode() instead\", \"2.0.0\")\n  def explode[A, B : TypeTag](inputColumn: String, outputColumn: String)(f: A => TraversableOnce[B])\n    : DataFrame = {\n    val dataType = ScalaReflection.schemaFor[B].dataType\n    val attributes = AttributeReference(outputColumn, dataType)() :: Nil\n    // TODO handle the metadata?\n    val elementSchema = attributes.toStructType\n\n    def rowFunction(row: Row): TraversableOnce[InternalRow] = {\n      val convert = CatalystTypeConverters.createToCatalystConverter(dataType)\n      f(row(0).asInstanceOf[A]).map(o => InternalRow(convert(o)))\n    }\n    val generator = UserDefinedGenerator(elementSchema, rowFunction, apply(inputColumn).expr :: Nil)\n\n    withPlan {\n      Generate(generator, join = true, outer = false,\n        qualifier = None, generatorOutput = Nil, logicalPlan)\n    }\n  }\n## \n  /**\n   * Returns a new Dataset by adding a column or replacing the existing column that has\n   * the same name.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  def withColumn(colName: String, col: Column): DataFrame = {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val output = queryExecution.analyzed.output\n    val shouldReplace = output.exists(f => resolver(f.name, colName))\n    if (shouldReplace) {\n      val columns = output.map { field =>\n        if (resolver(field.name, colName)) {\n          col.as(colName)\n        } else {\n          Column(field)\n        }\n      }\n      select(columns : _*)\n    } else {\n      select(Column(\"*\"), col.as(colName))\n    }\n  }\n\n  /**\n   * Returns a new Dataset by adding a column with metadata.\n   */\n  private[spark] def withColumn(colName: String, col: Column, metadata: Metadata): DataFrame = {\n    withColumn(colName, col.as(colName, metadata))\n  }\n\n  /**\n   * Returns a new Dataset with a column renamed.\n   * This is a no-op if schema doesn't contain existingName.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def withColumnRenamed(existingName: String, newName: String): DataFrame = {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val output = queryExecution.analyzed.output\n    val shouldRename = output.exists(f => resolver(f.name, existingName))\n    if (shouldRename) {\n      val columns = output.map { col =>\n        if (resolver(col.name, existingName)) {\n          Column(col).as(newName)\n        } else {\n          Column(col)\n        }\n      }\n      select(columns : _*)\n    } else {\n      toDF()\n    }\n  }\n\n  /**\n   * Returns a new Dataset with a column dropped. This is a no-op if schema doesn't contain\n   * column name.\n   *\n   * This method can only be used to drop top level columns. the colName string is treated\n   * literally without further interpretation.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  \n  def drop(colName: String): DataFrame = {\n    drop(Seq(colName) : _*)\n  }\n\n  /**\n   * Returns a new Dataset with columns dropped.\n   * This is a no-op if schema doesn't contain column name(s).\n   *\n   * This method can only be used to drop top level columns. the colName string is treated literally\n   * without further interpretation.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def drop(colNames: String*): DataFrame = {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val allColumns = queryExecution.analyzed.output\n    val remainingCols = allColumns.filter { attribute =>\n      colNames.forall(n => !resolver(attribute.name, n))\n    }.map(attribute => Column(attribute))\n    if (remainingCols.size == allColumns.size) {\n      toDF()\n    } else {\n      this.select(remainingCols: _*)\n    }\n  }\n\n  /**\n   * Returns a new Dataset with a column dropped.\n   * This version of drop accepts a [[Column]] rather than a name.\n   * This is a no-op if the Dataset doesn't have a column\n   * with an equivalent expression.\n   *\n   * @group untypedrel\n   * @since 2.0.0\n   */\n  def drop(col: Column): DataFrame = {\n    val expression = col match {\n      case Column(u: UnresolvedAttribute) =>\n        queryExecution.analyzed.resolveQuoted(\n          u.name, sparkSession.sessionState.analyzer.resolver).getOrElse(u)\n      case Column(expr: Expression) => expr\n    }\n    val attrs = this.logicalPlan.output\n    val colsAfterDrop = attrs.filter { attr =>\n      attr != expression\n    }.map(attr => Column(attr))\n    select(colsAfterDrop : _*)\n  }\n```\n## \n```\n  /**\n   * Returns a new Dataset that contains only the unique rows from this Dataset.\n   * This is an alias for `distinct`.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  \n  def dropDuplicates(): Dataset[T] = dropDuplicates(this.columns)\n\n  /**\n   * (Scala-specific) Returns a new Dataset with duplicate rows removed, considering only\n   * the subset of columns.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def dropDuplicates(colNames: Seq[String]): Dataset[T] = withTypedPlan {\n    val resolver = sparkSession.sessionState.analyzer.resolver\n    val allColumns = queryExecution.analyzed.output\n    val groupCols = colNames.toSet.toSeq.flatMap { (colName: String) =>\n      // It is possibly there are more than one columns with the same name,\n      // so we call filter instead of find.\n      val cols = allColumns.filter(col => resolver(col.name, colName))\n      if (cols.isEmpty) {\n        throw new AnalysisException(\n          s\"\"\"Cannot resolve column name \"$colName\" among (${schema.fieldNames.mkString(\", \")})\"\"\")\n      }\n      cols\n    }\n    Deduplicate(groupCols, logicalPlan, isStreaming)\n  }\n\n  /**\n   * Returns a new Dataset with duplicate rows removed, considering only\n   * the subset of columns.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def dropDuplicates(colNames: Array[String]): Dataset[T] = dropDuplicates(colNames.toSeq)\n\n  /**\n   * Returns a new [[Dataset]] with duplicate rows removed, considering only\n   * the subset of columns.\n   *\n   * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it\n   * will keep all data across triggers as intermediate state to drop duplicates rows. You can use\n   * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit\n   * the state. In addition, too late data older than watermark will be dropped to avoid any\n   * possibility of duplicates.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def dropDuplicates(col1: String, cols: String*): Dataset[T] = {\n    val colNames: Seq[String] = col1 +: cols\n    dropDuplicates(colNames)\n  }\n  ```\n## \n    ```\n  /**\n   * Computes statistics for numeric and string columns, including count, mean, stddev, min, and\n   * max. If no columns are given, this function computes statistics for all numerical or string\n   * columns.\n   *\n   * This function is meant for exploratory data analysis, as we make no guarantee about the\n   * backward compatibility of the schema of the resulting Dataset. If you want to\n   * programmatically compute summary statistics, use the `agg` function instead.\n   *\n   * {{{\n   *   ds.describe(\"age\", \"height\").show()\n   *\n   *   // output:\n   *   // summary age   height\n   *   // count   10.0  10.0\n   *   // mean    53.3  178.05\n   *   // stddev  11.6  15.7\n   *   // min     18.0  163.0\n   *   // max     92.0  192.0\n   * }}}\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  \n  @scala.annotation.varargs\n  def describe(cols: String*): DataFrame = withPlan {\n\n    // The list of summary statistics to compute, in the form of expressions.\n    val statistics = List[(String, Expression => Expression)](\n      \"count\" -> ((child: Expression) => Count(child).toAggregateExpression()),\n      \"mean\" -> ((child: Expression) => Average(child).toAggregateExpression()),\n      \"stddev\" -> ((child: Expression) => StddevSamp(child).toAggregateExpression()),\n      \"min\" -> ((child: Expression) => Min(child).toAggregateExpression()),\n      \"max\" -> ((child: Expression) => Max(child).toAggregateExpression()))\n\n    val outputCols =\n      (if (cols.isEmpty) aggregatableColumns.map(usePrettyExpression(_).sql) else cols).toList\n\n    val ret: Seq[Row] = if (outputCols.nonEmpty) {\n      val aggExprs = statistics.flatMap { case (_, colToAgg) =>\n        outputCols.map(c => Column(Cast(colToAgg(Column(c).expr), StringType)).as(c))\n      }\n\n      val row = groupBy().agg(aggExprs.head, aggExprs.tail: _*).head().toSeq\n\n      // Pivot the data so each summary is one row\n      row.grouped(outputCols.size).toSeq.zip(statistics).map { case (aggregation, (statistic, _)) =>\n        Row(statistic :: aggregation.toList: _*)\n      }\n    } else {\n      // If there are no output columns, just output a single column that contains the stats.\n      statistics.map { case (name, _) => Row(name) }\n    }\n\n    // All columns are string type\n    val schema = StructType(\n      StructField(\"summary\", StringType) :: outputCols.map(StructField(_, StringType))).toAttributes\n    // `toArray` forces materialization to make the seq serializable\n    LocalRelation.fromExternalRows(schema, ret.toArray.toSeq)\n  }\n\n  /**\n   * Returns the first `n` rows.\n   *\n   * @note this method should only be used if the resulting array is expected to be small, as\n   * all the data is loaded into the driver's memory.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  n\n  def head(n: Int): Array[T] = withAction(\"head\", limit(n).queryExecution)(collectFromPlan)\n\n  /**\n   * Returns the first row.\n   * @group action\n   * @since 1.6.0\n   */\n  def head(): T = head(1).head\n\n  /**\n   * Returns the first row. Alias for head().\n   * @group action\n   * @since 1.6.0\n   */\n  def first(): T = head()\n\n  /**\n   * Concise syntax for chaining custom transformations.\n   * {{{\n   *   def featurize(ds: Dataset[T]): Dataset[U] = ...\n   *\n   *   ds\n   *     .transform(featurize)\n   *     .transform(...)\n   * }}}\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  def transform[U](t: Dataset[T] => Dataset[U]): Dataset[U] = t(this)\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset that only contains elements where `func` returns `true`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  @Experimental\n  @InterfaceStability.Evolving\n  def filter(func: T => Boolean): Dataset[T] = {\n    withTypedPlan(TypedFilter(func, logicalPlan))\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset that only contains elements where `func` returns `true`.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def filter(func: FilterFunction[T]): Dataset[T] = {\n    withTypedPlan(TypedFilter(func, logicalPlan))\n  }\n```\n## \n  ```\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset that contains the result of applying `func` to each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  @Experimental\n  @InterfaceStability.Evolving\n  def map[U : Encoder](func: T => U): Dataset[U] = withTypedPlan {\n    MapElements[T, U](func, logicalPlan)\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset that contains the result of applying `func` to each element.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def map[U](func: MapFunction[T, U], encoder: Encoder[U]): Dataset[U] = {\n    implicit val uEnc = encoder\n    withTypedPlan(MapElements[T, U](func, logicalPlan))\n  }\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset that contains the result of applying `func` to each partition.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def mapPartitions[U : Encoder](func: Iterator[T] => Iterator[U]): Dataset[U] = {\n    new Dataset[U](\n      sparkSession,\n      MapPartitions[T, U](func, logicalPlan),\n      implicitly[Encoder[U]])\n  }\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset that contains the result of applying `f` to each partition.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def mapPartitions[U](f: MapPartitionsFunction[T, U], encoder: Encoder[U]): Dataset[U] = {\n    val func: (Iterator[T]) => Iterator[U] = x => f.call(x.asJava).asScala\n    mapPartitions(func)(encoder)\n  }\n\n  /**\n   * Returns a new `DataFrame` that contains the result of applying a serialized R function\n   * `func` to each partition.\n   */\n  private[sql] def mapPartitionsInR(\n      func: Array[Byte],\n      packageNames: Array[Byte],\n      broadcastVars: Array[Broadcast[Object]],\n      schema: StructType): DataFrame = {\n    val rowEncoder = encoder.asInstanceOf[ExpressionEncoder[Row]]\n    Dataset.ofRows(\n      sparkSession,\n      MapPartitionsInR(func, packageNames, broadcastVars, schema, rowEncoder, logicalPlan))\n  }\n\n  /**\n   * :: Experimental ::\n   * (Scala-specific)\n   * Returns a new Dataset by first applying a function to all elements of this Dataset,\n   * and then flattening the results.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def flatMap[U : Encoder](func: T => TraversableOnce[U]): Dataset[U] =\n    mapPartitions(_.flatMap(func))\n\n  /**\n   * :: Experimental ::\n   * (Java-specific)\n   * Returns a new Dataset by first applying a function to all elements of this Dataset,\n   * and then flattening the results.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def flatMap[U](f: FlatMapFunction[T, U], encoder: Encoder[U]): Dataset[U] = {\n    val func: (T) => Iterator[U] = x => f.call(x).asScala\n    flatMap(func)(encoder)\n  }\n\n  /**\n   * Applies a function `f` to all rows.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreach(f: T => Unit): Unit = withNewExecutionId {\n    rdd.foreach(f)\n  }\n\n  /**\n   * (Java-specific)\n   * Runs `func` on each element of this Dataset.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreach(func: ForeachFunction[T]): Unit = foreach(func.call(_))\n\n  /**\n   * Applies a function `f` to each partition of this Dataset.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreachPartition(f: Iterator[T] => Unit): Unit = withNewExecutionId {\n    rdd.foreachPartition(f)\n  }\n```\n## \n  ```\n  /**\n   * (Java-specific)\n   * Runs `func` on each partition of this Dataset.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def foreachPartition(func: ForeachPartitionFunction[T]): Unit =\n    foreachPartition(it => func.call(it.asJava))\n\n  /**\n   * Returns the first `n` rows in the Dataset.\n   *\n   * Running take requires moving data into the application's driver process, and doing so with\n   * a very large `n` can crash the driver process with OutOfMemoryError.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def take(n: Int): Array[T] = head(n)\n\n  /**\n   * Returns the first `n` rows in the Dataset as a list.\n   *\n   * Running take requires moving data into the application's driver process, and doing so with\n   * a very large `n` can crash the driver process with OutOfMemoryError.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n    \n  def takeAsList(n: Int): java.util.List[T] = java.util.Arrays.asList(take(n) : _*)\n\n  /**\n   * Returns an array that contains all rows in this Dataset.\n   *\n   * Running collect requires moving all the data into the application's driver process, and\n   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.\n   *\n   * For Java API, use [[collectAsList]].\n   *\n   * @group action\n   * @since 1.6.0\n   */\n\n\n  def collect(): Array[T] = withAction(\"collect\", queryExecution)(collectFromPlan)\n\n  /**\n   * Returns a Java list that contains all rows in this Dataset.\n   *\n   * Running collect requires moving all the data into the application's driver process, and\n   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.\n   *\n   * @group action\n   * @since 1.6.0\n   */\n  def collectAsList(): java.util.List[T] = withAction(\"collectAsList\", queryExecution) { plan =>\n    val values = collectFromPlan(plan)\n    java.util.Arrays.asList(values : _*)\n  }\n\n  /**\n   * Return an iterator that contains all rows in this Dataset.\n   *\n   * The iterator will consume as much memory as the largest partition in this Dataset.\n   *\n   * @note this results in multiple Spark jobs, and if the input Dataset is the result\n   * of a wide transformation (e.g. join with different partitioners), to avoid\n   * recomputing the input Dataset should be cached first.\n   *\n   * @group action\n   * @since 2.0.0\n   */\n  def toLocalIterator(): java.util.Iterator[T] = {\n    withAction(\"toLocalIterator\", queryExecution) { plan =>\n      plan.executeToIterator().map(boundEnc.fromRow).asJava\n    }\n  }\n\n  /**\n   * Returns the number of rows in the Dataset.\n   * @group action\n   * @since 1.6.0\n   */\n  \n  def count(): Long = withAction(\"count\", groupBy().count().queryExecution) { plan =>\n    plan.executeCollect().head.getLong(0)\n  }\n  ```\n## \n    ```\n  /**\n   * Returns a new Dataset that has exactly `numPartitions` partitions.\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  \n  def repartition(numPartitions: Int): Dataset[T] = withTypedPlan {\n    Repartition(numPartitions, shuffle = true, logicalPlan)\n  }\n\n  /**\n   * Returns a new Dataset partitioned by the given partitioning expressions into\n   * `numPartitions`. The resulting Dataset is hash partitioned.\n   *\n   * This is the same operation as \"DISTRIBUTE BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def repartition(numPartitions: Int, partitionExprs: Column*): Dataset[T] = withTypedPlan {\n    RepartitionByExpression(partitionExprs.map(_.expr), logicalPlan, numPartitions)\n  }\n\n  /**\n   * Returns a new Dataset partitioned by the given partitioning expressions, using\n   * `spark.sql.shuffle.partitions` as number of partitions.\n   * The resulting Dataset is hash partitioned.\n   *\n   * This is the same operation as \"DISTRIBUTE BY\" in SQL (Hive QL).\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  @scala.annotation.varargs\n  def repartition(partitionExprs: Column*): Dataset[T] = withTypedPlan {\n    RepartitionByExpression(\n      partitionExprs.map(_.expr), logicalPlan, sparkSession.sessionState.conf.numShufflePartitions)\n  }\n\n  /**\n   * Returns a new Dataset that has exactly `numPartitions` partitions.\n   * Similar to coalesce defined on an `RDD`, this operation results in a narrow dependency, e.g.\n   * if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of\n   * the 100 new partitions will claim 10 of the current partitions.  If a larger number of\n   * partitions is requested, it will stay at the current number of partitions.\n   *\n   * However, if you're doing a drastic coalesce, e.g. to numPartitions = 1,\n   * this may result in your computation taking place on fewer nodes than\n   * you like (e.g. one node in the case of numPartitions = 1). To avoid this,\n   * you can call repartition. This will add a shuffle step, but means the\n   * current upstream partitions will be executed in parallel (per whatever\n   * the current partitioning is).\n   *\n   * @group typedrel\n   * @since 1.6.0\n   */\n  def coalesce(numPartitions: Int): Dataset[T] = withTypedPlan {\n    Repartition(numPartitions, shuffle = false, logicalPlan)\n  }\n\n  /**\n   * Returns a new Dataset that contains only the unique rows from this Dataset.\n   * This is an alias for `dropDuplicates`.\n   *\n   * @note Equality checking is performed directly on the encoded representation of the data\n   * and thus is not affected by a custom `equals` function defined on `T`.\n   *\n   * @group typedrel\n   * @since 2.0.0\n   */\n  def distinct(): Dataset[T] = dropDuplicates()\n\n```\n## \n  rddrdd\n\n```\n  /**\n   * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n                  \n  def persist(): this.type = {\n    sparkSession.sharedState.cacheManager.cacheQuery(this)\n    this\n  }\n\n  /**\n   * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def cache(): this.type = persist()\n\n  /**\n   * Persist this Dataset with the given storage level.\n   * @param newLevel One of: `MEMORY_ONLY`, `MEMORY_AND_DISK`, `MEMORY_ONLY_SER`,\n   *                 `MEMORY_AND_DISK_SER`, `DISK_ONLY`, `MEMORY_ONLY_2`,\n   *                 `MEMORY_AND_DISK_2`, etc.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def persist(newLevel: StorageLevel): this.type = {\n    sparkSession.sharedState.cacheManager.cacheQuery(this, None, newLevel)\n    this\n  }\n\n  /**\n   * Get the Dataset's current storage level, or StorageLevel.NONE if not persisted.\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  def storageLevel: StorageLevel = {\n    sparkSession.sharedState.cacheManager.lookupCachedData(this).map { cachedData =>\n      cachedData.cachedRepresentation.storageLevel\n    }.getOrElse(StorageLevel.NONE)\n  }\n\n  /**\n   * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.\n   *\n   * @param blocking Whether to block until all blocks are deleted.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def unpersist(blocking: Boolean): this.type = {\n    sparkSession.sharedState.cacheManager.uncacheQuery(this, blocking)\n    this\n  }\n\n  /**\n   * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def unpersist(): this.type = unpersist(blocking = false)\n\n  /**\n   * Represents the content of the Dataset as an `RDD` of `T`.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  lazy val rdd: RDD[T] = {\n    val objectType = exprEnc.deserializer.dataType\n    val deserialized = CatalystSerde.deserialize[T](logicalPlan)\n    sparkSession.sessionState.executePlan(deserialized).toRdd.mapPartitions { rows =>\n      rows.map(_.get(0, objectType).asInstanceOf[T])\n    }\n  }\n\n  /**\n   * Returns the content of the Dataset as a `JavaRDD` of `T`s.\n   * @group basic\n   * @since 1.6.0\n   */\n  def toJavaRDD: JavaRDD[T] = rdd.toJavaRDD()\n\n  /**\n   * Returns the content of the Dataset as a `JavaRDD` of `T`s.\n   * @group basic\n   * @since 1.6.0\n   */\n  def javaRDD: JavaRDD[T] = toJavaRDD\n```\n## \ndatasetsqldataset\n```\n  /**\n   * Registers this Dataset as a temporary table using the given name. The lifetime of this\n   * temporary table is tied to the [[SparkSession]] that was used to create this Dataset.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  \n  @deprecated(\"Use createOrReplaceTempView(viewName) instead.\", \"2.0.0\")\n  def registerTempTable(tableName: String): Unit = {\n    createOrReplaceTempView(tableName)\n  }\n\n  /**\n   * Creates a local temporary view using the given name. The lifetime of this\n   * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.\n   *\n   * Local temporary view is session-scoped. Its lifetime is the lifetime of the session that\n   * created it, i.e. it will be automatically dropped when the session terminates. It's not\n   * tied to any databases, i.e. we can't use `db1.view1` to reference a local temporary view.\n   *\n   * @throws AnalysisException if the view name is invalid or already exists\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  \n  @throws[AnalysisException]\n  def createTempView(viewName: String): Unit = withPlan {\n    createTempViewCommand(viewName, replace = false, global = false)\n  }\n\n\n\n  /**\n   * Creates a local temporary view using the given name. The lifetime of this\n   * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  def createOrReplaceTempView(viewName: String): Unit = withPlan {\n    createTempViewCommand(viewName, replace = true, global = false)\n  }\n\n  /**\n   * Creates a global temporary view using the given name. The lifetime of this\n   * temporary view is tied to this Spark application.\n   *\n   * Global temporary view is cross-session. Its lifetime is the lifetime of the Spark application,\n   * i.e. it will be automatically dropped when the application terminates. It's tied to a system\n   * preserved database `global_temp`, and we must use the qualified name to refer a global temp\n   * view, e.g. `SELECT * FROM global_temp.view1`.\n   *\n   * @throws AnalysisException if the view name is invalid or already exists\n   *\n   * @group basic\n   * @since 2.1.0\n   */\n  @throws[AnalysisException]\n  def createGlobalTempView(viewName: String): Unit = withPlan {\n    createTempViewCommand(viewName, replace = false, global = true)\n  }\n\n  private def createTempViewCommand(\n      viewName: String,\n      replace: Boolean,\n      global: Boolean): CreateViewCommand = {\n    val viewType = if (global) GlobalTempView else LocalTempView\n\n    val tableIdentifier = try {\n      sparkSession.sessionState.sqlParser.parseTableIdentifier(viewName)\n    } catch {\n      case _: ParseException => throw new AnalysisException(s\"Invalid view name: $viewName\")\n    }\n    CreateViewCommand(\n      name = tableIdentifier,\n      userSpecifiedColumns = Nil,\n      comment = None,\n      properties = Map.empty,\n      originalText = None,\n      child = logicalPlan,\n      allowExisting = false,\n      replace = replace,\n      viewType = viewType)\n  }\n  ```\n## \n    writewritewrite\n```\n  /**\n   * Interface for saving the content of the non-streaming Dataset out into external storage.\n   *\n   * @group basic\n   * @since 1.6.0\n   */\n  def write: DataFrameWriter[T] = {\n    if (isStreaming) {\n      logicalPlan.failAnalysis(\n        \"'write' can not be called on streaming Dataset/DataFrame\")\n    }\n    new DataFrameWriter[T](this)\n  }\n\n  /**\n   * :: Experimental ::\n   * Interface for saving the content of the streaming Dataset out into external storage.\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  @Experimental\n  @InterfaceStability.Evolving\n  def writeStream: DataStreamWriter[T] = {\n    if (!isStreaming) {\n      logicalPlan.failAnalysis(\n        \"'writeStream' can be called only on streaming Dataset/DataFrame\")\n    }\n    new DataStreamWriter[T](this)\n  }\n\n```\n## json\n```\n  /**\n   * Returns the content of the Dataset as a Dataset of JSON strings.\n   * @since 2.0.0\n   */\n  def toJSON: Dataset[String] = {\n    val rowSchema = this.schema\n    val sessionLocalTimeZone = sparkSession.sessionState.conf.sessionLocalTimeZone\n    val rdd: RDD[String] = queryExecution.toRdd.mapPartitions { iter =>\n      val writer = new CharArrayWriter()\n      // create the Generator without separator inserted between 2 records\n      val gen = new JacksonGenerator(rowSchema, writer,\n        new JSONOptions(Map.empty[String, String], sessionLocalTimeZone))\n\n      new Iterator[String] {\n        override def hasNext: Boolean = iter.hasNext\n        override def next(): String = {\n          gen.write(iter.next())\n          gen.flush()\n\n          val json = writer.toString\n          if (hasNext) {\n            writer.reset()\n          } else {\n            gen.close()\n          }\n\n          json\n        }\n      }\n    }\n    import sparkSession.implicits.newStringEncoder\n    sparkSession.createDataset(rdd)\n  }\n  ```\n##  \n  dataSet\n  ```\n  /**\n   * Returns a best-effort snapshot of the files that compose this Dataset. This method simply\n   * asks each constituent BaseRelation for its respective files and takes the union of all results.\n   * Depending on the source relations, this may not find all input files. Duplicates are removed.\n   *\n   * @group basic\n   * @since 2.0.0\n   */\n  def inputFiles: Array[String] = {\n    val files: Seq[String] = queryExecution.optimizedPlan.collect {\n      case LogicalRelation(fsBasedRelation: FileRelation, _, _) =>\n        fsBasedRelation.inputFiles\n      case fr: FileRelation =>\n        fr.inputFiles\n    }.flatten\n    files.toSet.toArray\n  }\n```\n","slug":"spark1","published":1,"updated":"2017-03-11T23:38:34.813Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj70mt11o001g60tusrxx6308","content":"<p>sparksqldataframe sparkspark,.<br>:spark 2.0.1<br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>showString sparkshowshowString<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Compose the string representing rows for output</div><div class=\"line\"> *</div><div class=\"line\"> * @param _numRows Number of rows to show</div><div class=\"line\"> * @param truncate If set to more than 0, truncates strings to `truncate` characters and</div><div class=\"line\"> *                   all cells will be aligned right.</div><div class=\"line\"> */</div><div class=\"line\">private[sql] def showString(_numRows: Int, truncate: Int = 20): String</div></pre></td></tr></table></figure></p>\n<h2 id=\"dataSetdataFrame\"><a href=\"#dataSetdataFrame\" class=\"headerlink\" title=\"dataSetdataFrame\"></a>dataSetdataFrame</h2><p>   dataframdataset<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Converts this strongly typed collection of data to generic `DataFrame` with columns renamed.</div><div class=\"line\"> * This can be quite convenient in conversion from an RDD of tuples into a `DataFrame` with</div><div class=\"line\"> * meaningful names. For example:</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   val rdd: RDD[(Int, String)] = ...</div><div class=\"line\"> *   rdd.toDF()  // this implicit conversion creates a DataFrame with column name `_1` and `_2`</div><div class=\"line\"> *   rdd.toDF(&quot;id&quot;, &quot;name&quot;)  // this creates a DataFrame with column name &quot;id&quot; and &quot;name&quot;</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def toDF(colNames: String*): DataFrame = &#123;</div><div class=\"line\">  require(schema.size == colNames.size,</div><div class=\"line\">    &quot;The number of columns doesn&apos;t match.\\n&quot; +</div><div class=\"line\">      s&quot;Old column names ($&#123;schema.size&#125;): &quot; + schema.fields.map(_.name).mkString(&quot;, &quot;) + &quot;\\n&quot; +</div><div class=\"line\">      s&quot;New column names ($&#123;colNames.size&#125;): &quot; + colNames.mkString(&quot;, &quot;))</div><div class=\"line\"></div><div class=\"line\">  val newCols = logicalPlan.output.zip(colNames).map &#123; case (oldAttribute, newName) =&gt;</div><div class=\"line\">    Column(oldAttribute).as(newName)</div><div class=\"line\">  &#125;</div><div class=\"line\">  select(newCols : _*)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>dataset<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns the schema of this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def schema: StructType = queryExecution.analyzed.schema</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Prints the schema to the console in a nice tree format.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">// scalastyle:off println</div><div class=\"line\">def printSchema(): Unit = println(schema.treeString)</div><div class=\"line\">// scalastyle:on println</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Prints the plans (logical and physical) to the console for debugging purposes.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def explain(extended: Boolean): Unit = &#123;</div><div class=\"line\">  val explain = ExplainCommand(queryExecution.logical, extended = extended)</div><div class=\"line\">  sparkSession.sessionState.executePlan(explain).executedPlan.executeCollect().foreach &#123;</div><div class=\"line\">    // scalastyle:off println</div><div class=\"line\">    r =&gt; println(r.getString(0))</div><div class=\"line\">    // scalastyle:on println</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Prints the physical plan to the console for debugging purposes.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def explain(): Unit = explain(extended = false)</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns all column names and their data types as an array.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def dtypes: Array[(String, String)] = schema.fields.map &#123; field =&gt;</div><div class=\"line\">  (field.name, field.dataType.toString)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns all column names as an array.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def columns: Array[String] = schema.fields.map(_.name)</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns true if the `collect` and `take` methods can be run locally</div><div class=\"line\"> * (without any Spark executors).</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def isLocal: Boolean = logicalPlan.isInstanceOf[LocalRelation]</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns true if this Dataset contains one or more sources that continuously</div><div class=\"line\"> * return data as it arrives. A Dataset that reads data from a streaming source</div><div class=\"line\"> * must be executed as a `StreamingQuery` using the `start()` method in</div><div class=\"line\"> * `DataStreamWriter`. Methods that return a single answer, e.g. `count()` or</div><div class=\"line\"> * `collect()`, will throw an [[AnalysisException]] when there is a streaming</div><div class=\"line\"> * source present.</div><div class=\"line\"> *</div><div class=\"line\"> * @group streaming</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def isStreaming: Boolean = logicalPlan.isStreaming</div></pre></td></tr></table></figure></p>\n<p><strong></strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Eagerly checkpoint a Dataset and return the new Dataset. Checkpointing can be used to truncate</div><div class=\"line\"> * the logical plan of this Dataset, which is especially useful in iterative algorithms where the</div><div class=\"line\"> * plan may grow exponentially. It will be saved to files inside the checkpoint</div><div class=\"line\"> * directory set with `SparkContext#setCheckpointDir`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def checkpoint(): Dataset[T] = checkpoint(eager = true)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a checkpointed version of this Dataset. Checkpointing can be used to truncate the</div><div class=\"line\"> * logical plan of this Dataset, which is especially useful in iterative algorithms where the</div><div class=\"line\"> * plan may grow exponentially. It will be saved to files inside the checkpoint</div><div class=\"line\"> * directory set with `SparkContext#setCheckpointDir`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def checkpoint(eager: Boolean): Dataset[T] = &#123;</div><div class=\"line\">  val internalRdd = queryExecution.toRdd.map(_.copy())</div><div class=\"line\">  internalRdd.checkpoint()</div><div class=\"line\"></div><div class=\"line\">  if (eager) &#123;</div><div class=\"line\">    internalRdd.count()</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  val physicalPlan = queryExecution.executedPlan</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">  // Takes the first leaf partitioning whenever we see a `PartitioningCollection`. Otherwise the</div><div class=\"line\">  // size of `PartitioningCollection` may grow exponentially for queries involving deep inner</div><div class=\"line\">  // joins.</div><div class=\"line\">  def firstLeafPartitioning(partitioning: Partitioning): Partitioning = &#123;</div><div class=\"line\">    partitioning match &#123;</div><div class=\"line\">      case p: PartitioningCollection =&gt; firstLeafPartitioning(p.partitionings.head)</div><div class=\"line\">      case p =&gt; p</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  val outputPartitioning = firstLeafPartitioning(physicalPlan.outputPartitioning)</div><div class=\"line\"></div><div class=\"line\">  Dataset.ofRows(</div><div class=\"line\">    sparkSession,</div><div class=\"line\">    LogicalRDD(</div><div class=\"line\">      logicalPlan.output,</div><div class=\"line\">      internalRdd,</div><div class=\"line\">      outputPartitioning,</div><div class=\"line\">      physicalPlan.outputOrdering</div><div class=\"line\">    )(sparkSession)).as[T]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * Defines an event time watermark for this [[Dataset]]. A watermark tracks a point in time</div><div class=\"line\"> * before which we assume no more late data is going to arrive.</div><div class=\"line\"> *</div><div class=\"line\"> * Spark will use this watermark for several purposes:</div><div class=\"line\"> *  - To know when a given time window aggregation can be finalized and thus can be emitted when</div><div class=\"line\"> *    using output modes that do not allow updates.</div><div class=\"line\"> *  - To minimize the amount of state that we need to keep for on-going aggregations,</div><div class=\"line\"> *    `mapGroupsWithState` and `dropDuplicates` operators.</div><div class=\"line\"> *</div><div class=\"line\"> *  The current watermark is computed by looking at the `MAX(eventTime)` seen across</div><div class=\"line\"> *  all of the partitions in the query minus a user specified `delayThreshold`.  Due to the cost</div><div class=\"line\"> *  of coordinating this value across partitions, the actual watermark used is only guaranteed</div><div class=\"line\"> *  to be at least `delayThreshold` behind the actual event time.  In some cases we may still</div><div class=\"line\"> *  process records that arrive more than `delayThreshold` late.</div><div class=\"line\"> *</div><div class=\"line\"> * @param eventTime the name of the column that contains the event time of the row.</div><div class=\"line\"> * @param delayThreshold the minimum delay to wait to data to arrive late, relative to the latest</div><div class=\"line\"> *                       record that has been processed in the form of an interval</div><div class=\"line\"> *                       (e.g. &quot;1 minute&quot; or &quot;5 hours&quot;).</div><div class=\"line\"> *</div><div class=\"line\"> * @group streaming</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">// We only accept an existing column name, not a derived column here as a watermark that is</div><div class=\"line\">// defined on a derived column cannot referenced elsewhere in the plan.</div><div class=\"line\">def withWatermark(eventTime: String, delayThreshold: String): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  val parsedDelay =</div><div class=\"line\">    Option(CalendarInterval.fromString(&quot;interval &quot; + delayThreshold))</div><div class=\"line\">      .getOrElse(throw new AnalysisException(s&quot;Unable to parse time delay &apos;$delayThreshold&apos;&quot;))</div><div class=\"line\">  EventTimeWatermark(UnresolvedAttribute(eventTime), parsedDelay, logicalPlan)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Displays the Dataset in a tabular form. Strings more than 20 characters will be truncated,</div><div class=\"line\">   * and all cells will be aligned right. For example:</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   year  month AVG(&apos;Adj Close) MAX(&apos;Adj Close)</div><div class=\"line\">   *   1980  12    0.503218        0.595103</div><div class=\"line\">   *   1981  01    0.523289        0.570307</div><div class=\"line\">   *   1982  02    0.436504        0.475256</div><div class=\"line\">   *   1983  03    0.410516        0.442194</div><div class=\"line\">   *   1984  04    0.450090        0.483521</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param numRows Number of rows to show</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">datafram20</div><div class=\"line\">  def show(numRows: Int): Unit = show(numRows, truncate = true)</div><div class=\"line\"></div><div class=\"line\">datafram2020</div><div class=\"line\">  </div><div class=\"line\">  def show(): Unit = show(20)</div><div class=\"line\"></div><div class=\"line\">datafram20truncate</div><div class=\"line\">  def show(truncate: Boolean): Unit = show(20, truncate)</div><div class=\"line\"></div><div class=\"line\">dataframnumRowstruncate</div><div class=\"line\">  def show(numRows: Int, truncate: Boolean): Unit = if (truncate) &#123;</div><div class=\"line\">  def show(numRows: Int, truncate: Int): Unit = println(showString(numRows, truncate))</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div><div class=\"line\">175</div><div class=\"line\">176</div><div class=\"line\">177</div><div class=\"line\">178</div><div class=\"line\">179</div><div class=\"line\">180</div><div class=\"line\">181</div><div class=\"line\">182</div><div class=\"line\">183</div><div class=\"line\">184</div><div class=\"line\">185</div><div class=\"line\">186</div><div class=\"line\">187</div><div class=\"line\">188</div><div class=\"line\">189</div><div class=\"line\">190</div><div class=\"line\">191</div><div class=\"line\">192</div><div class=\"line\">193</div><div class=\"line\">194</div><div class=\"line\">195</div><div class=\"line\">196</div><div class=\"line\">197</div><div class=\"line\">198</div><div class=\"line\">199</div><div class=\"line\">200</div><div class=\"line\">201</div><div class=\"line\">202</div><div class=\"line\">203</div><div class=\"line\">204</div><div class=\"line\">205</div><div class=\"line\">206</div><div class=\"line\">207</div><div class=\"line\">208</div><div class=\"line\">209</div><div class=\"line\">210</div><div class=\"line\">211</div><div class=\"line\">212</div><div class=\"line\">213</div><div class=\"line\">214</div><div class=\"line\">215</div><div class=\"line\">216</div><div class=\"line\">217</div><div class=\"line\">218</div><div class=\"line\">219</div><div class=\"line\">220</div><div class=\"line\">221</div><div class=\"line\">222</div><div class=\"line\">223</div><div class=\"line\">224</div><div class=\"line\">225</div><div class=\"line\">226</div><div class=\"line\">227</div><div class=\"line\">228</div><div class=\"line\">229</div><div class=\"line\">230</div><div class=\"line\">231</div><div class=\"line\">232</div><div class=\"line\">233</div><div class=\"line\">234</div><div class=\"line\">235</div><div class=\"line\">236</div><div class=\"line\">237</div><div class=\"line\">238</div><div class=\"line\">239</div><div class=\"line\">240</div><div class=\"line\">241</div><div class=\"line\">242</div><div class=\"line\">243</div><div class=\"line\">244</div><div class=\"line\">245</div><div class=\"line\">246</div><div class=\"line\">247</div><div class=\"line\">248</div><div class=\"line\">249</div><div class=\"line\">250</div><div class=\"line\">251</div><div class=\"line\">252</div><div class=\"line\">253</div><div class=\"line\">254</div><div class=\"line\">255</div><div class=\"line\">256</div><div class=\"line\">257</div><div class=\"line\">258</div><div class=\"line\">259</div><div class=\"line\">260</div><div class=\"line\">261</div><div class=\"line\">262</div><div class=\"line\">263</div><div class=\"line\">264</div><div class=\"line\">265</div><div class=\"line\">266</div><div class=\"line\">267</div><div class=\"line\">268</div><div class=\"line\">269</div><div class=\"line\">270</div><div class=\"line\">271</div><div class=\"line\">272</div><div class=\"line\">273</div><div class=\"line\">274</div><div class=\"line\">275</div><div class=\"line\">276</div><div class=\"line\">277</div><div class=\"line\">278</div><div class=\"line\">279</div><div class=\"line\">280</div><div class=\"line\">281</div><div class=\"line\">282</div><div class=\"line\">283</div><div class=\"line\">284</div><div class=\"line\">285</div><div class=\"line\">286</div><div class=\"line\">287</div><div class=\"line\">288</div><div class=\"line\">289</div><div class=\"line\">290</div><div class=\"line\">291</div><div class=\"line\">292</div><div class=\"line\">293</div><div class=\"line\">294</div><div class=\"line\">295</div><div class=\"line\">296</div><div class=\"line\">297</div><div class=\"line\">298</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">dataset</div><div class=\"line\">  def na: DataFrameNaFunctions = new DataFrameNaFunctions(toDF())</div><div class=\"line\"></div><div class=\"line\">dataset</div><div class=\"line\">  def stat: DataFrameStatFunctions = new DataFrameStatFunctions(toDF())</div><div class=\"line\">dataframe</div><div class=\"line\">  def join(right: Dataset[_]): DataFrame = withPlan &#123;</div><div class=\"line\">    Join(logicalPlan, right.logicalPlan, joinType = Inner, None)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Inner equi-join with another `DataFrame` using the given column.</div><div class=\"line\">   *</div><div class=\"line\">   * Different from other join functions, the join column will only appear once in the output,</div><div class=\"line\">   * i.e. similar to SQL&apos;s `JOIN USING` syntax.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // Joining df1 and df2 using the column &quot;user_id&quot;</div><div class=\"line\">   *   df1.join(df2, &quot;user_id&quot;)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   * @param usingColumn Name of the column to join on. This column must exist on both sides.</div><div class=\"line\">   *</div><div class=\"line\">   * @note If you perform a self-join using this function without aliasing the input</div><div class=\"line\">   * `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class=\"line\">   * there is no way to disambiguate which side of the join you would like to reference.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], usingColumn: String): DataFrame = &#123;</div><div class=\"line\">    join(right, Seq(usingColumn))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Inner equi-join with another `DataFrame` using the given columns.</div><div class=\"line\">   *</div><div class=\"line\">   * Different from other join functions, the join columns will only appear once in the output,</div><div class=\"line\">   * i.e. similar to SQL&apos;s `JOIN USING` syntax.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // Joining df1 and df2 using the columns &quot;user_id&quot; and &quot;user_name&quot;</div><div class=\"line\">   *   df1.join(df2, Seq(&quot;user_id&quot;, &quot;user_name&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.</div><div class=\"line\">   *</div><div class=\"line\">   * @note If you perform a self-join using this function without aliasing the input</div><div class=\"line\">   * `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class=\"line\">   * there is no way to disambiguate which side of the join you would like to reference.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">dataframekey</div><div class=\"line\">  def join(right: Dataset[_], usingColumns: Seq[String]): DataFrame = &#123;</div><div class=\"line\">    join(right, usingColumns, &quot;inner&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Equi-join with another `DataFrame` using the given columns. A cross join with a predicate</div><div class=\"line\">   * is specified as an inner join. If you would explicitly like to perform a cross join use the</div><div class=\"line\">   * `crossJoin` method.</div><div class=\"line\">   *</div><div class=\"line\">   * Different from other join functions, the join columns will only appear once in the output,</div><div class=\"line\">   * i.e. similar to SQL&apos;s `JOIN USING` syntax.</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.</div><div class=\"line\">   * @param joinType Type of join to perform. Default `inner`. Must be one of:</div><div class=\"line\">   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,</div><div class=\"line\">   *                 `right`, `right_outer`, `left_semi`, `left_anti`.</div><div class=\"line\">   *</div><div class=\"line\">   * @note If you perform a self-join using this function without aliasing the input</div><div class=\"line\">   * `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class=\"line\">   * there is no way to disambiguate which side of the join you would like to reference.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], usingColumns: Seq[String], joinType: String): DataFrame = &#123;</div><div class=\"line\">    // Analyze the self join. The assumption is that the analyzer will disambiguate left vs right</div><div class=\"line\">    // by creating a new instance for one of the branch.</div><div class=\"line\">    val joined = sparkSession.sessionState.executePlan(</div><div class=\"line\">      Join(logicalPlan, right.logicalPlan, joinType = JoinType(joinType), None))</div><div class=\"line\">      .analyzed.asInstanceOf[Join]</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      Join(</div><div class=\"line\">        joined.left,</div><div class=\"line\">        joined.right,</div><div class=\"line\">        UsingJoin(JoinType(joinType), usingColumns),</div><div class=\"line\">        None)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Inner join with another `DataFrame`, using the given join expression.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following two are equivalent:</div><div class=\"line\">   *   df1.join(df2, $&quot;df1Key&quot; === $&quot;df2Key&quot;)</div><div class=\"line\">   *   df1.join(df2).where($&quot;df1Key&quot; === $&quot;df2Key&quot;)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], joinExprs: Column): DataFrame = join(right, joinExprs, &quot;inner&quot;)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Join with another `DataFrame`, using the given join expression. The following performs</div><div class=\"line\">   * a full outer join between `df1` and `df2`.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // Scala:</div><div class=\"line\">   *   import org.apache.spark.sql.functions._</div><div class=\"line\">   *   df1.join(df2, $&quot;df1Key&quot; === $&quot;df2Key&quot;, &quot;outer&quot;)</div><div class=\"line\">   *</div><div class=\"line\">   *   // Java:</div><div class=\"line\">   *   import static org.apache.spark.sql.functions.*;</div><div class=\"line\">   *   df1.join(df2, col(&quot;df1Key&quot;).equalTo(col(&quot;df2Key&quot;)), &quot;outer&quot;);</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join.</div><div class=\"line\">   * @param joinExprs Join expression.</div><div class=\"line\">   * @param joinType Type of join to perform. Default `inner`. Must be one of:</div><div class=\"line\">   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,</div><div class=\"line\">   *                 `right`, `right_outer`, `left_semi`, `left_anti`.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame = &#123;</div><div class=\"line\">    // Note that in this function, we introduce a hack in the case of self-join to automatically</div><div class=\"line\">    // resolve ambiguous join conditions into ones that might make sense [SPARK-6231].</div><div class=\"line\">    // Consider this case: df.join(df, df(&quot;key&quot;) === df(&quot;key&quot;))</div><div class=\"line\">    // Since df(&quot;key&quot;) === df(&quot;key&quot;) is a trivially true condition, this actually becomes a</div><div class=\"line\">    // cartesian join. However, most likely users expect to perform a self join using &quot;key&quot;.</div><div class=\"line\">    // With that assumption, this hack turns the trivially true condition into equality on join</div><div class=\"line\">    // keys that are resolved to both sides.</div><div class=\"line\"></div><div class=\"line\">    // Trigger analysis so in the case of self-join, the analyzer will clone the plan.</div><div class=\"line\">    // After the cloning, left and right side will have distinct expression ids.</div><div class=\"line\">    val plan = withPlan(</div><div class=\"line\">      Join(logicalPlan, right.logicalPlan, JoinType(joinType), Some(joinExprs.expr)))</div><div class=\"line\">      .queryExecution.analyzed.asInstanceOf[Join]</div><div class=\"line\"></div><div class=\"line\">    // If auto self join alias is disabled, return the plan.</div><div class=\"line\">    if (!sparkSession.sessionState.conf.dataFrameSelfJoinAutoResolveAmbiguity) &#123;</div><div class=\"line\">      return withPlan(plan)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    // If left/right have no output set intersection, return the plan.</div><div class=\"line\">    val lanalyzed = withPlan(this.logicalPlan).queryExecution.analyzed</div><div class=\"line\">    val ranalyzed = withPlan(right.logicalPlan).queryExecution.analyzed</div><div class=\"line\">    if (lanalyzed.outputSet.intersect(ranalyzed.outputSet).isEmpty) &#123;</div><div class=\"line\">      return withPlan(plan)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    // Otherwise, find the trivially true predicates and automatically resolves them to both sides.</div><div class=\"line\">    // By the time we get here, since we have already run analysis, all attributes should&apos;ve been</div><div class=\"line\">    // resolved and become AttributeReference.</div><div class=\"line\">    val cond = plan.condition.map &#123; _.transform &#123;</div><div class=\"line\">      case catalyst.expressions.EqualTo(a: AttributeReference, b: AttributeReference)</div><div class=\"line\">          if a.sameRef(b) =&gt;</div><div class=\"line\">        catalyst.expressions.EqualTo(</div><div class=\"line\">          withPlan(plan.left).resolve(a.name),</div><div class=\"line\">          withPlan(plan.right).resolve(b.name))</div><div class=\"line\">    &#125;&#125;</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      plan.copy(condition = cond)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Explicit cartesian join with another `DataFrame`.</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   *</div><div class=\"line\">   * @note Cartesian joins are very expensive without an extra filter that can be pushed down.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.1.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def crossJoin(right: Dataset[_]): DataFrame = withPlan &#123;</div><div class=\"line\">    Join(logicalPlan, right.logicalPlan, joinType = Cross, None)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Joins this Dataset returning a `Tuple2` for each pair where `condition` evaluates to</div><div class=\"line\">   * true.</div><div class=\"line\">   *</div><div class=\"line\">   * This is similar to the relation `join` function with one important difference in the</div><div class=\"line\">   * result schema. Since `joinWith` preserves objects present on either side of the join, the</div><div class=\"line\">   * result schema is similarly nested into a tuple under the column names `_1` and `_2`.</div><div class=\"line\">   *</div><div class=\"line\">   * This type of join can be useful both for preserving type-safety with the original object</div><div class=\"line\">   * types as well as working with relational data where either side of the join has column</div><div class=\"line\">   * names in common.</div><div class=\"line\">   *</div><div class=\"line\">   * @param other Right side of the join.</div><div class=\"line\">   * @param condition Join expression.</div><div class=\"line\">   * @param joinType Type of join to perform. Default `inner`. Must be one of:</div><div class=\"line\">   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,</div><div class=\"line\">   *                 `right`, `right_outer`, `left_semi`, `left_anti`.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def joinWith[U](other: Dataset[U], condition: Column, joinType: String): Dataset[(T, U)] = &#123;</div><div class=\"line\">    // Creates a Join node and resolve it first, to get join condition resolved, self-join resolved,</div><div class=\"line\">    // etc.</div><div class=\"line\">    val joined = sparkSession.sessionState.executePlan(</div><div class=\"line\">      Join(</div><div class=\"line\">        this.logicalPlan,</div><div class=\"line\">        other.logicalPlan,</div><div class=\"line\">        JoinType(joinType),</div><div class=\"line\">        Some(condition.expr))).analyzed.asInstanceOf[Join]</div><div class=\"line\"></div><div class=\"line\">    // For both join side, combine all outputs into a single column and alias it with &quot;_1&quot; or &quot;_2&quot;,</div><div class=\"line\">    // to match the schema for the encoder of the join result.</div><div class=\"line\">    // Note that we do this before joining them, to enable the join operator to return null for one</div><div class=\"line\">    // side, in cases like outer-join.</div><div class=\"line\">    val left = &#123;</div><div class=\"line\">      val combined = if (this.exprEnc.flat) &#123;</div><div class=\"line\">        assert(joined.left.output.length == 1)</div><div class=\"line\">        Alias(joined.left.output.head, &quot;_1&quot;)()</div><div class=\"line\">      &#125; else &#123;</div><div class=\"line\">        Alias(CreateStruct(joined.left.output), &quot;_1&quot;)()</div><div class=\"line\">      &#125;</div><div class=\"line\">      Project(combined :: Nil, joined.left)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    val right = &#123;</div><div class=\"line\">      val combined = if (other.exprEnc.flat) &#123;</div><div class=\"line\">        assert(joined.right.output.length == 1)</div><div class=\"line\">        Alias(joined.right.output.head, &quot;_2&quot;)()</div><div class=\"line\">      &#125; else &#123;</div><div class=\"line\">        Alias(CreateStruct(joined.right.output), &quot;_2&quot;)()</div><div class=\"line\">      &#125;</div><div class=\"line\">      Project(combined :: Nil, joined.right)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    // Rewrites the join condition to make the attribute point to correct column/field, after we</div><div class=\"line\">    // combine the outputs of each join side.</div><div class=\"line\">    val conditionExpr = joined.condition.get transformUp &#123;</div><div class=\"line\">      case a: Attribute if joined.left.outputSet.contains(a) =&gt;</div><div class=\"line\">        if (this.exprEnc.flat) &#123;</div><div class=\"line\">          left.output.head</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          val index = joined.left.output.indexWhere(_.exprId == a.exprId)</div><div class=\"line\">          GetStructField(left.output.head, index)</div><div class=\"line\">        &#125;</div><div class=\"line\">      case a: Attribute if joined.right.outputSet.contains(a) =&gt;</div><div class=\"line\">        if (other.exprEnc.flat) &#123;</div><div class=\"line\">          right.output.head</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          val index = joined.right.output.indexWhere(_.exprId == a.exprId)</div><div class=\"line\">          GetStructField(right.output.head, index)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    implicit val tuple2Encoder: Encoder[(T, U)] =</div><div class=\"line\">      ExpressionEncoder.tuple(this.exprEnc, other.exprEnc)</div><div class=\"line\"></div><div class=\"line\">    withTypedPlan(Join(left, right, joined.joinType, Some(conditionExpr)))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Using inner equi-join to join this Dataset returning a `Tuple2` for each pair</div><div class=\"line\">   * where `condition` evaluates to true.</div><div class=\"line\">   *</div><div class=\"line\">   * @param other Right side of the join.</div><div class=\"line\">   * @param condition Join expression.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def joinWith[U](other: Dataset[U], condition: Column): Dataset[(T, U)] = &#123;</div><div class=\"line\">    joinWith(other, condition, &quot;inner&quot;)</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with each partition sorted by the given expressions.</div><div class=\"line\">   *</div><div class=\"line\">   * This is the same operation as &quot;SORT BY&quot; in SQL (Hive QL).</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sortWithinPartitions(sortCol: String, sortCols: String*): Dataset[T] = &#123;</div><div class=\"line\">    sortWithinPartitions((sortCol +: sortCols).map(Column(_)) : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with each partition sorted by the given expressions.</div><div class=\"line\">   *</div><div class=\"line\">   * This is the same operation as &quot;SORT BY&quot; in SQL (Hive QL).</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sortWithinPartitions(sortExprs: Column*): Dataset[T] = &#123;</div><div class=\"line\">    sortInternal(global = false, sortExprs)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the specified column, all in ascending order.</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following 3 are equivalent</div><div class=\"line\">   *   ds.sort(&quot;sortcol&quot;)</div><div class=\"line\">   *   ds.sort($&quot;sortcol&quot;)</div><div class=\"line\">   *   ds.sort($&quot;sortcol&quot;.asc)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sort(sortCol: String, sortCols: String*): Dataset[T] = &#123;</div><div class=\"line\">    sort((sortCol +: sortCols).map(apply) : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the given expressions. For example:</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.sort($&quot;col1&quot;, $&quot;col2&quot;.desc)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sort(sortExprs: Column*): Dataset[T] = &#123;</div><div class=\"line\">    sortInternal(global = true, sortExprs)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the given expressions.</div><div class=\"line\">   * This is an alias of the `sort` function.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def orderBy(sortCol: String, sortCols: String*): Dataset[T] = sort(sortCol, sortCols : _*)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the given expressions.</div><div class=\"line\">   * This is an alias of the `sort` function.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def orderBy(sortExprs: Column*): Dataset[T] = sort(sortExprs : _*)</div></pre></td></tr></table></figure>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Selects column based on the column name and return it as a [[Column]].</div><div class=\"line\"> *</div><div class=\"line\"> * @note The column name can also reference to a nested column like `a.b`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def apply(colName: String): Column = col(colName)</div><div class=\"line\">/**</div><div class=\"line\"> * Selects column based on the column name and return it as a [[Column]].</div><div class=\"line\"> *</div><div class=\"line\"> * @note The column name can also reference to a nested column like `a.b`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def col(colName: String): Column = colName match &#123;</div><div class=\"line\">  case &quot;*&quot; =&gt;</div><div class=\"line\">    Column(ResolvedStar(queryExecution.analyzed.output))</div><div class=\"line\">  case _ =&gt;</div><div class=\"line\">    val expr = resolve(colName)</div><div class=\"line\">    Column(expr)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>datasetdataset<br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset with an alias set.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def as(alias: String): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  SubqueryAlias(alias, logicalPlan, None)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Returns a new Dataset with an alias set.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def as(alias: Symbol): Dataset[T] = as(alias.name)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset with an alias set. Same as `as`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def alias(alias: String): Dataset[T] = as(alias)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Returns a new Dataset with an alias set. Same as `as`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def alias(alias: Symbol): Dataset[T] = as(alias)</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Selects a set of column based expressions.</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.select($&quot;colA&quot;, $&quot;colB&quot; + 1)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def select(cols: Column*): DataFrame = withPlan &#123;</div><div class=\"line\">    Project(cols.map(_.named), logicalPlan)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Selects a set of columns. This is a variant of `select` that can only select</div><div class=\"line\">   * existing columns using column names (i.e. cannot construct expressions).</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following two are equivalent:</div><div class=\"line\">   *   ds.select(&quot;colA&quot;, &quot;colB&quot;)</div><div class=\"line\">   *   ds.select($&quot;colA&quot;, $&quot;colB&quot;)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def select(col: String, cols: String*): DataFrame = select((col +: cols).map(Column(_)) : _*)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Selects a set of SQL expressions. This is a variant of `select` that accepts</div><div class=\"line\">   * SQL expressions.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following are equivalent:</div><div class=\"line\">   *   ds.selectExpr(&quot;colA&quot;, &quot;colB as newName&quot;, &quot;abs(colC)&quot;)</div><div class=\"line\">   *   ds.select(expr(&quot;colA&quot;), expr(&quot;colB as newName&quot;), expr(&quot;abs(colC)&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def selectExpr(exprs: String*): DataFrame = &#123;</div><div class=\"line\">    select(exprs.map &#123; expr =&gt;</div><div class=\"line\">      Column(sparkSession.sessionState.sqlParser.parseExpression(expr))</div><div class=\"line\">    &#125;: _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expression for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   val ds = Seq(1, 2, 3).toDS()</div><div class=\"line\">   *   val newDS = ds.select(expr(&quot;value + 1&quot;).as[Int])</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1](c1: TypedColumn[T, U1]): Dataset[U1] = &#123;</div><div class=\"line\">    implicit val encoder = c1.encoder</div><div class=\"line\">    val project = Project(c1.withInputType(exprEnc, logicalPlan.output).named :: Nil,</div><div class=\"line\">      logicalPlan)</div><div class=\"line\"></div><div class=\"line\">    if (encoder.flat) &#123;</div><div class=\"line\">      new Dataset[U1](sparkSession, project, encoder)</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      // Flattens inner fields of U1</div><div class=\"line\">      new Dataset[Tuple1[U1]](sparkSession, project, ExpressionEncoder.tuple(encoder)).map(_._1)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Internal helper function for building typed selects that return tuples. For simplicity and</div><div class=\"line\">   * code reuse, we do this without the help of the type system and then use helper functions</div><div class=\"line\">   * that cast appropriately for the user facing interface.</div><div class=\"line\">   */</div><div class=\"line\">  ???</div><div class=\"line\">  protected def selectUntyped(columns: TypedColumn[_, _]*): Dataset[_] = &#123;</div><div class=\"line\">    val encoders = columns.map(_.encoder)</div><div class=\"line\">    val namedColumns =</div><div class=\"line\">      columns.map(_.withInputType(exprEnc, logicalPlan.output).named)</div><div class=\"line\">    val execution = new QueryExecution(sparkSession, Project(namedColumns, logicalPlan))</div><div class=\"line\">    new Dataset(sparkSession, execution, ExpressionEncoder.tuple(encoders))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2](c1: TypedColumn[T, U1], c2: TypedColumn[T, U2]): Dataset[(U1, U2)] =</div><div class=\"line\">    selectUntyped(c1, c2).asInstanceOf[Dataset[(U1, U2)]]</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2, U3](</div><div class=\"line\">      c1: TypedColumn[T, U1],</div><div class=\"line\">      c2: TypedColumn[T, U2],</div><div class=\"line\">      c3: TypedColumn[T, U3]): Dataset[(U1, U2, U3)] =</div><div class=\"line\">    selectUntyped(c1, c2, c3).asInstanceOf[Dataset[(U1, U2, U3)]]</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2, U3, U4](</div><div class=\"line\">      c1: TypedColumn[T, U1],</div><div class=\"line\">      c2: TypedColumn[T, U2],</div><div class=\"line\">      c3: TypedColumn[T, U3],</div><div class=\"line\">      c4: TypedColumn[T, U4]): Dataset[(U1, U2, U3, U4)] =</div><div class=\"line\">    selectUntyped(c1, c2, c3, c4).asInstanceOf[Dataset[(U1, U2, U3, U4)]]</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2, U3, U4, U5](</div><div class=\"line\">      c1: TypedColumn[T, U1],</div><div class=\"line\">      c2: TypedColumn[T, U2],</div><div class=\"line\">      c3: TypedColumn[T, U3],</div><div class=\"line\">      c4: TypedColumn[T, U4],</div><div class=\"line\">      c5: TypedColumn[T, U5]): Dataset[(U1, U2, U3, U4, U5)] =</div><div class=\"line\">    selectUntyped(c1, c2, c3, c4, c5).asInstanceOf[Dataset[(U1, U2, U3, U4, U5)]]</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>sqlwhere<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given condition.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // The following are equivalent:</div><div class=\"line\"> *   peopleDs.filter($&quot;age&quot; &gt; 15)</div><div class=\"line\"> *   peopleDs.where($&quot;age&quot; &gt; 15)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def filter(condition: Column): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Filter(condition.expr, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given SQL expression.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   peopleDs.filter(&quot;age &gt; 15&quot;)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def filter(conditionExpr: String): Dataset[T] = &#123;</div><div class=\"line\">  filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given condition. This is an alias for `filter`.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // The following are equivalent:</div><div class=\"line\"> *   peopleDs.filter($&quot;age&quot; &gt; 15)</div><div class=\"line\"> *   peopleDs.where($&quot;age&quot; &gt; 15)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def where(condition: Column): Dataset[T] = filter(condition)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given SQL expression.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   peopleDs.where(&quot;age &gt; 15&quot;)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def where(conditionExpr: String): Dataset[T] = &#123;</div><div class=\"line\">  filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Groups the Dataset using the specified columns, so we can run aggregation on them. See</div><div class=\"line\"> * [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns grouped by department.</div><div class=\"line\"> *   ds.groupBy($&quot;department&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, grouped by department and gender.</div><div class=\"line\"> *   ds.groupBy($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def groupBy(cols: Column*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.GroupByType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional rollup for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns rolluped by department and group.</div><div class=\"line\"> *   ds.rollup($&quot;department&quot;, $&quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, rolluped by department and gender.</div><div class=\"line\"> *   ds.rollup($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def rollup(cols: Column*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.RollupType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional cube for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns cubed by department and group.</div><div class=\"line\"> *   ds.cube($&quot;department&quot;, $&quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, cubed by department and gender.</div><div class=\"line\"> *   ds.cube($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def cube(cols: Column*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.CubeType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Groups the Dataset using the specified columns, so that we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * This is a variant of groupBy that can only group by existing columns using column names</div><div class=\"line\"> * (i.e. cannot construct expressions).</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns grouped by department.</div><div class=\"line\"> *   ds.groupBy(&quot;department&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, grouped by department and gender.</div><div class=\"line\"> *   ds.groupBy($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def groupBy(col1: String, cols: String*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  RelationalGroupedDataset(</div><div class=\"line\">    toDF(), colNames.map(colName =&gt; resolve(colName)), RelationalGroupedDataset.GroupByType)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"reduce\"><a href=\"#reduce\" class=\"headerlink\" title=\"reduce\"></a>reduce</h2>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Reduces the elements of this Dataset using the specified binary function. The given `func`</div><div class=\"line\"> * must be commutative and associative or the result may be non-deterministic.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def reduce(func: (T, T) =&gt; T): T = rdd.reduce(func)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Reduces the elements of this Dataset using the specified binary function. The given `func`</div><div class=\"line\"> * must be commutative and associative or the result may be non-deterministic.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def reduce(func: ReduceFunction[T]): T = reduce(func.call(_, _))</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">                                  </div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def groupByKey[K: Encoder](func: T =&gt; K): KeyValueGroupedDataset[K, T] = &#123;</div><div class=\"line\">  val inputPlan = logicalPlan</div><div class=\"line\">  val withGroupingKey = AppendColumns(func, inputPlan)</div><div class=\"line\">  val executed = sparkSession.sessionState.executePlan(withGroupingKey)</div><div class=\"line\"></div><div class=\"line\">  new KeyValueGroupedDataset(</div><div class=\"line\">    encoderFor[K],</div><div class=\"line\">    encoderFor[T],</div><div class=\"line\">    executed,</div><div class=\"line\">    inputPlan.output,</div><div class=\"line\">    withGroupingKey.newColumns)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def groupByKey[K](func: MapFunction[T, K], encoder: Encoder[K]): KeyValueGroupedDataset[K, T] =</div><div class=\"line\">  groupByKey(func.call(_))(encoder)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional rollup for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * This is a variant of rollup that can only group by existing columns using column names</div><div class=\"line\"> * (i.e. cannot construct expressions).</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns rolluped by department and group.</div><div class=\"line\"> *   ds.rollup(&quot;department&quot;, &quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, rolluped by department and gender.</div><div class=\"line\"> *   ds.rollup($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def rollup(col1: String, cols: String*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  RelationalGroupedDataset(</div><div class=\"line\">    toDF(), colNames.map(colName =&gt; resolve(colName)), RelationalGroupedDataset.RollupType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional cube for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * This is a variant of cube that can only group by existing columns using column names</div><div class=\"line\"> * (i.e. cannot construct expressions).</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns cubed by department and group.</div><div class=\"line\"> *   ds.cube(&quot;department&quot;, &quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, cubed by department and gender.</div><div class=\"line\"> *   ds.cube($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def cube(col1: String, cols: String*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  RelationalGroupedDataset(</div><div class=\"line\">    toDF(), colNames.map(colName =&gt; resolve(colName)), RelationalGroupedDataset.CubeType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;)</div><div class=\"line\"> *   ds.groupBy().agg(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def agg(aggExpr: (String, String), aggExprs: (String, String)*): DataFrame = &#123;</div><div class=\"line\">  groupBy().agg(aggExpr, aggExprs : _*)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> *   ds.groupBy().agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def agg(exprs: Map[String, String]): DataFrame = groupBy().agg(exprs)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Java-specific) Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> *   ds.groupBy().agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def agg(exprs: java.util.Map[String, String]): DataFrame = groupBy().agg(exprs)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(max($&quot;age&quot;), avg($&quot;salary&quot;))</div><div class=\"line\"> *   ds.groupBy().agg(max($&quot;age&quot;), avg($&quot;salary&quot;))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def agg(expr: Column, exprs: Column*): DataFrame = groupBy().agg(expr, exprs : _*)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset by taking the first `n` rows. The difference between this function</div><div class=\"line\"> * and `head` is that `head` is an action and returns an array (by triggering query execution)</div><div class=\"line\"> * while `limit` returns a new Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def limit(n: Int): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Limit(Literal(n), logicalPlan)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div><div class=\"line\"> * This is equivalent to `UNION ALL` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * To do a SQL-style set union (that does deduplication of elements), use this function followed</div><div class=\"line\"> * by a [[distinct]].</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@deprecated(&quot;use union()&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">def unionAll(other: Dataset[T]): Dataset[T] = union(other)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div><div class=\"line\"> * This is equivalent to `UNION ALL` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * To do a SQL-style set union (that does deduplication of elements), use this function followed</div><div class=\"line\"> * by a [[distinct]].</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def union(other: Dataset[T]): Dataset[T] = withSetOperator &#123;</div><div class=\"line\">  // This breaks caching, but it&apos;s usually ok because it addresses a very specific use case:</div><div class=\"line\">  // using union to union many files or partitions.</div><div class=\"line\">  CombineUnions(Union(logicalPlan, other.logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing rows only in both this Dataset and another Dataset.</div><div class=\"line\"> * This is equivalent to `INTERSECT` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * @note Equality checking is performed directly on the encoded representation of the data</div><div class=\"line\"> * and thus is not affected by a custom `equals` function defined on `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def intersect(other: Dataset[T]): Dataset[T] = withSetOperator &#123;</div><div class=\"line\">  Intersect(logicalPlan, other.logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing rows in this Dataset but not in another Dataset.</div><div class=\"line\"> * This is equivalent to `EXCEPT` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * @note Equality checking is performed directly on the encoded representation of the data</div><div class=\"line\"> * and thus is not affected by a custom `equals` function defined on `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def except(other: Dataset[T]): Dataset[T] = withSetOperator &#123;</div><div class=\"line\">  Except(logicalPlan, other.logicalPlan)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div><div class=\"line\">175</div><div class=\"line\">176</div><div class=\"line\">177</div><div class=\"line\">178</div><div class=\"line\">179</div><div class=\"line\">180</div><div class=\"line\">181</div><div class=\"line\">182</div><div class=\"line\">183</div><div class=\"line\">184</div><div class=\"line\">185</div><div class=\"line\">186</div><div class=\"line\">187</div><div class=\"line\">188</div><div class=\"line\">189</div><div class=\"line\">190</div><div class=\"line\">191</div><div class=\"line\">192</div><div class=\"line\">193</div><div class=\"line\">194</div><div class=\"line\">195</div><div class=\"line\">196</div><div class=\"line\">197</div><div class=\"line\">198</div><div class=\"line\">199</div><div class=\"line\">200</div><div class=\"line\">201</div><div class=\"line\">202</div><div class=\"line\">203</div><div class=\"line\">204</div><div class=\"line\">205</div><div class=\"line\">206</div><div class=\"line\">207</div><div class=\"line\">208</div><div class=\"line\">209</div><div class=\"line\">210</div><div class=\"line\">211</div><div class=\"line\">212</div><div class=\"line\">213</div><div class=\"line\">214</div><div class=\"line\">215</div><div class=\"line\">216</div><div class=\"line\">217</div><div class=\"line\">218</div><div class=\"line\">219</div><div class=\"line\">220</div><div class=\"line\">221</div><div class=\"line\">222</div><div class=\"line\">223</div><div class=\"line\">224</div><div class=\"line\">225</div><div class=\"line\">226</div><div class=\"line\">227</div><div class=\"line\">228</div><div class=\"line\">229</div><div class=\"line\">230</div><div class=\"line\">231</div><div class=\"line\">232</div><div class=\"line\">233</div><div class=\"line\">234</div><div class=\"line\">235</div><div class=\"line\">236</div><div class=\"line\">237</div><div class=\"line\">238</div><div class=\"line\">239</div><div class=\"line\">240</div><div class=\"line\">241</div><div class=\"line\">242</div><div class=\"line\">243</div><div class=\"line\">244</div><div class=\"line\">245</div><div class=\"line\">246</div><div class=\"line\">247</div><div class=\"line\">248</div><div class=\"line\">249</div><div class=\"line\">250</div><div class=\"line\">251</div><div class=\"line\">252</div><div class=\"line\">253</div><div class=\"line\">254</div><div class=\"line\">255</div><div class=\"line\">256</div><div class=\"line\">257</div><div class=\"line\">258</div><div class=\"line\">259</div><div class=\"line\">260</div><div class=\"line\">261</div><div class=\"line\">262</div><div class=\"line\">263</div><div class=\"line\">264</div><div class=\"line\">265</div><div class=\"line\">266</div><div class=\"line\">267</div><div class=\"line\">268</div><div class=\"line\">269</div><div class=\"line\">270</div><div class=\"line\">271</div><div class=\"line\">272</div><div class=\"line\">273</div><div class=\"line\">274</div><div class=\"line\">275</div><div class=\"line\">276</div><div class=\"line\">277</div><div class=\"line\">278</div><div class=\"line\">279</div><div class=\"line\">280</div><div class=\"line\">281</div><div class=\"line\">282</div><div class=\"line\">283</div><div class=\"line\">284</div><div class=\"line\">285</div><div class=\"line\">286</div><div class=\"line\">287</div><div class=\"line\">288</div><div class=\"line\">289</div><div class=\"line\">290</div><div class=\"line\">291</div><div class=\"line\">292</div><div class=\"line\">293</div><div class=\"line\">294</div><div class=\"line\">295</div><div class=\"line\">296</div><div class=\"line\">297</div><div class=\"line\">298</div><div class=\"line\">299</div><div class=\"line\">300</div><div class=\"line\">301</div><div class=\"line\">302</div><div class=\"line\">303</div><div class=\"line\">304</div><div class=\"line\">305</div><div class=\"line\">306</div><div class=\"line\">307</div><div class=\"line\">308</div><div class=\"line\">309</div><div class=\"line\">310</div><div class=\"line\">311</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new [[Dataset]] by sampling a fraction of rows, using a user-supplied seed.</div><div class=\"line\">   *</div><div class=\"line\">   * @param withReplacement Sample with replacement or not.</div><div class=\"line\">   * @param fraction Fraction of rows to generate.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   *</div><div class=\"line\">   * @note This is NOT guaranteed to provide exactly the fraction of the count</div><div class=\"line\">   * of the given [[Dataset]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def sample(withReplacement: Boolean, fraction: Double, seed: Long): Dataset[T] = &#123;</div><div class=\"line\">    require(fraction &gt;= 0,</div><div class=\"line\">      s&quot;Fraction must be nonnegative, but got $&#123;fraction&#125;&quot;)</div><div class=\"line\"></div><div class=\"line\">    withTypedPlan &#123;</div><div class=\"line\">      Sample(0.0, fraction, withReplacement, seed, logicalPlan)()</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new [[Dataset]] by sampling a fraction of rows, using a random seed.</div><div class=\"line\">   *</div><div class=\"line\">   * @param withReplacement Sample with replacement or not.</div><div class=\"line\">   * @param fraction Fraction of rows to generate.</div><div class=\"line\">   *</div><div class=\"line\">   * @note This is NOT guaranteed to provide exactly the fraction of the total count</div><div class=\"line\">   * of the given [[Dataset]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def sample(withReplacement: Boolean, fraction: Double): Dataset[T] = &#123;</div><div class=\"line\">    sample(withReplacement, fraction, Utils.random.nextLong)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Randomly splits this Dataset with the provided weights.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   *</div><div class=\"line\">   * For Java API, use [[randomSplitAsList]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  ???</div><div class=\"line\">  def randomSplit(weights: Array[Double], seed: Long): Array[Dataset[T]] = &#123;</div><div class=\"line\">    require(weights.forall(_ &gt;= 0),</div><div class=\"line\">      s&quot;Weights must be nonnegative, but got $&#123;weights.mkString(&quot;[&quot;, &quot;,&quot;, &quot;]&quot;)&#125;&quot;)</div><div class=\"line\">    require(weights.sum &gt; 0,</div><div class=\"line\">      s&quot;Sum of weights must be positive, but got $&#123;weights.mkString(&quot;[&quot;, &quot;,&quot;, &quot;]&quot;)&#125;&quot;)</div><div class=\"line\"></div><div class=\"line\">    // It is possible that the underlying dataframe doesn&apos;t guarantee the ordering of rows in its</div><div class=\"line\">    // constituent partitions each time a split is materialized which could result in</div><div class=\"line\">    // overlapping splits. To prevent this, we explicitly sort each input partition to make the</div><div class=\"line\">    // ordering deterministic.</div><div class=\"line\">    // MapType cannot be sorted.</div><div class=\"line\">    val sorted = Sort(logicalPlan.output.filterNot(_.dataType.isInstanceOf[MapType])</div><div class=\"line\">      .map(SortOrder(_, Ascending)), global = false, logicalPlan)</div><div class=\"line\">    val sum = weights.sum</div><div class=\"line\">    val normalizedCumWeights = weights.map(_ / sum).scanLeft(0.0d)(_ + _)</div><div class=\"line\">    normalizedCumWeights.sliding(2).map &#123; x =&gt;</div><div class=\"line\">      new Dataset[T](</div><div class=\"line\">        sparkSession, Sample(x(0), x(1), withReplacement = false, seed, sorted)(), encoder)</div><div class=\"line\">    &#125;.toArray</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a Java list that contains randomly split Dataset with the provided weights.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def randomSplitAsList(weights: Array[Double], seed: Long): java.util.List[Dataset[T]] = &#123;</div><div class=\"line\">    val values = randomSplit(weights, seed)</div><div class=\"line\">    java.util.Arrays.asList(values : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Randomly splits this Dataset with the provided weights.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def randomSplit(weights: Array[Double]): Array[Dataset[T]] = &#123;</div><div class=\"line\">    randomSplit(weights, Utils.random.nextLong)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Randomly splits this Dataset with the provided weights. Provided for the Python Api.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   */</div><div class=\"line\">  private[spark] def randomSplit(weights: List[Double], seed: Long): Array[Dataset[T]] = &#123;</div><div class=\"line\">    randomSplit(weights.toArray, seed)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * (Scala-specific) Returns a new Dataset where each row has been expanded to zero or more</div><div class=\"line\">   * rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. The columns of</div><div class=\"line\">   * the input row are implicitly joined with each row that is output by the function.</div><div class=\"line\">   *</div><div class=\"line\">   * Given that this is deprecated, as an alternative, you can explode columns either using</div><div class=\"line\">   * `functions.explode()` or `flatMap()`. The following example uses these alternatives to count</div><div class=\"line\">   * the number of books that contain a given word:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   case class Book(title: String, words: String)</div><div class=\"line\">   *   val ds: Dataset[Book]</div><div class=\"line\">   *</div><div class=\"line\">   *   val allWords = ds.select(&apos;title, explode(split(&apos;words, &quot; &quot;)).as(&quot;word&quot;))</div><div class=\"line\">   *</div><div class=\"line\">   *   val bookCountPerWord = allWords.groupBy(&quot;word&quot;).agg(countDistinct(&quot;title&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * Using `flatMap()` this can similarly be exploded as:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.flatMap(_.words.split(&quot; &quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  @deprecated(&quot;use flatMap() or select() with functions.explode() instead&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">  def explode[A &lt;: Product : TypeTag](input: Column*)(f: Row =&gt; TraversableOnce[A]): DataFrame = &#123;</div><div class=\"line\">    val elementSchema = ScalaReflection.schemaFor[A].dataType.asInstanceOf[StructType]</div><div class=\"line\"></div><div class=\"line\">    val convert = CatalystTypeConverters.createToCatalystConverter(elementSchema)</div><div class=\"line\"></div><div class=\"line\">    val rowFunction =</div><div class=\"line\">      f.andThen(_.map(convert(_).asInstanceOf[InternalRow]))</div><div class=\"line\">    val generator = UserDefinedGenerator(elementSchema, rowFunction, input.map(_.expr))</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      Generate(generator, join = true, outer = false,</div><div class=\"line\">        qualifier = None, generatorOutput = Nil, logicalPlan)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * (Scala-specific) Returns a new Dataset where a single column has been expanded to zero</div><div class=\"line\">   * or more rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. All</div><div class=\"line\">   * columns of the input row are implicitly joined with each value that is output by the function.</div><div class=\"line\">   *</div><div class=\"line\">   * Given that this is deprecated, as an alternative, you can explode columns either using</div><div class=\"line\">   * `functions.explode()`:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.select(explode(split(&apos;words, &quot; &quot;)).as(&quot;word&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * or `flatMap()`:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.flatMap(_.words.split(&quot; &quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @deprecated(&quot;use flatMap() or select() with functions.explode() instead&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">  def explode[A, B : TypeTag](inputColumn: String, outputColumn: String)(f: A =&gt; TraversableOnce[B])</div><div class=\"line\">    : DataFrame = &#123;</div><div class=\"line\">    val dataType = ScalaReflection.schemaFor[B].dataType</div><div class=\"line\">    val attributes = AttributeReference(outputColumn, dataType)() :: Nil</div><div class=\"line\">    // TODO handle the metadata?</div><div class=\"line\">    val elementSchema = attributes.toStructType</div><div class=\"line\"></div><div class=\"line\">    def rowFunction(row: Row): TraversableOnce[InternalRow] = &#123;</div><div class=\"line\">      val convert = CatalystTypeConverters.createToCatalystConverter(dataType)</div><div class=\"line\">      f(row(0).asInstanceOf[A]).map(o =&gt; InternalRow(convert(o)))</div><div class=\"line\">    &#125;</div><div class=\"line\">    val generator = UserDefinedGenerator(elementSchema, rowFunction, apply(inputColumn).expr :: Nil)</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      Generate(generator, join = true, outer = false,</div><div class=\"line\">        qualifier = None, generatorOutput = Nil, logicalPlan)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">## </div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset by adding a column or replacing the existing column that has</div><div class=\"line\">   * the same name.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def withColumn(colName: String, col: Column): DataFrame = &#123;</div><div class=\"line\">    val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">    val output = queryExecution.analyzed.output</div><div class=\"line\">    val shouldReplace = output.exists(f =&gt; resolver(f.name, colName))</div><div class=\"line\">    if (shouldReplace) &#123;</div><div class=\"line\">      val columns = output.map &#123; field =&gt;</div><div class=\"line\">        if (resolver(field.name, colName)) &#123;</div><div class=\"line\">          col.as(colName)</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          Column(field)</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">      select(columns : _*)</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      select(Column(&quot;*&quot;), col.as(colName))</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset by adding a column with metadata.</div><div class=\"line\">   */</div><div class=\"line\">  private[spark] def withColumn(colName: String, col: Column, metadata: Metadata): DataFrame = &#123;</div><div class=\"line\">    withColumn(colName, col.as(colName, metadata))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with a column renamed.</div><div class=\"line\">   * This is a no-op if schema doesn&apos;t contain existingName.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def withColumnRenamed(existingName: String, newName: String): DataFrame = &#123;</div><div class=\"line\">    val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">    val output = queryExecution.analyzed.output</div><div class=\"line\">    val shouldRename = output.exists(f =&gt; resolver(f.name, existingName))</div><div class=\"line\">    if (shouldRename) &#123;</div><div class=\"line\">      val columns = output.map &#123; col =&gt;</div><div class=\"line\">        if (resolver(col.name, existingName)) &#123;</div><div class=\"line\">          Column(col).as(newName)</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          Column(col)</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">      select(columns : _*)</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      toDF()</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with a column dropped. This is a no-op if schema doesn&apos;t contain</div><div class=\"line\">   * column name.</div><div class=\"line\">   *</div><div class=\"line\">   * This method can only be used to drop top level columns. the colName string is treated</div><div class=\"line\">   * literally without further interpretation.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def drop(colName: String): DataFrame = &#123;</div><div class=\"line\">    drop(Seq(colName) : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with columns dropped.</div><div class=\"line\">   * This is a no-op if schema doesn&apos;t contain column name(s).</div><div class=\"line\">   *</div><div class=\"line\">   * This method can only be used to drop top level columns. the colName string is treated literally</div><div class=\"line\">   * without further interpretation.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def drop(colNames: String*): DataFrame = &#123;</div><div class=\"line\">    val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">    val allColumns = queryExecution.analyzed.output</div><div class=\"line\">    val remainingCols = allColumns.filter &#123; attribute =&gt;</div><div class=\"line\">      colNames.forall(n =&gt; !resolver(attribute.name, n))</div><div class=\"line\">    &#125;.map(attribute =&gt; Column(attribute))</div><div class=\"line\">    if (remainingCols.size == allColumns.size) &#123;</div><div class=\"line\">      toDF()</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      this.select(remainingCols: _*)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with a column dropped.</div><div class=\"line\">   * This version of drop accepts a [[Column]] rather than a name.</div><div class=\"line\">   * This is a no-op if the Dataset doesn&apos;t have a column</div><div class=\"line\">   * with an equivalent expression.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def drop(col: Column): DataFrame = &#123;</div><div class=\"line\">    val expression = col match &#123;</div><div class=\"line\">      case Column(u: UnresolvedAttribute) =&gt;</div><div class=\"line\">        queryExecution.analyzed.resolveQuoted(</div><div class=\"line\">          u.name, sparkSession.sessionState.analyzer.resolver).getOrElse(u)</div><div class=\"line\">      case Column(expr: Expression) =&gt; expr</div><div class=\"line\">    &#125;</div><div class=\"line\">    val attrs = this.logicalPlan.output</div><div class=\"line\">    val colsAfterDrop = attrs.filter &#123; attr =&gt;</div><div class=\"line\">      attr != expression</div><div class=\"line\">    &#125;.map(attr =&gt; Column(attr))</div><div class=\"line\">    select(colsAfterDrop : _*)</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that contains only the unique rows from this Dataset.</div><div class=\"line\"> * This is an alias for `distinct`.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def dropDuplicates(): Dataset[T] = dropDuplicates(this.columns)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Returns a new Dataset with duplicate rows removed, considering only</div><div class=\"line\"> * the subset of columns.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def dropDuplicates(colNames: Seq[String]): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">  val allColumns = queryExecution.analyzed.output</div><div class=\"line\">  val groupCols = colNames.toSet.toSeq.flatMap &#123; (colName: String) =&gt;</div><div class=\"line\">    // It is possibly there are more than one columns with the same name,</div><div class=\"line\">    // so we call filter instead of find.</div><div class=\"line\">    val cols = allColumns.filter(col =&gt; resolver(col.name, colName))</div><div class=\"line\">    if (cols.isEmpty) &#123;</div><div class=\"line\">      throw new AnalysisException(</div><div class=\"line\">        s&quot;&quot;&quot;Cannot resolve column name &quot;$colName&quot; among ($&#123;schema.fieldNames.mkString(&quot;, &quot;)&#125;)&quot;&quot;&quot;)</div><div class=\"line\">    &#125;</div><div class=\"line\">    cols</div><div class=\"line\">  &#125;</div><div class=\"line\">  Deduplicate(groupCols, logicalPlan, isStreaming)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset with duplicate rows removed, considering only</div><div class=\"line\"> * the subset of columns.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def dropDuplicates(colNames: Array[String]): Dataset[T] = dropDuplicates(colNames.toSeq)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new [[Dataset]] with duplicate rows removed, considering only</div><div class=\"line\"> * the subset of columns.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def dropDuplicates(col1: String, cols: String*): Dataset[T] = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  dropDuplicates(colNames)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><pre><code><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Computes statistics for numeric and string columns, including count, mean, stddev, min, and</div><div class=\"line\"> * max. If no columns are given, this function computes statistics for all numerical or string</div><div class=\"line\"> * columns.</div><div class=\"line\"> *</div><div class=\"line\"> * This function is meant for exploratory data analysis, as we make no guarantee about the</div><div class=\"line\"> * backward compatibility of the schema of the resulting Dataset. If you want to</div><div class=\"line\"> * programmatically compute summary statistics, use the `agg` function instead.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   ds.describe(&quot;age&quot;, &quot;height&quot;).show()</div><div class=\"line\"> *</div><div class=\"line\"> *   // output:</div><div class=\"line\"> *   // summary age   height</div><div class=\"line\"> *   // count   10.0  10.0</div><div class=\"line\"> *   // mean    53.3  178.05</div><div class=\"line\"> *   // stddev  11.6  15.7</div><div class=\"line\"> *   // min     18.0  163.0</div><div class=\"line\"> *   // max     92.0  192.0</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def describe(cols: String*): DataFrame = withPlan &#123;</div><div class=\"line\"></div><div class=\"line\">  // The list of summary statistics to compute, in the form of expressions.</div><div class=\"line\">  val statistics = List[(String, Expression =&gt; Expression)](</div><div class=\"line\">    &quot;count&quot; -&gt; ((child: Expression) =&gt; Count(child).toAggregateExpression()),</div><div class=\"line\">    &quot;mean&quot; -&gt; ((child: Expression) =&gt; Average(child).toAggregateExpression()),</div><div class=\"line\">    &quot;stddev&quot; -&gt; ((child: Expression) =&gt; StddevSamp(child).toAggregateExpression()),</div><div class=\"line\">    &quot;min&quot; -&gt; ((child: Expression) =&gt; Min(child).toAggregateExpression()),</div><div class=\"line\">    &quot;max&quot; -&gt; ((child: Expression) =&gt; Max(child).toAggregateExpression()))</div><div class=\"line\"></div><div class=\"line\">  val outputCols =</div><div class=\"line\">    (if (cols.isEmpty) aggregatableColumns.map(usePrettyExpression(_).sql) else cols).toList</div><div class=\"line\"></div><div class=\"line\">  val ret: Seq[Row] = if (outputCols.nonEmpty) &#123;</div><div class=\"line\">    val aggExprs = statistics.flatMap &#123; case (_, colToAgg) =&gt;</div><div class=\"line\">      outputCols.map(c =&gt; Column(Cast(colToAgg(Column(c).expr), StringType)).as(c))</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    val row = groupBy().agg(aggExprs.head, aggExprs.tail: _*).head().toSeq</div><div class=\"line\"></div><div class=\"line\">    // Pivot the data so each summary is one row</div><div class=\"line\">    row.grouped(outputCols.size).toSeq.zip(statistics).map &#123; case (aggregation, (statistic, _)) =&gt;</div><div class=\"line\">      Row(statistic :: aggregation.toList: _*)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125; else &#123;</div><div class=\"line\">    // If there are no output columns, just output a single column that contains the stats.</div><div class=\"line\">    statistics.map &#123; case (name, _) =&gt; Row(name) &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  // All columns are string type</div><div class=\"line\">  val schema = StructType(</div><div class=\"line\">    StructField(&quot;summary&quot;, StringType) :: outputCols.map(StructField(_, StringType))).toAttributes</div><div class=\"line\">  // `toArray` forces materialization to make the seq serializable</div><div class=\"line\">  LocalRelation.fromExternalRows(schema, ret.toArray.toSeq)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the first `n` rows.</div><div class=\"line\"> *</div><div class=\"line\"> * @note this method should only be used if the resulting array is expected to be small, as</div><div class=\"line\"> * all the data is loaded into the driver&apos;s memory.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">n</div><div class=\"line\">def head(n: Int): Array[T] = withAction(&quot;head&quot;, limit(n).queryExecution)(collectFromPlan)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the first row.</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def head(): T = head(1).head</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the first row. Alias for head().</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def first(): T = head()</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Concise syntax for chaining custom transformations.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   def featurize(ds: Dataset[T]): Dataset[U] = ...</div><div class=\"line\"> *</div><div class=\"line\"> *   ds</div><div class=\"line\"> *     .transform(featurize)</div><div class=\"line\"> *     .transform(...)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def transform[U](t: Dataset[T] =&gt; Dataset[U]): Dataset[U] = t(this)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset that only contains elements where `func` returns `true`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def filter(func: T =&gt; Boolean): Dataset[T] = &#123;</div><div class=\"line\">  withTypedPlan(TypedFilter(func, logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset that only contains elements where `func` returns `true`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def filter(func: FilterFunction[T]): Dataset[T] = &#123;</div><div class=\"line\">  withTypedPlan(TypedFilter(func, logicalPlan))</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</code></pre><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `func` to each element.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def map[U : Encoder](func: T =&gt; U): Dataset[U] = withTypedPlan &#123;</div><div class=\"line\">  MapElements[T, U](func, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `func` to each element.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def map[U](func: MapFunction[T, U], encoder: Encoder[U]): Dataset[U] = &#123;</div><div class=\"line\">  implicit val uEnc = encoder</div><div class=\"line\">  withTypedPlan(MapElements[T, U](func, logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `func` to each partition.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def mapPartitions[U : Encoder](func: Iterator[T] =&gt; Iterator[U]): Dataset[U] = &#123;</div><div class=\"line\">  new Dataset[U](</div><div class=\"line\">    sparkSession,</div><div class=\"line\">    MapPartitions[T, U](func, logicalPlan),</div><div class=\"line\">    implicitly[Encoder[U]])</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `f` to each partition.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def mapPartitions[U](f: MapPartitionsFunction[T, U], encoder: Encoder[U]): Dataset[U] = &#123;</div><div class=\"line\">  val func: (Iterator[T]) =&gt; Iterator[U] = x =&gt; f.call(x.asJava).asScala</div><div class=\"line\">  mapPartitions(func)(encoder)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new `DataFrame` that contains the result of applying a serialized R function</div><div class=\"line\"> * `func` to each partition.</div><div class=\"line\"> */</div><div class=\"line\">private[sql] def mapPartitionsInR(</div><div class=\"line\">    func: Array[Byte],</div><div class=\"line\">    packageNames: Array[Byte],</div><div class=\"line\">    broadcastVars: Array[Broadcast[Object]],</div><div class=\"line\">    schema: StructType): DataFrame = &#123;</div><div class=\"line\">  val rowEncoder = encoder.asInstanceOf[ExpressionEncoder[Row]]</div><div class=\"line\">  Dataset.ofRows(</div><div class=\"line\">    sparkSession,</div><div class=\"line\">    MapPartitionsInR(func, packageNames, broadcastVars, schema, rowEncoder, logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset by first applying a function to all elements of this Dataset,</div><div class=\"line\"> * and then flattening the results.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def flatMap[U : Encoder](func: T =&gt; TraversableOnce[U]): Dataset[U] =</div><div class=\"line\">  mapPartitions(_.flatMap(func))</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset by first applying a function to all elements of this Dataset,</div><div class=\"line\"> * and then flattening the results.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def flatMap[U](f: FlatMapFunction[T, U], encoder: Encoder[U]): Dataset[U] = &#123;</div><div class=\"line\">  val func: (T) =&gt; Iterator[U] = x =&gt; f.call(x).asScala</div><div class=\"line\">  flatMap(func)(encoder)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Applies a function `f` to all rows.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def foreach(f: T =&gt; Unit): Unit = withNewExecutionId &#123;</div><div class=\"line\">  rdd.foreach(f)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Runs `func` on each element of this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def foreach(func: ForeachFunction[T]): Unit = foreach(func.call(_))</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Applies a function `f` to each partition of this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def foreachPartition(f: Iterator[T] =&gt; Unit): Unit = withNewExecutionId &#123;</div><div class=\"line\">  rdd.foreachPartition(f)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * (Java-specific)</div><div class=\"line\">   * Runs `func` on each partition of this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def foreachPartition(func: ForeachPartitionFunction[T]): Unit =</div><div class=\"line\">    foreachPartition(it =&gt; func.call(it.asJava))</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns the first `n` rows in the Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * Running take requires moving data into the application&apos;s driver process, and doing so with</div><div class=\"line\">   * a very large `n` can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def take(n: Int): Array[T] = head(n)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns the first `n` rows in the Dataset as a list.</div><div class=\"line\">   *</div><div class=\"line\">   * Running take requires moving data into the application&apos;s driver process, and doing so with</div><div class=\"line\">   * a very large `n` can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">    </div><div class=\"line\">  def takeAsList(n: Int): java.util.List[T] = java.util.Arrays.asList(take(n) : _*)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns an array that contains all rows in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * Running collect requires moving all the data into the application&apos;s driver process, and</div><div class=\"line\">   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * For Java API, use [[collectAsList]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">  def collect(): Array[T] = withAction(&quot;collect&quot;, queryExecution)(collectFromPlan)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a Java list that contains all rows in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * Running collect requires moving all the data into the application&apos;s driver process, and</div><div class=\"line\">   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def collectAsList(): java.util.List[T] = withAction(&quot;collectAsList&quot;, queryExecution) &#123; plan =&gt;</div><div class=\"line\">    val values = collectFromPlan(plan)</div><div class=\"line\">    java.util.Arrays.asList(values : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Return an iterator that contains all rows in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * The iterator will consume as much memory as the largest partition in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * @note this results in multiple Spark jobs, and if the input Dataset is the result</div><div class=\"line\">   * of a wide transformation (e.g. join with different partitioners), to avoid</div><div class=\"line\">   * recomputing the input Dataset should be cached first.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def toLocalIterator(): java.util.Iterator[T] = &#123;</div><div class=\"line\">    withAction(&quot;toLocalIterator&quot;, queryExecution) &#123; plan =&gt;</div><div class=\"line\">      plan.executeToIterator().map(boundEnc.fromRow).asJava</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns the number of rows in the Dataset.</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def count(): Long = withAction(&quot;count&quot;, groupBy().count().queryExecution) &#123; plan =&gt;</div><div class=\"line\">    plan.executeCollect().head.getLong(0)</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><pre><code><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that has exactly `numPartitions` partitions.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def repartition(numPartitions: Int): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Repartition(numPartitions, shuffle = true, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset partitioned by the given partitioning expressions into</div><div class=\"line\"> * `numPartitions`. The resulting Dataset is hash partitioned.</div><div class=\"line\"> *</div><div class=\"line\"> * This is the same operation as &quot;DISTRIBUTE BY&quot; in SQL (Hive QL).</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def repartition(numPartitions: Int, partitionExprs: Column*): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  RepartitionByExpression(partitionExprs.map(_.expr), logicalPlan, numPartitions)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset partitioned by the given partitioning expressions, using</div><div class=\"line\"> * `spark.sql.shuffle.partitions` as number of partitions.</div><div class=\"line\"> * The resulting Dataset is hash partitioned.</div><div class=\"line\"> *</div><div class=\"line\"> * This is the same operation as &quot;DISTRIBUTE BY&quot; in SQL (Hive QL).</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def repartition(partitionExprs: Column*): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  RepartitionByExpression(</div><div class=\"line\">    partitionExprs.map(_.expr), logicalPlan, sparkSession.sessionState.conf.numShufflePartitions)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that has exactly `numPartitions` partitions.</div><div class=\"line\"> * Similar to coalesce defined on an `RDD`, this operation results in a narrow dependency, e.g.</div><div class=\"line\"> * if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of</div><div class=\"line\"> * the 100 new partitions will claim 10 of the current partitions.  If a larger number of</div><div class=\"line\"> * partitions is requested, it will stay at the current number of partitions.</div><div class=\"line\"> *</div><div class=\"line\"> * However, if you&apos;re doing a drastic coalesce, e.g. to numPartitions = 1,</div><div class=\"line\"> * this may result in your computation taking place on fewer nodes than</div><div class=\"line\"> * you like (e.g. one node in the case of numPartitions = 1). To avoid this,</div><div class=\"line\"> * you can call repartition. This will add a shuffle step, but means the</div><div class=\"line\"> * current upstream partitions will be executed in parallel (per whatever</div><div class=\"line\"> * the current partitioning is).</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def coalesce(numPartitions: Int): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Repartition(numPartitions, shuffle = false, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that contains only the unique rows from this Dataset.</div><div class=\"line\"> * This is an alias for `dropDuplicates`.</div><div class=\"line\"> *</div><div class=\"line\"> * @note Equality checking is performed directly on the encoded representation of the data</div><div class=\"line\"> * and thus is not affected by a custom `equals` function defined on `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def distinct(): Dataset[T] = dropDuplicates()</div></pre></td></tr></table></figure>\n</code></pre><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>  rddrdd</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">                </div><div class=\"line\">def persist(): this.type = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.cacheQuery(this)</div><div class=\"line\">  this</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def cache(): this.type = persist()</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Persist this Dataset with the given storage level.</div><div class=\"line\"> * @param newLevel One of: `MEMORY_ONLY`, `MEMORY_AND_DISK`, `MEMORY_ONLY_SER`,</div><div class=\"line\"> *                 `MEMORY_AND_DISK_SER`, `DISK_ONLY`, `MEMORY_ONLY_2`,</div><div class=\"line\"> *                 `MEMORY_AND_DISK_2`, etc.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def persist(newLevel: StorageLevel): this.type = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.cacheQuery(this, None, newLevel)</div><div class=\"line\">  this</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Get the Dataset&apos;s current storage level, or StorageLevel.NONE if not persisted.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">def storageLevel: StorageLevel = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.lookupCachedData(this).map &#123; cachedData =&gt;</div><div class=\"line\">    cachedData.cachedRepresentation.storageLevel</div><div class=\"line\">  &#125;.getOrElse(StorageLevel.NONE)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div><div class=\"line\"> *</div><div class=\"line\"> * @param blocking Whether to block until all blocks are deleted.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def unpersist(blocking: Boolean): this.type = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.uncacheQuery(this, blocking)</div><div class=\"line\">  this</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def unpersist(): this.type = unpersist(blocking = false)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Represents the content of the Dataset as an `RDD` of `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">lazy val rdd: RDD[T] = &#123;</div><div class=\"line\">  val objectType = exprEnc.deserializer.dataType</div><div class=\"line\">  val deserialized = CatalystSerde.deserialize[T](logicalPlan)</div><div class=\"line\">  sparkSession.sessionState.executePlan(deserialized).toRdd.mapPartitions &#123; rows =&gt;</div><div class=\"line\">    rows.map(_.get(0, objectType).asInstanceOf[T])</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the content of the Dataset as a `JavaRDD` of `T`s.</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def toJavaRDD: JavaRDD[T] = rdd.toJavaRDD()</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the content of the Dataset as a `JavaRDD` of `T`s.</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def javaRDD: JavaRDD[T] = toJavaRDD</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>datasetsqldataset<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Registers this Dataset as a temporary table using the given name. The lifetime of this</div><div class=\"line\"> * temporary table is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@deprecated(&quot;Use createOrReplaceTempView(viewName) instead.&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">def registerTempTable(tableName: String): Unit = &#123;</div><div class=\"line\">  createOrReplaceTempView(tableName)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Creates a local temporary view using the given name. The lifetime of this</div><div class=\"line\"> * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * Local temporary view is session-scoped. Its lifetime is the lifetime of the session that</div><div class=\"line\"> * created it, i.e. it will be automatically dropped when the session terminates. It&apos;s not</div><div class=\"line\"> * tied to any databases, i.e. we can&apos;t use `db1.view1` to reference a local temporary view.</div><div class=\"line\"> *</div><div class=\"line\"> * @throws AnalysisException if the view name is invalid or already exists</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@throws[AnalysisException]</div><div class=\"line\">def createTempView(viewName: String): Unit = withPlan &#123;</div><div class=\"line\">  createTempViewCommand(viewName, replace = false, global = false)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Creates a local temporary view using the given name. The lifetime of this</div><div class=\"line\"> * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def createOrReplaceTempView(viewName: String): Unit = withPlan &#123;</div><div class=\"line\">  createTempViewCommand(viewName, replace = true, global = false)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Creates a global temporary view using the given name. The lifetime of this</div><div class=\"line\"> * temporary view is tied to this Spark application.</div><div class=\"line\"> *</div><div class=\"line\"> * Global temporary view is cross-session. Its lifetime is the lifetime of the Spark application,</div><div class=\"line\"> * i.e. it will be automatically dropped when the application terminates. It&apos;s tied to a system</div><div class=\"line\"> * preserved database `global_temp`, and we must use the qualified name to refer a global temp</div><div class=\"line\"> * view, e.g. `SELECT * FROM global_temp.view1`.</div><div class=\"line\"> *</div><div class=\"line\"> * @throws AnalysisException if the view name is invalid or already exists</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@throws[AnalysisException]</div><div class=\"line\">def createGlobalTempView(viewName: String): Unit = withPlan &#123;</div><div class=\"line\">  createTempViewCommand(viewName, replace = false, global = true)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">private def createTempViewCommand(</div><div class=\"line\">    viewName: String,</div><div class=\"line\">    replace: Boolean,</div><div class=\"line\">    global: Boolean): CreateViewCommand = &#123;</div><div class=\"line\">  val viewType = if (global) GlobalTempView else LocalTempView</div><div class=\"line\"></div><div class=\"line\">  val tableIdentifier = try &#123;</div><div class=\"line\">    sparkSession.sessionState.sqlParser.parseTableIdentifier(viewName)</div><div class=\"line\">  &#125; catch &#123;</div><div class=\"line\">    case _: ParseException =&gt; throw new AnalysisException(s&quot;Invalid view name: $viewName&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\">  CreateViewCommand(</div><div class=\"line\">    name = tableIdentifier,</div><div class=\"line\">    userSpecifiedColumns = Nil,</div><div class=\"line\">    comment = None,</div><div class=\"line\">    properties = Map.empty,</div><div class=\"line\">    originalText = None,</div><div class=\"line\">    child = logicalPlan,</div><div class=\"line\">    allowExisting = false,</div><div class=\"line\">    replace = replace,</div><div class=\"line\">    viewType = viewType)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><pre><code>writewritewrite\n</code></pre><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Interface for saving the content of the non-streaming Dataset out into external storage.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def write: DataFrameWriter[T] = &#123;</div><div class=\"line\">  if (isStreaming) &#123;</div><div class=\"line\">    logicalPlan.failAnalysis(</div><div class=\"line\">      &quot;&apos;write&apos; can not be called on streaming Dataset/DataFrame&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\">  new DataFrameWriter[T](this)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * Interface for saving the content of the streaming Dataset out into external storage.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def writeStream: DataStreamWriter[T] = &#123;</div><div class=\"line\">  if (!isStreaming) &#123;</div><div class=\"line\">    logicalPlan.failAnalysis(</div><div class=\"line\">      &quot;&apos;writeStream&apos; can be called only on streaming Dataset/DataFrame&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\">  new DataStreamWriter[T](this)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"json\"><a href=\"#json\" class=\"headerlink\" title=\"json\"></a>json</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns the content of the Dataset as a Dataset of JSON strings.</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def toJSON: Dataset[String] = &#123;</div><div class=\"line\">  val rowSchema = this.schema</div><div class=\"line\">  val sessionLocalTimeZone = sparkSession.sessionState.conf.sessionLocalTimeZone</div><div class=\"line\">  val rdd: RDD[String] = queryExecution.toRdd.mapPartitions &#123; iter =&gt;</div><div class=\"line\">    val writer = new CharArrayWriter()</div><div class=\"line\">    // create the Generator without separator inserted between 2 records</div><div class=\"line\">    val gen = new JacksonGenerator(rowSchema, writer,</div><div class=\"line\">      new JSONOptions(Map.empty[String, String], sessionLocalTimeZone))</div><div class=\"line\"></div><div class=\"line\">    new Iterator[String] &#123;</div><div class=\"line\">      override def hasNext: Boolean = iter.hasNext</div><div class=\"line\">      override def next(): String = &#123;</div><div class=\"line\">        gen.write(iter.next())</div><div class=\"line\">        gen.flush()</div><div class=\"line\"></div><div class=\"line\">        val json = writer.toString</div><div class=\"line\">        if (hasNext) &#123;</div><div class=\"line\">          writer.reset()</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          gen.close()</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        json</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">  import sparkSession.implicits.newStringEncoder</div><div class=\"line\">  sparkSession.createDataset(rdd)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>  dataSet<br>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a best-effort snapshot of the files that compose this Dataset. This method simply</div><div class=\"line\"> * asks each constituent BaseRelation for its respective files and takes the union of all results.</div><div class=\"line\"> * Depending on the source relations, this may not find all input files. Duplicates are removed.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def inputFiles: Array[String] = &#123;</div><div class=\"line\">  val files: Seq[String] = queryExecution.optimizedPlan.collect &#123;</div><div class=\"line\">    case LogicalRelation(fsBasedRelation: FileRelation, _, _) =&gt;</div><div class=\"line\">      fsBasedRelation.inputFiles</div><div class=\"line\">    case fr: FileRelation =&gt;</div><div class=\"line\">      fr.inputFiles</div><div class=\"line\">  &#125;.flatten</div><div class=\"line\">  files.toSet.toArray</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","excerpt":"<p>sparksqldataframe sparkspark,.<br>:spark 2.0.1<br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>showString sparkshowshowString<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Compose the string representing rows for output</div><div class=\"line\"> *</div><div class=\"line\"> * @param _numRows Number of rows to show</div><div class=\"line\"> * @param truncate If set to more than 0, truncates strings to `truncate` characters and</div><div class=\"line\"> *                   all cells will be aligned right.</div><div class=\"line\"> */</div><div class=\"line\">private[sql] def showString(_numRows: Int, truncate: Int = 20): String</div></pre></td></tr></table></figure></p>\n<h2 id=\"dataSetdataFrame\"><a href=\"#dataSetdataFrame\" class=\"headerlink\" title=\"dataSetdataFrame\"></a>dataSetdataFrame</h2><p>   dataframdataset<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Converts this strongly typed collection of data to generic `DataFrame` with columns renamed.</div><div class=\"line\"> * This can be quite convenient in conversion from an RDD of tuples into a `DataFrame` with</div><div class=\"line\"> * meaningful names. For example:</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   val rdd: RDD[(Int, String)] = ...</div><div class=\"line\"> *   rdd.toDF()  // this implicit conversion creates a DataFrame with column name `_1` and `_2`</div><div class=\"line\"> *   rdd.toDF(&quot;id&quot;, &quot;name&quot;)  // this creates a DataFrame with column name &quot;id&quot; and &quot;name&quot;</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def toDF(colNames: String*): DataFrame = &#123;</div><div class=\"line\">  require(schema.size == colNames.size,</div><div class=\"line\">    &quot;The number of columns doesn&apos;t match.\\n&quot; +</div><div class=\"line\">      s&quot;Old column names ($&#123;schema.size&#125;): &quot; + schema.fields.map(_.name).mkString(&quot;, &quot;) + &quot;\\n&quot; +</div><div class=\"line\">      s&quot;New column names ($&#123;colNames.size&#125;): &quot; + colNames.mkString(&quot;, &quot;))</div><div class=\"line\"></div><div class=\"line\">  val newCols = logicalPlan.output.zip(colNames).map &#123; case (oldAttribute, newName) =&gt;</div><div class=\"line\">    Column(oldAttribute).as(newName)</div><div class=\"line\">  &#125;</div><div class=\"line\">  select(newCols : _*)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>dataset<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns the schema of this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def schema: StructType = queryExecution.analyzed.schema</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Prints the schema to the console in a nice tree format.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">// scalastyle:off println</div><div class=\"line\">def printSchema(): Unit = println(schema.treeString)</div><div class=\"line\">// scalastyle:on println</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Prints the plans (logical and physical) to the console for debugging purposes.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def explain(extended: Boolean): Unit = &#123;</div><div class=\"line\">  val explain = ExplainCommand(queryExecution.logical, extended = extended)</div><div class=\"line\">  sparkSession.sessionState.executePlan(explain).executedPlan.executeCollect().foreach &#123;</div><div class=\"line\">    // scalastyle:off println</div><div class=\"line\">    r =&gt; println(r.getString(0))</div><div class=\"line\">    // scalastyle:on println</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Prints the physical plan to the console for debugging purposes.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def explain(): Unit = explain(extended = false)</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns all column names and their data types as an array.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def dtypes: Array[(String, String)] = schema.fields.map &#123; field =&gt;</div><div class=\"line\">  (field.name, field.dataType.toString)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns all column names as an array.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def columns: Array[String] = schema.fields.map(_.name)</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns true if the `collect` and `take` methods can be run locally</div><div class=\"line\"> * (without any Spark executors).</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def isLocal: Boolean = logicalPlan.isInstanceOf[LocalRelation]</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns true if this Dataset contains one or more sources that continuously</div><div class=\"line\"> * return data as it arrives. A Dataset that reads data from a streaming source</div><div class=\"line\"> * must be executed as a `StreamingQuery` using the `start()` method in</div><div class=\"line\"> * `DataStreamWriter`. Methods that return a single answer, e.g. `count()` or</div><div class=\"line\"> * `collect()`, will throw an [[AnalysisException]] when there is a streaming</div><div class=\"line\"> * source present.</div><div class=\"line\"> *</div><div class=\"line\"> * @group streaming</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def isStreaming: Boolean = logicalPlan.isStreaming</div></pre></td></tr></table></figure></p>\n<p><strong></strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Eagerly checkpoint a Dataset and return the new Dataset. Checkpointing can be used to truncate</div><div class=\"line\"> * the logical plan of this Dataset, which is especially useful in iterative algorithms where the</div><div class=\"line\"> * plan may grow exponentially. It will be saved to files inside the checkpoint</div><div class=\"line\"> * directory set with `SparkContext#setCheckpointDir`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def checkpoint(): Dataset[T] = checkpoint(eager = true)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a checkpointed version of this Dataset. Checkpointing can be used to truncate the</div><div class=\"line\"> * logical plan of this Dataset, which is especially useful in iterative algorithms where the</div><div class=\"line\"> * plan may grow exponentially. It will be saved to files inside the checkpoint</div><div class=\"line\"> * directory set with `SparkContext#setCheckpointDir`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def checkpoint(eager: Boolean): Dataset[T] = &#123;</div><div class=\"line\">  val internalRdd = queryExecution.toRdd.map(_.copy())</div><div class=\"line\">  internalRdd.checkpoint()</div><div class=\"line\"></div><div class=\"line\">  if (eager) &#123;</div><div class=\"line\">    internalRdd.count()</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  val physicalPlan = queryExecution.executedPlan</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">  // Takes the first leaf partitioning whenever we see a `PartitioningCollection`. Otherwise the</div><div class=\"line\">  // size of `PartitioningCollection` may grow exponentially for queries involving deep inner</div><div class=\"line\">  // joins.</div><div class=\"line\">  def firstLeafPartitioning(partitioning: Partitioning): Partitioning = &#123;</div><div class=\"line\">    partitioning match &#123;</div><div class=\"line\">      case p: PartitioningCollection =&gt; firstLeafPartitioning(p.partitionings.head)</div><div class=\"line\">      case p =&gt; p</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  val outputPartitioning = firstLeafPartitioning(physicalPlan.outputPartitioning)</div><div class=\"line\"></div><div class=\"line\">  Dataset.ofRows(</div><div class=\"line\">    sparkSession,</div><div class=\"line\">    LogicalRDD(</div><div class=\"line\">      logicalPlan.output,</div><div class=\"line\">      internalRdd,</div><div class=\"line\">      outputPartitioning,</div><div class=\"line\">      physicalPlan.outputOrdering</div><div class=\"line\">    )(sparkSession)).as[T]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * Defines an event time watermark for this [[Dataset]]. A watermark tracks a point in time</div><div class=\"line\"> * before which we assume no more late data is going to arrive.</div><div class=\"line\"> *</div><div class=\"line\"> * Spark will use this watermark for several purposes:</div><div class=\"line\"> *  - To know when a given time window aggregation can be finalized and thus can be emitted when</div><div class=\"line\"> *    using output modes that do not allow updates.</div><div class=\"line\"> *  - To minimize the amount of state that we need to keep for on-going aggregations,</div><div class=\"line\"> *    `mapGroupsWithState` and `dropDuplicates` operators.</div><div class=\"line\"> *</div><div class=\"line\"> *  The current watermark is computed by looking at the `MAX(eventTime)` seen across</div><div class=\"line\"> *  all of the partitions in the query minus a user specified `delayThreshold`.  Due to the cost</div><div class=\"line\"> *  of coordinating this value across partitions, the actual watermark used is only guaranteed</div><div class=\"line\"> *  to be at least `delayThreshold` behind the actual event time.  In some cases we may still</div><div class=\"line\"> *  process records that arrive more than `delayThreshold` late.</div><div class=\"line\"> *</div><div class=\"line\"> * @param eventTime the name of the column that contains the event time of the row.</div><div class=\"line\"> * @param delayThreshold the minimum delay to wait to data to arrive late, relative to the latest</div><div class=\"line\"> *                       record that has been processed in the form of an interval</div><div class=\"line\"> *                       (e.g. &quot;1 minute&quot; or &quot;5 hours&quot;).</div><div class=\"line\"> *</div><div class=\"line\"> * @group streaming</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">// We only accept an existing column name, not a derived column here as a watermark that is</div><div class=\"line\">// defined on a derived column cannot referenced elsewhere in the plan.</div><div class=\"line\">def withWatermark(eventTime: String, delayThreshold: String): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  val parsedDelay =</div><div class=\"line\">    Option(CalendarInterval.fromString(&quot;interval &quot; + delayThreshold))</div><div class=\"line\">      .getOrElse(throw new AnalysisException(s&quot;Unable to parse time delay &apos;$delayThreshold&apos;&quot;))</div><div class=\"line\">  EventTimeWatermark(UnresolvedAttribute(eventTime), parsedDelay, logicalPlan)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Displays the Dataset in a tabular form. Strings more than 20 characters will be truncated,</div><div class=\"line\">   * and all cells will be aligned right. For example:</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   year  month AVG(&apos;Adj Close) MAX(&apos;Adj Close)</div><div class=\"line\">   *   1980  12    0.503218        0.595103</div><div class=\"line\">   *   1981  01    0.523289        0.570307</div><div class=\"line\">   *   1982  02    0.436504        0.475256</div><div class=\"line\">   *   1983  03    0.410516        0.442194</div><div class=\"line\">   *   1984  04    0.450090        0.483521</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param numRows Number of rows to show</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">datafram20</div><div class=\"line\">  def show(numRows: Int): Unit = show(numRows, truncate = true)</div><div class=\"line\"></div><div class=\"line\">datafram2020</div><div class=\"line\">  </div><div class=\"line\">  def show(): Unit = show(20)</div><div class=\"line\"></div><div class=\"line\">datafram20truncate</div><div class=\"line\">  def show(truncate: Boolean): Unit = show(20, truncate)</div><div class=\"line\"></div><div class=\"line\">dataframnumRowstruncate</div><div class=\"line\">  def show(numRows: Int, truncate: Boolean): Unit = if (truncate) &#123;</div><div class=\"line\">  def show(numRows: Int, truncate: Int): Unit = println(showString(numRows, truncate))</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div><div class=\"line\">175</div><div class=\"line\">176</div><div class=\"line\">177</div><div class=\"line\">178</div><div class=\"line\">179</div><div class=\"line\">180</div><div class=\"line\">181</div><div class=\"line\">182</div><div class=\"line\">183</div><div class=\"line\">184</div><div class=\"line\">185</div><div class=\"line\">186</div><div class=\"line\">187</div><div class=\"line\">188</div><div class=\"line\">189</div><div class=\"line\">190</div><div class=\"line\">191</div><div class=\"line\">192</div><div class=\"line\">193</div><div class=\"line\">194</div><div class=\"line\">195</div><div class=\"line\">196</div><div class=\"line\">197</div><div class=\"line\">198</div><div class=\"line\">199</div><div class=\"line\">200</div><div class=\"line\">201</div><div class=\"line\">202</div><div class=\"line\">203</div><div class=\"line\">204</div><div class=\"line\">205</div><div class=\"line\">206</div><div class=\"line\">207</div><div class=\"line\">208</div><div class=\"line\">209</div><div class=\"line\">210</div><div class=\"line\">211</div><div class=\"line\">212</div><div class=\"line\">213</div><div class=\"line\">214</div><div class=\"line\">215</div><div class=\"line\">216</div><div class=\"line\">217</div><div class=\"line\">218</div><div class=\"line\">219</div><div class=\"line\">220</div><div class=\"line\">221</div><div class=\"line\">222</div><div class=\"line\">223</div><div class=\"line\">224</div><div class=\"line\">225</div><div class=\"line\">226</div><div class=\"line\">227</div><div class=\"line\">228</div><div class=\"line\">229</div><div class=\"line\">230</div><div class=\"line\">231</div><div class=\"line\">232</div><div class=\"line\">233</div><div class=\"line\">234</div><div class=\"line\">235</div><div class=\"line\">236</div><div class=\"line\">237</div><div class=\"line\">238</div><div class=\"line\">239</div><div class=\"line\">240</div><div class=\"line\">241</div><div class=\"line\">242</div><div class=\"line\">243</div><div class=\"line\">244</div><div class=\"line\">245</div><div class=\"line\">246</div><div class=\"line\">247</div><div class=\"line\">248</div><div class=\"line\">249</div><div class=\"line\">250</div><div class=\"line\">251</div><div class=\"line\">252</div><div class=\"line\">253</div><div class=\"line\">254</div><div class=\"line\">255</div><div class=\"line\">256</div><div class=\"line\">257</div><div class=\"line\">258</div><div class=\"line\">259</div><div class=\"line\">260</div><div class=\"line\">261</div><div class=\"line\">262</div><div class=\"line\">263</div><div class=\"line\">264</div><div class=\"line\">265</div><div class=\"line\">266</div><div class=\"line\">267</div><div class=\"line\">268</div><div class=\"line\">269</div><div class=\"line\">270</div><div class=\"line\">271</div><div class=\"line\">272</div><div class=\"line\">273</div><div class=\"line\">274</div><div class=\"line\">275</div><div class=\"line\">276</div><div class=\"line\">277</div><div class=\"line\">278</div><div class=\"line\">279</div><div class=\"line\">280</div><div class=\"line\">281</div><div class=\"line\">282</div><div class=\"line\">283</div><div class=\"line\">284</div><div class=\"line\">285</div><div class=\"line\">286</div><div class=\"line\">287</div><div class=\"line\">288</div><div class=\"line\">289</div><div class=\"line\">290</div><div class=\"line\">291</div><div class=\"line\">292</div><div class=\"line\">293</div><div class=\"line\">294</div><div class=\"line\">295</div><div class=\"line\">296</div><div class=\"line\">297</div><div class=\"line\">298</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">dataset</div><div class=\"line\">  def na: DataFrameNaFunctions = new DataFrameNaFunctions(toDF())</div><div class=\"line\"></div><div class=\"line\">dataset</div><div class=\"line\">  def stat: DataFrameStatFunctions = new DataFrameStatFunctions(toDF())</div><div class=\"line\">dataframe</div><div class=\"line\">  def join(right: Dataset[_]): DataFrame = withPlan &#123;</div><div class=\"line\">    Join(logicalPlan, right.logicalPlan, joinType = Inner, None)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Inner equi-join with another `DataFrame` using the given column.</div><div class=\"line\">   *</div><div class=\"line\">   * Different from other join functions, the join column will only appear once in the output,</div><div class=\"line\">   * i.e. similar to SQL&apos;s `JOIN USING` syntax.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // Joining df1 and df2 using the column &quot;user_id&quot;</div><div class=\"line\">   *   df1.join(df2, &quot;user_id&quot;)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   * @param usingColumn Name of the column to join on. This column must exist on both sides.</div><div class=\"line\">   *</div><div class=\"line\">   * @note If you perform a self-join using this function without aliasing the input</div><div class=\"line\">   * `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class=\"line\">   * there is no way to disambiguate which side of the join you would like to reference.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], usingColumn: String): DataFrame = &#123;</div><div class=\"line\">    join(right, Seq(usingColumn))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Inner equi-join with another `DataFrame` using the given columns.</div><div class=\"line\">   *</div><div class=\"line\">   * Different from other join functions, the join columns will only appear once in the output,</div><div class=\"line\">   * i.e. similar to SQL&apos;s `JOIN USING` syntax.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // Joining df1 and df2 using the columns &quot;user_id&quot; and &quot;user_name&quot;</div><div class=\"line\">   *   df1.join(df2, Seq(&quot;user_id&quot;, &quot;user_name&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.</div><div class=\"line\">   *</div><div class=\"line\">   * @note If you perform a self-join using this function without aliasing the input</div><div class=\"line\">   * `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class=\"line\">   * there is no way to disambiguate which side of the join you would like to reference.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">dataframekey</div><div class=\"line\">  def join(right: Dataset[_], usingColumns: Seq[String]): DataFrame = &#123;</div><div class=\"line\">    join(right, usingColumns, &quot;inner&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Equi-join with another `DataFrame` using the given columns. A cross join with a predicate</div><div class=\"line\">   * is specified as an inner join. If you would explicitly like to perform a cross join use the</div><div class=\"line\">   * `crossJoin` method.</div><div class=\"line\">   *</div><div class=\"line\">   * Different from other join functions, the join columns will only appear once in the output,</div><div class=\"line\">   * i.e. similar to SQL&apos;s `JOIN USING` syntax.</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   * @param usingColumns Names of the columns to join on. This columns must exist on both sides.</div><div class=\"line\">   * @param joinType Type of join to perform. Default `inner`. Must be one of:</div><div class=\"line\">   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,</div><div class=\"line\">   *                 `right`, `right_outer`, `left_semi`, `left_anti`.</div><div class=\"line\">   *</div><div class=\"line\">   * @note If you perform a self-join using this function without aliasing the input</div><div class=\"line\">   * `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class=\"line\">   * there is no way to disambiguate which side of the join you would like to reference.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], usingColumns: Seq[String], joinType: String): DataFrame = &#123;</div><div class=\"line\">    // Analyze the self join. The assumption is that the analyzer will disambiguate left vs right</div><div class=\"line\">    // by creating a new instance for one of the branch.</div><div class=\"line\">    val joined = sparkSession.sessionState.executePlan(</div><div class=\"line\">      Join(logicalPlan, right.logicalPlan, joinType = JoinType(joinType), None))</div><div class=\"line\">      .analyzed.asInstanceOf[Join]</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      Join(</div><div class=\"line\">        joined.left,</div><div class=\"line\">        joined.right,</div><div class=\"line\">        UsingJoin(JoinType(joinType), usingColumns),</div><div class=\"line\">        None)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Inner join with another `DataFrame`, using the given join expression.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following two are equivalent:</div><div class=\"line\">   *   df1.join(df2, $&quot;df1Key&quot; === $&quot;df2Key&quot;)</div><div class=\"line\">   *   df1.join(df2).where($&quot;df1Key&quot; === $&quot;df2Key&quot;)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], joinExprs: Column): DataFrame = join(right, joinExprs, &quot;inner&quot;)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Join with another `DataFrame`, using the given join expression. The following performs</div><div class=\"line\">   * a full outer join between `df1` and `df2`.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // Scala:</div><div class=\"line\">   *   import org.apache.spark.sql.functions._</div><div class=\"line\">   *   df1.join(df2, $&quot;df1Key&quot; === $&quot;df2Key&quot;, &quot;outer&quot;)</div><div class=\"line\">   *</div><div class=\"line\">   *   // Java:</div><div class=\"line\">   *   import static org.apache.spark.sql.functions.*;</div><div class=\"line\">   *   df1.join(df2, col(&quot;df1Key&quot;).equalTo(col(&quot;df2Key&quot;)), &quot;outer&quot;);</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join.</div><div class=\"line\">   * @param joinExprs Join expression.</div><div class=\"line\">   * @param joinType Type of join to perform. Default `inner`. Must be one of:</div><div class=\"line\">   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,</div><div class=\"line\">   *                 `right`, `right_outer`, `left_semi`, `left_anti`.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame = &#123;</div><div class=\"line\">    // Note that in this function, we introduce a hack in the case of self-join to automatically</div><div class=\"line\">    // resolve ambiguous join conditions into ones that might make sense [SPARK-6231].</div><div class=\"line\">    // Consider this case: df.join(df, df(&quot;key&quot;) === df(&quot;key&quot;))</div><div class=\"line\">    // Since df(&quot;key&quot;) === df(&quot;key&quot;) is a trivially true condition, this actually becomes a</div><div class=\"line\">    // cartesian join. However, most likely users expect to perform a self join using &quot;key&quot;.</div><div class=\"line\">    // With that assumption, this hack turns the trivially true condition into equality on join</div><div class=\"line\">    // keys that are resolved to both sides.</div><div class=\"line\"></div><div class=\"line\">    // Trigger analysis so in the case of self-join, the analyzer will clone the plan.</div><div class=\"line\">    // After the cloning, left and right side will have distinct expression ids.</div><div class=\"line\">    val plan = withPlan(</div><div class=\"line\">      Join(logicalPlan, right.logicalPlan, JoinType(joinType), Some(joinExprs.expr)))</div><div class=\"line\">      .queryExecution.analyzed.asInstanceOf[Join]</div><div class=\"line\"></div><div class=\"line\">    // If auto self join alias is disabled, return the plan.</div><div class=\"line\">    if (!sparkSession.sessionState.conf.dataFrameSelfJoinAutoResolveAmbiguity) &#123;</div><div class=\"line\">      return withPlan(plan)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    // If left/right have no output set intersection, return the plan.</div><div class=\"line\">    val lanalyzed = withPlan(this.logicalPlan).queryExecution.analyzed</div><div class=\"line\">    val ranalyzed = withPlan(right.logicalPlan).queryExecution.analyzed</div><div class=\"line\">    if (lanalyzed.outputSet.intersect(ranalyzed.outputSet).isEmpty) &#123;</div><div class=\"line\">      return withPlan(plan)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    // Otherwise, find the trivially true predicates and automatically resolves them to both sides.</div><div class=\"line\">    // By the time we get here, since we have already run analysis, all attributes should&apos;ve been</div><div class=\"line\">    // resolved and become AttributeReference.</div><div class=\"line\">    val cond = plan.condition.map &#123; _.transform &#123;</div><div class=\"line\">      case catalyst.expressions.EqualTo(a: AttributeReference, b: AttributeReference)</div><div class=\"line\">          if a.sameRef(b) =&gt;</div><div class=\"line\">        catalyst.expressions.EqualTo(</div><div class=\"line\">          withPlan(plan.left).resolve(a.name),</div><div class=\"line\">          withPlan(plan.right).resolve(b.name))</div><div class=\"line\">    &#125;&#125;</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      plan.copy(condition = cond)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Explicit cartesian join with another `DataFrame`.</div><div class=\"line\">   *</div><div class=\"line\">   * @param right Right side of the join operation.</div><div class=\"line\">   *</div><div class=\"line\">   * @note Cartesian joins are very expensive without an extra filter that can be pushed down.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.1.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  def crossJoin(right: Dataset[_]): DataFrame = withPlan &#123;</div><div class=\"line\">    Join(logicalPlan, right.logicalPlan, joinType = Cross, None)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Joins this Dataset returning a `Tuple2` for each pair where `condition` evaluates to</div><div class=\"line\">   * true.</div><div class=\"line\">   *</div><div class=\"line\">   * This is similar to the relation `join` function with one important difference in the</div><div class=\"line\">   * result schema. Since `joinWith` preserves objects present on either side of the join, the</div><div class=\"line\">   * result schema is similarly nested into a tuple under the column names `_1` and `_2`.</div><div class=\"line\">   *</div><div class=\"line\">   * This type of join can be useful both for preserving type-safety with the original object</div><div class=\"line\">   * types as well as working with relational data where either side of the join has column</div><div class=\"line\">   * names in common.</div><div class=\"line\">   *</div><div class=\"line\">   * @param other Right side of the join.</div><div class=\"line\">   * @param condition Join expression.</div><div class=\"line\">   * @param joinType Type of join to perform. Default `inner`. Must be one of:</div><div class=\"line\">   *                 `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`,</div><div class=\"line\">   *                 `right`, `right_outer`, `left_semi`, `left_anti`.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def joinWith[U](other: Dataset[U], condition: Column, joinType: String): Dataset[(T, U)] = &#123;</div><div class=\"line\">    // Creates a Join node and resolve it first, to get join condition resolved, self-join resolved,</div><div class=\"line\">    // etc.</div><div class=\"line\">    val joined = sparkSession.sessionState.executePlan(</div><div class=\"line\">      Join(</div><div class=\"line\">        this.logicalPlan,</div><div class=\"line\">        other.logicalPlan,</div><div class=\"line\">        JoinType(joinType),</div><div class=\"line\">        Some(condition.expr))).analyzed.asInstanceOf[Join]</div><div class=\"line\"></div><div class=\"line\">    // For both join side, combine all outputs into a single column and alias it with &quot;_1&quot; or &quot;_2&quot;,</div><div class=\"line\">    // to match the schema for the encoder of the join result.</div><div class=\"line\">    // Note that we do this before joining them, to enable the join operator to return null for one</div><div class=\"line\">    // side, in cases like outer-join.</div><div class=\"line\">    val left = &#123;</div><div class=\"line\">      val combined = if (this.exprEnc.flat) &#123;</div><div class=\"line\">        assert(joined.left.output.length == 1)</div><div class=\"line\">        Alias(joined.left.output.head, &quot;_1&quot;)()</div><div class=\"line\">      &#125; else &#123;</div><div class=\"line\">        Alias(CreateStruct(joined.left.output), &quot;_1&quot;)()</div><div class=\"line\">      &#125;</div><div class=\"line\">      Project(combined :: Nil, joined.left)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    val right = &#123;</div><div class=\"line\">      val combined = if (other.exprEnc.flat) &#123;</div><div class=\"line\">        assert(joined.right.output.length == 1)</div><div class=\"line\">        Alias(joined.right.output.head, &quot;_2&quot;)()</div><div class=\"line\">      &#125; else &#123;</div><div class=\"line\">        Alias(CreateStruct(joined.right.output), &quot;_2&quot;)()</div><div class=\"line\">      &#125;</div><div class=\"line\">      Project(combined :: Nil, joined.right)</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    // Rewrites the join condition to make the attribute point to correct column/field, after we</div><div class=\"line\">    // combine the outputs of each join side.</div><div class=\"line\">    val conditionExpr = joined.condition.get transformUp &#123;</div><div class=\"line\">      case a: Attribute if joined.left.outputSet.contains(a) =&gt;</div><div class=\"line\">        if (this.exprEnc.flat) &#123;</div><div class=\"line\">          left.output.head</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          val index = joined.left.output.indexWhere(_.exprId == a.exprId)</div><div class=\"line\">          GetStructField(left.output.head, index)</div><div class=\"line\">        &#125;</div><div class=\"line\">      case a: Attribute if joined.right.outputSet.contains(a) =&gt;</div><div class=\"line\">        if (other.exprEnc.flat) &#123;</div><div class=\"line\">          right.output.head</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          val index = joined.right.output.indexWhere(_.exprId == a.exprId)</div><div class=\"line\">          GetStructField(right.output.head, index)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    implicit val tuple2Encoder: Encoder[(T, U)] =</div><div class=\"line\">      ExpressionEncoder.tuple(this.exprEnc, other.exprEnc)</div><div class=\"line\"></div><div class=\"line\">    withTypedPlan(Join(left, right, joined.joinType, Some(conditionExpr)))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Using inner equi-join to join this Dataset returning a `Tuple2` for each pair</div><div class=\"line\">   * where `condition` evaluates to true.</div><div class=\"line\">   *</div><div class=\"line\">   * @param other Right side of the join.</div><div class=\"line\">   * @param condition Join expression.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def joinWith[U](other: Dataset[U], condition: Column): Dataset[(T, U)] = &#123;</div><div class=\"line\">    joinWith(other, condition, &quot;inner&quot;)</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with each partition sorted by the given expressions.</div><div class=\"line\">   *</div><div class=\"line\">   * This is the same operation as &quot;SORT BY&quot; in SQL (Hive QL).</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sortWithinPartitions(sortCol: String, sortCols: String*): Dataset[T] = &#123;</div><div class=\"line\">    sortWithinPartitions((sortCol +: sortCols).map(Column(_)) : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with each partition sorted by the given expressions.</div><div class=\"line\">   *</div><div class=\"line\">   * This is the same operation as &quot;SORT BY&quot; in SQL (Hive QL).</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sortWithinPartitions(sortExprs: Column*): Dataset[T] = &#123;</div><div class=\"line\">    sortInternal(global = false, sortExprs)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the specified column, all in ascending order.</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following 3 are equivalent</div><div class=\"line\">   *   ds.sort(&quot;sortcol&quot;)</div><div class=\"line\">   *   ds.sort($&quot;sortcol&quot;)</div><div class=\"line\">   *   ds.sort($&quot;sortcol&quot;.asc)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sort(sortCol: String, sortCols: String*): Dataset[T] = &#123;</div><div class=\"line\">    sort((sortCol +: sortCols).map(apply) : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the given expressions. For example:</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.sort($&quot;col1&quot;, $&quot;col2&quot;.desc)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def sort(sortExprs: Column*): Dataset[T] = &#123;</div><div class=\"line\">    sortInternal(global = true, sortExprs)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the given expressions.</div><div class=\"line\">   * This is an alias of the `sort` function.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def orderBy(sortCol: String, sortCols: String*): Dataset[T] = sort(sortCol, sortCols : _*)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset sorted by the given expressions.</div><div class=\"line\">   * This is an alias of the `sort` function.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def orderBy(sortExprs: Column*): Dataset[T] = sort(sortExprs : _*)</div></pre></td></tr></table></figure>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Selects column based on the column name and return it as a [[Column]].</div><div class=\"line\"> *</div><div class=\"line\"> * @note The column name can also reference to a nested column like `a.b`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def apply(colName: String): Column = col(colName)</div><div class=\"line\">/**</div><div class=\"line\"> * Selects column based on the column name and return it as a [[Column]].</div><div class=\"line\"> *</div><div class=\"line\"> * @note The column name can also reference to a nested column like `a.b`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def col(colName: String): Column = colName match &#123;</div><div class=\"line\">  case &quot;*&quot; =&gt;</div><div class=\"line\">    Column(ResolvedStar(queryExecution.analyzed.output))</div><div class=\"line\">  case _ =&gt;</div><div class=\"line\">    val expr = resolve(colName)</div><div class=\"line\">    Column(expr)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>datasetdataset<br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset with an alias set.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def as(alias: String): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  SubqueryAlias(alias, logicalPlan, None)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Returns a new Dataset with an alias set.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def as(alias: Symbol): Dataset[T] = as(alias.name)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset with an alias set. Same as `as`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def alias(alias: String): Dataset[T] = as(alias)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Returns a new Dataset with an alias set. Same as `as`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def alias(alias: Symbol): Dataset[T] = as(alias)</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Selects a set of column based expressions.</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.select($&quot;colA&quot;, $&quot;colB&quot; + 1)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def select(cols: Column*): DataFrame = withPlan &#123;</div><div class=\"line\">    Project(cols.map(_.named), logicalPlan)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Selects a set of columns. This is a variant of `select` that can only select</div><div class=\"line\">   * existing columns using column names (i.e. cannot construct expressions).</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following two are equivalent:</div><div class=\"line\">   *   ds.select(&quot;colA&quot;, &quot;colB&quot;)</div><div class=\"line\">   *   ds.select($&quot;colA&quot;, $&quot;colB&quot;)</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def select(col: String, cols: String*): DataFrame = select((col +: cols).map(Column(_)) : _*)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Selects a set of SQL expressions. This is a variant of `select` that accepts</div><div class=\"line\">   * SQL expressions.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   // The following are equivalent:</div><div class=\"line\">   *   ds.selectExpr(&quot;colA&quot;, &quot;colB as newName&quot;, &quot;abs(colC)&quot;)</div><div class=\"line\">   *   ds.select(expr(&quot;colA&quot;), expr(&quot;colB as newName&quot;), expr(&quot;abs(colC)&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def selectExpr(exprs: String*): DataFrame = &#123;</div><div class=\"line\">    select(exprs.map &#123; expr =&gt;</div><div class=\"line\">      Column(sparkSession.sessionState.sqlParser.parseExpression(expr))</div><div class=\"line\">    &#125;: _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expression for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   val ds = Seq(1, 2, 3).toDS()</div><div class=\"line\">   *   val newDS = ds.select(expr(&quot;value + 1&quot;).as[Int])</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1](c1: TypedColumn[T, U1]): Dataset[U1] = &#123;</div><div class=\"line\">    implicit val encoder = c1.encoder</div><div class=\"line\">    val project = Project(c1.withInputType(exprEnc, logicalPlan.output).named :: Nil,</div><div class=\"line\">      logicalPlan)</div><div class=\"line\"></div><div class=\"line\">    if (encoder.flat) &#123;</div><div class=\"line\">      new Dataset[U1](sparkSession, project, encoder)</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      // Flattens inner fields of U1</div><div class=\"line\">      new Dataset[Tuple1[U1]](sparkSession, project, ExpressionEncoder.tuple(encoder)).map(_._1)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Internal helper function for building typed selects that return tuples. For simplicity and</div><div class=\"line\">   * code reuse, we do this without the help of the type system and then use helper functions</div><div class=\"line\">   * that cast appropriately for the user facing interface.</div><div class=\"line\">   */</div><div class=\"line\">  ???</div><div class=\"line\">  protected def selectUntyped(columns: TypedColumn[_, _]*): Dataset[_] = &#123;</div><div class=\"line\">    val encoders = columns.map(_.encoder)</div><div class=\"line\">    val namedColumns =</div><div class=\"line\">      columns.map(_.withInputType(exprEnc, logicalPlan.output).named)</div><div class=\"line\">    val execution = new QueryExecution(sparkSession, Project(namedColumns, logicalPlan))</div><div class=\"line\">    new Dataset(sparkSession, execution, ExpressionEncoder.tuple(encoders))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2](c1: TypedColumn[T, U1], c2: TypedColumn[T, U2]): Dataset[(U1, U2)] =</div><div class=\"line\">    selectUntyped(c1, c2).asInstanceOf[Dataset[(U1, U2)]]</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2, U3](</div><div class=\"line\">      c1: TypedColumn[T, U1],</div><div class=\"line\">      c2: TypedColumn[T, U2],</div><div class=\"line\">      c3: TypedColumn[T, U3]): Dataset[(U1, U2, U3)] =</div><div class=\"line\">    selectUntyped(c1, c2, c3).asInstanceOf[Dataset[(U1, U2, U3)]]</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2, U3, U4](</div><div class=\"line\">      c1: TypedColumn[T, U1],</div><div class=\"line\">      c2: TypedColumn[T, U2],</div><div class=\"line\">      c3: TypedColumn[T, U3],</div><div class=\"line\">      c4: TypedColumn[T, U4]): Dataset[(U1, U2, U3, U4)] =</div><div class=\"line\">    selectUntyped(c1, c2, c3, c4).asInstanceOf[Dataset[(U1, U2, U3, U4)]]</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * :: Experimental ::</div><div class=\"line\">   * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  @Experimental</div><div class=\"line\">  @InterfaceStability.Evolving</div><div class=\"line\">  def select[U1, U2, U3, U4, U5](</div><div class=\"line\">      c1: TypedColumn[T, U1],</div><div class=\"line\">      c2: TypedColumn[T, U2],</div><div class=\"line\">      c3: TypedColumn[T, U3],</div><div class=\"line\">      c4: TypedColumn[T, U4],</div><div class=\"line\">      c5: TypedColumn[T, U5]): Dataset[(U1, U2, U3, U4, U5)] =</div><div class=\"line\">    selectUntyped(c1, c2, c3, c4, c5).asInstanceOf[Dataset[(U1, U2, U3, U4, U5)]]</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>sqlwhere<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given condition.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // The following are equivalent:</div><div class=\"line\"> *   peopleDs.filter($&quot;age&quot; &gt; 15)</div><div class=\"line\"> *   peopleDs.where($&quot;age&quot; &gt; 15)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def filter(condition: Column): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Filter(condition.expr, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given SQL expression.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   peopleDs.filter(&quot;age &gt; 15&quot;)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def filter(conditionExpr: String): Dataset[T] = &#123;</div><div class=\"line\">  filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given condition. This is an alias for `filter`.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // The following are equivalent:</div><div class=\"line\"> *   peopleDs.filter($&quot;age&quot; &gt; 15)</div><div class=\"line\"> *   peopleDs.where($&quot;age&quot; &gt; 15)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def where(condition: Column): Dataset[T] = filter(condition)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Filters rows using the given SQL expression.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   peopleDs.where(&quot;age &gt; 15&quot;)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def where(conditionExpr: String): Dataset[T] = &#123;</div><div class=\"line\">  filter(Column(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Groups the Dataset using the specified columns, so we can run aggregation on them. See</div><div class=\"line\"> * [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns grouped by department.</div><div class=\"line\"> *   ds.groupBy($&quot;department&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, grouped by department and gender.</div><div class=\"line\"> *   ds.groupBy($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def groupBy(cols: Column*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.GroupByType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional rollup for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns rolluped by department and group.</div><div class=\"line\"> *   ds.rollup($&quot;department&quot;, $&quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, rolluped by department and gender.</div><div class=\"line\"> *   ds.rollup($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def rollup(cols: Column*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.RollupType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional cube for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns cubed by department and group.</div><div class=\"line\"> *   ds.cube($&quot;department&quot;, $&quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, cubed by department and gender.</div><div class=\"line\"> *   ds.cube($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def cube(cols: Column*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  RelationalGroupedDataset(toDF(), cols.map(_.expr), RelationalGroupedDataset.CubeType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Groups the Dataset using the specified columns, so that we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * This is a variant of groupBy that can only group by existing columns using column names</div><div class=\"line\"> * (i.e. cannot construct expressions).</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns grouped by department.</div><div class=\"line\"> *   ds.groupBy(&quot;department&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, grouped by department and gender.</div><div class=\"line\"> *   ds.groupBy($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def groupBy(col1: String, cols: String*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  RelationalGroupedDataset(</div><div class=\"line\">    toDF(), colNames.map(colName =&gt; resolve(colName)), RelationalGroupedDataset.GroupByType)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"reduce\"><a href=\"#reduce\" class=\"headerlink\" title=\"reduce\"></a>reduce</h2>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Reduces the elements of this Dataset using the specified binary function. The given `func`</div><div class=\"line\"> * must be commutative and associative or the result may be non-deterministic.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def reduce(func: (T, T) =&gt; T): T = rdd.reduce(func)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Reduces the elements of this Dataset using the specified binary function. The given `func`</div><div class=\"line\"> * must be commutative and associative or the result may be non-deterministic.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def reduce(func: ReduceFunction[T]): T = reduce(func.call(_, _))</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">                                  </div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def groupByKey[K: Encoder](func: T =&gt; K): KeyValueGroupedDataset[K, T] = &#123;</div><div class=\"line\">  val inputPlan = logicalPlan</div><div class=\"line\">  val withGroupingKey = AppendColumns(func, inputPlan)</div><div class=\"line\">  val executed = sparkSession.sessionState.executePlan(withGroupingKey)</div><div class=\"line\"></div><div class=\"line\">  new KeyValueGroupedDataset(</div><div class=\"line\">    encoderFor[K],</div><div class=\"line\">    encoderFor[T],</div><div class=\"line\">    executed,</div><div class=\"line\">    inputPlan.output,</div><div class=\"line\">    withGroupingKey.newColumns)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def groupByKey[K](func: MapFunction[T, K], encoder: Encoder[K]): KeyValueGroupedDataset[K, T] =</div><div class=\"line\">  groupByKey(func.call(_))(encoder)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional rollup for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * This is a variant of rollup that can only group by existing columns using column names</div><div class=\"line\"> * (i.e. cannot construct expressions).</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns rolluped by department and group.</div><div class=\"line\"> *   ds.rollup(&quot;department&quot;, &quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, rolluped by department and gender.</div><div class=\"line\"> *   ds.rollup($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def rollup(col1: String, cols: String*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  RelationalGroupedDataset(</div><div class=\"line\">    toDF(), colNames.map(colName =&gt; resolve(colName)), RelationalGroupedDataset.RollupType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Create a multi-dimensional cube for the current Dataset using the specified columns,</div><div class=\"line\"> * so we can run aggregation on them.</div><div class=\"line\"> * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class=\"line\"> *</div><div class=\"line\"> * This is a variant of cube that can only group by existing columns using column names</div><div class=\"line\"> * (i.e. cannot construct expressions).</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // Compute the average for all numeric columns cubed by department and group.</div><div class=\"line\"> *   ds.cube(&quot;department&quot;, &quot;group&quot;).avg()</div><div class=\"line\"> *</div><div class=\"line\"> *   // Compute the max age and average salary, cubed by department and gender.</div><div class=\"line\"> *   ds.cube($&quot;department&quot;, $&quot;gender&quot;).agg(Map(</div><div class=\"line\"> *     &quot;salary&quot; -&gt; &quot;avg&quot;,</div><div class=\"line\"> *     &quot;age&quot; -&gt; &quot;max&quot;</div><div class=\"line\"> *   ))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def cube(col1: String, cols: String*): RelationalGroupedDataset = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  RelationalGroupedDataset(</div><div class=\"line\">    toDF(), colNames.map(colName =&gt; resolve(colName)), RelationalGroupedDataset.CubeType)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;)</div><div class=\"line\"> *   ds.groupBy().agg(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def agg(aggExpr: (String, String), aggExprs: (String, String)*): DataFrame = &#123;</div><div class=\"line\">  groupBy().agg(aggExpr, aggExprs : _*)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> *   ds.groupBy().agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def agg(exprs: Map[String, String]): DataFrame = groupBy().agg(exprs)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Java-specific) Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> *   ds.groupBy().agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def agg(exprs: java.util.Map[String, String]): DataFrame = groupBy().agg(exprs)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Aggregates on the entire Dataset without groups.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class=\"line\"> *   ds.agg(max($&quot;age&quot;), avg($&quot;salary&quot;))</div><div class=\"line\"> *   ds.groupBy().agg(max($&quot;age&quot;), avg($&quot;salary&quot;))</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group untypedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def agg(expr: Column, exprs: Column*): DataFrame = groupBy().agg(expr, exprs : _*)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset by taking the first `n` rows. The difference between this function</div><div class=\"line\"> * and `head` is that `head` is an action and returns an array (by triggering query execution)</div><div class=\"line\"> * while `limit` returns a new Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def limit(n: Int): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Limit(Literal(n), logicalPlan)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div><div class=\"line\"> * This is equivalent to `UNION ALL` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * To do a SQL-style set union (that does deduplication of elements), use this function followed</div><div class=\"line\"> * by a [[distinct]].</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@deprecated(&quot;use union()&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">def unionAll(other: Dataset[T]): Dataset[T] = union(other)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div><div class=\"line\"> * This is equivalent to `UNION ALL` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * To do a SQL-style set union (that does deduplication of elements), use this function followed</div><div class=\"line\"> * by a [[distinct]].</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def union(other: Dataset[T]): Dataset[T] = withSetOperator &#123;</div><div class=\"line\">  // This breaks caching, but it&apos;s usually ok because it addresses a very specific use case:</div><div class=\"line\">  // using union to union many files or partitions.</div><div class=\"line\">  CombineUnions(Union(logicalPlan, other.logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing rows only in both this Dataset and another Dataset.</div><div class=\"line\"> * This is equivalent to `INTERSECT` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * @note Equality checking is performed directly on the encoded representation of the data</div><div class=\"line\"> * and thus is not affected by a custom `equals` function defined on `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def intersect(other: Dataset[T]): Dataset[T] = withSetOperator &#123;</div><div class=\"line\">  Intersect(logicalPlan, other.logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset containing rows in this Dataset but not in another Dataset.</div><div class=\"line\"> * This is equivalent to `EXCEPT` in SQL.</div><div class=\"line\"> *</div><div class=\"line\"> * @note Equality checking is performed directly on the encoded representation of the data</div><div class=\"line\"> * and thus is not affected by a custom `equals` function defined on `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def except(other: Dataset[T]): Dataset[T] = withSetOperator &#123;</div><div class=\"line\">  Except(logicalPlan, other.logicalPlan)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div><div class=\"line\">175</div><div class=\"line\">176</div><div class=\"line\">177</div><div class=\"line\">178</div><div class=\"line\">179</div><div class=\"line\">180</div><div class=\"line\">181</div><div class=\"line\">182</div><div class=\"line\">183</div><div class=\"line\">184</div><div class=\"line\">185</div><div class=\"line\">186</div><div class=\"line\">187</div><div class=\"line\">188</div><div class=\"line\">189</div><div class=\"line\">190</div><div class=\"line\">191</div><div class=\"line\">192</div><div class=\"line\">193</div><div class=\"line\">194</div><div class=\"line\">195</div><div class=\"line\">196</div><div class=\"line\">197</div><div class=\"line\">198</div><div class=\"line\">199</div><div class=\"line\">200</div><div class=\"line\">201</div><div class=\"line\">202</div><div class=\"line\">203</div><div class=\"line\">204</div><div class=\"line\">205</div><div class=\"line\">206</div><div class=\"line\">207</div><div class=\"line\">208</div><div class=\"line\">209</div><div class=\"line\">210</div><div class=\"line\">211</div><div class=\"line\">212</div><div class=\"line\">213</div><div class=\"line\">214</div><div class=\"line\">215</div><div class=\"line\">216</div><div class=\"line\">217</div><div class=\"line\">218</div><div class=\"line\">219</div><div class=\"line\">220</div><div class=\"line\">221</div><div class=\"line\">222</div><div class=\"line\">223</div><div class=\"line\">224</div><div class=\"line\">225</div><div class=\"line\">226</div><div class=\"line\">227</div><div class=\"line\">228</div><div class=\"line\">229</div><div class=\"line\">230</div><div class=\"line\">231</div><div class=\"line\">232</div><div class=\"line\">233</div><div class=\"line\">234</div><div class=\"line\">235</div><div class=\"line\">236</div><div class=\"line\">237</div><div class=\"line\">238</div><div class=\"line\">239</div><div class=\"line\">240</div><div class=\"line\">241</div><div class=\"line\">242</div><div class=\"line\">243</div><div class=\"line\">244</div><div class=\"line\">245</div><div class=\"line\">246</div><div class=\"line\">247</div><div class=\"line\">248</div><div class=\"line\">249</div><div class=\"line\">250</div><div class=\"line\">251</div><div class=\"line\">252</div><div class=\"line\">253</div><div class=\"line\">254</div><div class=\"line\">255</div><div class=\"line\">256</div><div class=\"line\">257</div><div class=\"line\">258</div><div class=\"line\">259</div><div class=\"line\">260</div><div class=\"line\">261</div><div class=\"line\">262</div><div class=\"line\">263</div><div class=\"line\">264</div><div class=\"line\">265</div><div class=\"line\">266</div><div class=\"line\">267</div><div class=\"line\">268</div><div class=\"line\">269</div><div class=\"line\">270</div><div class=\"line\">271</div><div class=\"line\">272</div><div class=\"line\">273</div><div class=\"line\">274</div><div class=\"line\">275</div><div class=\"line\">276</div><div class=\"line\">277</div><div class=\"line\">278</div><div class=\"line\">279</div><div class=\"line\">280</div><div class=\"line\">281</div><div class=\"line\">282</div><div class=\"line\">283</div><div class=\"line\">284</div><div class=\"line\">285</div><div class=\"line\">286</div><div class=\"line\">287</div><div class=\"line\">288</div><div class=\"line\">289</div><div class=\"line\">290</div><div class=\"line\">291</div><div class=\"line\">292</div><div class=\"line\">293</div><div class=\"line\">294</div><div class=\"line\">295</div><div class=\"line\">296</div><div class=\"line\">297</div><div class=\"line\">298</div><div class=\"line\">299</div><div class=\"line\">300</div><div class=\"line\">301</div><div class=\"line\">302</div><div class=\"line\">303</div><div class=\"line\">304</div><div class=\"line\">305</div><div class=\"line\">306</div><div class=\"line\">307</div><div class=\"line\">308</div><div class=\"line\">309</div><div class=\"line\">310</div><div class=\"line\">311</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new [[Dataset]] by sampling a fraction of rows, using a user-supplied seed.</div><div class=\"line\">   *</div><div class=\"line\">   * @param withReplacement Sample with replacement or not.</div><div class=\"line\">   * @param fraction Fraction of rows to generate.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   *</div><div class=\"line\">   * @note This is NOT guaranteed to provide exactly the fraction of the count</div><div class=\"line\">   * of the given [[Dataset]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def sample(withReplacement: Boolean, fraction: Double, seed: Long): Dataset[T] = &#123;</div><div class=\"line\">    require(fraction &gt;= 0,</div><div class=\"line\">      s&quot;Fraction must be nonnegative, but got $&#123;fraction&#125;&quot;)</div><div class=\"line\"></div><div class=\"line\">    withTypedPlan &#123;</div><div class=\"line\">      Sample(0.0, fraction, withReplacement, seed, logicalPlan)()</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new [[Dataset]] by sampling a fraction of rows, using a random seed.</div><div class=\"line\">   *</div><div class=\"line\">   * @param withReplacement Sample with replacement or not.</div><div class=\"line\">   * @param fraction Fraction of rows to generate.</div><div class=\"line\">   *</div><div class=\"line\">   * @note This is NOT guaranteed to provide exactly the fraction of the total count</div><div class=\"line\">   * of the given [[Dataset]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def sample(withReplacement: Boolean, fraction: Double): Dataset[T] = &#123;</div><div class=\"line\">    sample(withReplacement, fraction, Utils.random.nextLong)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Randomly splits this Dataset with the provided weights.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   *</div><div class=\"line\">   * For Java API, use [[randomSplitAsList]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  ???</div><div class=\"line\">  def randomSplit(weights: Array[Double], seed: Long): Array[Dataset[T]] = &#123;</div><div class=\"line\">    require(weights.forall(_ &gt;= 0),</div><div class=\"line\">      s&quot;Weights must be nonnegative, but got $&#123;weights.mkString(&quot;[&quot;, &quot;,&quot;, &quot;]&quot;)&#125;&quot;)</div><div class=\"line\">    require(weights.sum &gt; 0,</div><div class=\"line\">      s&quot;Sum of weights must be positive, but got $&#123;weights.mkString(&quot;[&quot;, &quot;,&quot;, &quot;]&quot;)&#125;&quot;)</div><div class=\"line\"></div><div class=\"line\">    // It is possible that the underlying dataframe doesn&apos;t guarantee the ordering of rows in its</div><div class=\"line\">    // constituent partitions each time a split is materialized which could result in</div><div class=\"line\">    // overlapping splits. To prevent this, we explicitly sort each input partition to make the</div><div class=\"line\">    // ordering deterministic.</div><div class=\"line\">    // MapType cannot be sorted.</div><div class=\"line\">    val sorted = Sort(logicalPlan.output.filterNot(_.dataType.isInstanceOf[MapType])</div><div class=\"line\">      .map(SortOrder(_, Ascending)), global = false, logicalPlan)</div><div class=\"line\">    val sum = weights.sum</div><div class=\"line\">    val normalizedCumWeights = weights.map(_ / sum).scanLeft(0.0d)(_ + _)</div><div class=\"line\">    normalizedCumWeights.sliding(2).map &#123; x =&gt;</div><div class=\"line\">      new Dataset[T](</div><div class=\"line\">        sparkSession, Sample(x(0), x(1), withReplacement = false, seed, sorted)(), encoder)</div><div class=\"line\">    &#125;.toArray</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a Java list that contains randomly split Dataset with the provided weights.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   *</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def randomSplitAsList(weights: Array[Double], seed: Long): java.util.List[Dataset[T]] = &#123;</div><div class=\"line\">    val values = randomSplit(weights, seed)</div><div class=\"line\">    java.util.Arrays.asList(values : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Randomly splits this Dataset with the provided weights.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @group typedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def randomSplit(weights: Array[Double]): Array[Dataset[T]] = &#123;</div><div class=\"line\">    randomSplit(weights, Utils.random.nextLong)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Randomly splits this Dataset with the provided weights. Provided for the Python Api.</div><div class=\"line\">   *</div><div class=\"line\">   * @param weights weights for splits, will be normalized if they don&apos;t sum to 1.</div><div class=\"line\">   * @param seed Seed for sampling.</div><div class=\"line\">   */</div><div class=\"line\">  private[spark] def randomSplit(weights: List[Double], seed: Long): Array[Dataset[T]] = &#123;</div><div class=\"line\">    randomSplit(weights.toArray, seed)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * (Scala-specific) Returns a new Dataset where each row has been expanded to zero or more</div><div class=\"line\">   * rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. The columns of</div><div class=\"line\">   * the input row are implicitly joined with each row that is output by the function.</div><div class=\"line\">   *</div><div class=\"line\">   * Given that this is deprecated, as an alternative, you can explode columns either using</div><div class=\"line\">   * `functions.explode()` or `flatMap()`. The following example uses these alternatives to count</div><div class=\"line\">   * the number of books that contain a given word:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   case class Book(title: String, words: String)</div><div class=\"line\">   *   val ds: Dataset[Book]</div><div class=\"line\">   *</div><div class=\"line\">   *   val allWords = ds.select(&apos;title, explode(split(&apos;words, &quot; &quot;)).as(&quot;word&quot;))</div><div class=\"line\">   *</div><div class=\"line\">   *   val bookCountPerWord = allWords.groupBy(&quot;word&quot;).agg(countDistinct(&quot;title&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * Using `flatMap()` this can similarly be exploded as:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.flatMap(_.words.split(&quot; &quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  @deprecated(&quot;use flatMap() or select() with functions.explode() instead&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">  def explode[A &lt;: Product : TypeTag](input: Column*)(f: Row =&gt; TraversableOnce[A]): DataFrame = &#123;</div><div class=\"line\">    val elementSchema = ScalaReflection.schemaFor[A].dataType.asInstanceOf[StructType]</div><div class=\"line\"></div><div class=\"line\">    val convert = CatalystTypeConverters.createToCatalystConverter(elementSchema)</div><div class=\"line\"></div><div class=\"line\">    val rowFunction =</div><div class=\"line\">      f.andThen(_.map(convert(_).asInstanceOf[InternalRow]))</div><div class=\"line\">    val generator = UserDefinedGenerator(elementSchema, rowFunction, input.map(_.expr))</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      Generate(generator, join = true, outer = false,</div><div class=\"line\">        qualifier = None, generatorOutput = Nil, logicalPlan)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * (Scala-specific) Returns a new Dataset where a single column has been expanded to zero</div><div class=\"line\">   * or more rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. All</div><div class=\"line\">   * columns of the input row are implicitly joined with each value that is output by the function.</div><div class=\"line\">   *</div><div class=\"line\">   * Given that this is deprecated, as an alternative, you can explode columns either using</div><div class=\"line\">   * `functions.explode()`:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.select(explode(split(&apos;words, &quot; &quot;)).as(&quot;word&quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * or `flatMap()`:</div><div class=\"line\">   *</div><div class=\"line\">   * &#123;&#123;&#123;</div><div class=\"line\">   *   ds.flatMap(_.words.split(&quot; &quot;))</div><div class=\"line\">   * &#125;&#125;&#125;</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @deprecated(&quot;use flatMap() or select() with functions.explode() instead&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">  def explode[A, B : TypeTag](inputColumn: String, outputColumn: String)(f: A =&gt; TraversableOnce[B])</div><div class=\"line\">    : DataFrame = &#123;</div><div class=\"line\">    val dataType = ScalaReflection.schemaFor[B].dataType</div><div class=\"line\">    val attributes = AttributeReference(outputColumn, dataType)() :: Nil</div><div class=\"line\">    // TODO handle the metadata?</div><div class=\"line\">    val elementSchema = attributes.toStructType</div><div class=\"line\"></div><div class=\"line\">    def rowFunction(row: Row): TraversableOnce[InternalRow] = &#123;</div><div class=\"line\">      val convert = CatalystTypeConverters.createToCatalystConverter(dataType)</div><div class=\"line\">      f(row(0).asInstanceOf[A]).map(o =&gt; InternalRow(convert(o)))</div><div class=\"line\">    &#125;</div><div class=\"line\">    val generator = UserDefinedGenerator(elementSchema, rowFunction, apply(inputColumn).expr :: Nil)</div><div class=\"line\"></div><div class=\"line\">    withPlan &#123;</div><div class=\"line\">      Generate(generator, join = true, outer = false,</div><div class=\"line\">        qualifier = None, generatorOutput = Nil, logicalPlan)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">## </div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset by adding a column or replacing the existing column that has</div><div class=\"line\">   * the same name.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def withColumn(colName: String, col: Column): DataFrame = &#123;</div><div class=\"line\">    val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">    val output = queryExecution.analyzed.output</div><div class=\"line\">    val shouldReplace = output.exists(f =&gt; resolver(f.name, colName))</div><div class=\"line\">    if (shouldReplace) &#123;</div><div class=\"line\">      val columns = output.map &#123; field =&gt;</div><div class=\"line\">        if (resolver(field.name, colName)) &#123;</div><div class=\"line\">          col.as(colName)</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          Column(field)</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">      select(columns : _*)</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      select(Column(&quot;*&quot;), col.as(colName))</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset by adding a column with metadata.</div><div class=\"line\">   */</div><div class=\"line\">  private[spark] def withColumn(colName: String, col: Column, metadata: Metadata): DataFrame = &#123;</div><div class=\"line\">    withColumn(colName, col.as(colName, metadata))</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with a column renamed.</div><div class=\"line\">   * This is a no-op if schema doesn&apos;t contain existingName.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def withColumnRenamed(existingName: String, newName: String): DataFrame = &#123;</div><div class=\"line\">    val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">    val output = queryExecution.analyzed.output</div><div class=\"line\">    val shouldRename = output.exists(f =&gt; resolver(f.name, existingName))</div><div class=\"line\">    if (shouldRename) &#123;</div><div class=\"line\">      val columns = output.map &#123; col =&gt;</div><div class=\"line\">        if (resolver(col.name, existingName)) &#123;</div><div class=\"line\">          Column(col).as(newName)</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          Column(col)</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">      select(columns : _*)</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      toDF()</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with a column dropped. This is a no-op if schema doesn&apos;t contain</div><div class=\"line\">   * column name.</div><div class=\"line\">   *</div><div class=\"line\">   * This method can only be used to drop top level columns. the colName string is treated</div><div class=\"line\">   * literally without further interpretation.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def drop(colName: String): DataFrame = &#123;</div><div class=\"line\">    drop(Seq(colName) : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with columns dropped.</div><div class=\"line\">   * This is a no-op if schema doesn&apos;t contain column name(s).</div><div class=\"line\">   *</div><div class=\"line\">   * This method can only be used to drop top level columns. the colName string is treated literally</div><div class=\"line\">   * without further interpretation.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  @scala.annotation.varargs</div><div class=\"line\">  def drop(colNames: String*): DataFrame = &#123;</div><div class=\"line\">    val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">    val allColumns = queryExecution.analyzed.output</div><div class=\"line\">    val remainingCols = allColumns.filter &#123; attribute =&gt;</div><div class=\"line\">      colNames.forall(n =&gt; !resolver(attribute.name, n))</div><div class=\"line\">    &#125;.map(attribute =&gt; Column(attribute))</div><div class=\"line\">    if (remainingCols.size == allColumns.size) &#123;</div><div class=\"line\">      toDF()</div><div class=\"line\">    &#125; else &#123;</div><div class=\"line\">      this.select(remainingCols: _*)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a new Dataset with a column dropped.</div><div class=\"line\">   * This version of drop accepts a [[Column]] rather than a name.</div><div class=\"line\">   * This is a no-op if the Dataset doesn&apos;t have a column</div><div class=\"line\">   * with an equivalent expression.</div><div class=\"line\">   *</div><div class=\"line\">   * @group untypedrel</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def drop(col: Column): DataFrame = &#123;</div><div class=\"line\">    val expression = col match &#123;</div><div class=\"line\">      case Column(u: UnresolvedAttribute) =&gt;</div><div class=\"line\">        queryExecution.analyzed.resolveQuoted(</div><div class=\"line\">          u.name, sparkSession.sessionState.analyzer.resolver).getOrElse(u)</div><div class=\"line\">      case Column(expr: Expression) =&gt; expr</div><div class=\"line\">    &#125;</div><div class=\"line\">    val attrs = this.logicalPlan.output</div><div class=\"line\">    val colsAfterDrop = attrs.filter &#123; attr =&gt;</div><div class=\"line\">      attr != expression</div><div class=\"line\">    &#125;.map(attr =&gt; Column(attr))</div><div class=\"line\">    select(colsAfterDrop : _*)</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that contains only the unique rows from this Dataset.</div><div class=\"line\"> * This is an alias for `distinct`.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def dropDuplicates(): Dataset[T] = dropDuplicates(this.columns)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Scala-specific) Returns a new Dataset with duplicate rows removed, considering only</div><div class=\"line\"> * the subset of columns.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def dropDuplicates(colNames: Seq[String]): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  val resolver = sparkSession.sessionState.analyzer.resolver</div><div class=\"line\">  val allColumns = queryExecution.analyzed.output</div><div class=\"line\">  val groupCols = colNames.toSet.toSeq.flatMap &#123; (colName: String) =&gt;</div><div class=\"line\">    // It is possibly there are more than one columns with the same name,</div><div class=\"line\">    // so we call filter instead of find.</div><div class=\"line\">    val cols = allColumns.filter(col =&gt; resolver(col.name, colName))</div><div class=\"line\">    if (cols.isEmpty) &#123;</div><div class=\"line\">      throw new AnalysisException(</div><div class=\"line\">        s&quot;&quot;&quot;Cannot resolve column name &quot;$colName&quot; among ($&#123;schema.fieldNames.mkString(&quot;, &quot;)&#125;)&quot;&quot;&quot;)</div><div class=\"line\">    &#125;</div><div class=\"line\">    cols</div><div class=\"line\">  &#125;</div><div class=\"line\">  Deduplicate(groupCols, logicalPlan, isStreaming)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset with duplicate rows removed, considering only</div><div class=\"line\"> * the subset of columns.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def dropDuplicates(colNames: Array[String]): Dataset[T] = dropDuplicates(colNames.toSeq)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new [[Dataset]] with duplicate rows removed, considering only</div><div class=\"line\"> * the subset of columns.</div><div class=\"line\"> *</div><div class=\"line\"> * For a static batch [[Dataset]], it just drops duplicate rows. For a streaming [[Dataset]], it</div><div class=\"line\"> * will keep all data across triggers as intermediate state to drop duplicates rows. You can use</div><div class=\"line\"> * [[withWatermark]] to limit how late the duplicate data can be and system will accordingly limit</div><div class=\"line\"> * the state. In addition, too late data older than watermark will be dropped to avoid any</div><div class=\"line\"> * possibility of duplicates.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def dropDuplicates(col1: String, cols: String*): Dataset[T] = &#123;</div><div class=\"line\">  val colNames: Seq[String] = col1 +: cols</div><div class=\"line\">  dropDuplicates(colNames)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><pre><code><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Computes statistics for numeric and string columns, including count, mean, stddev, min, and</div><div class=\"line\"> * max. If no columns are given, this function computes statistics for all numerical or string</div><div class=\"line\"> * columns.</div><div class=\"line\"> *</div><div class=\"line\"> * This function is meant for exploratory data analysis, as we make no guarantee about the</div><div class=\"line\"> * backward compatibility of the schema of the resulting Dataset. If you want to</div><div class=\"line\"> * programmatically compute summary statistics, use the `agg` function instead.</div><div class=\"line\"> *</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   ds.describe(&quot;age&quot;, &quot;height&quot;).show()</div><div class=\"line\"> *</div><div class=\"line\"> *   // output:</div><div class=\"line\"> *   // summary age   height</div><div class=\"line\"> *   // count   10.0  10.0</div><div class=\"line\"> *   // mean    53.3  178.05</div><div class=\"line\"> *   // stddev  11.6  15.7</div><div class=\"line\"> *   // min     18.0  163.0</div><div class=\"line\"> *   // max     92.0  192.0</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def describe(cols: String*): DataFrame = withPlan &#123;</div><div class=\"line\"></div><div class=\"line\">  // The list of summary statistics to compute, in the form of expressions.</div><div class=\"line\">  val statistics = List[(String, Expression =&gt; Expression)](</div><div class=\"line\">    &quot;count&quot; -&gt; ((child: Expression) =&gt; Count(child).toAggregateExpression()),</div><div class=\"line\">    &quot;mean&quot; -&gt; ((child: Expression) =&gt; Average(child).toAggregateExpression()),</div><div class=\"line\">    &quot;stddev&quot; -&gt; ((child: Expression) =&gt; StddevSamp(child).toAggregateExpression()),</div><div class=\"line\">    &quot;min&quot; -&gt; ((child: Expression) =&gt; Min(child).toAggregateExpression()),</div><div class=\"line\">    &quot;max&quot; -&gt; ((child: Expression) =&gt; Max(child).toAggregateExpression()))</div><div class=\"line\"></div><div class=\"line\">  val outputCols =</div><div class=\"line\">    (if (cols.isEmpty) aggregatableColumns.map(usePrettyExpression(_).sql) else cols).toList</div><div class=\"line\"></div><div class=\"line\">  val ret: Seq[Row] = if (outputCols.nonEmpty) &#123;</div><div class=\"line\">    val aggExprs = statistics.flatMap &#123; case (_, colToAgg) =&gt;</div><div class=\"line\">      outputCols.map(c =&gt; Column(Cast(colToAgg(Column(c).expr), StringType)).as(c))</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    val row = groupBy().agg(aggExprs.head, aggExprs.tail: _*).head().toSeq</div><div class=\"line\"></div><div class=\"line\">    // Pivot the data so each summary is one row</div><div class=\"line\">    row.grouped(outputCols.size).toSeq.zip(statistics).map &#123; case (aggregation, (statistic, _)) =&gt;</div><div class=\"line\">      Row(statistic :: aggregation.toList: _*)</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125; else &#123;</div><div class=\"line\">    // If there are no output columns, just output a single column that contains the stats.</div><div class=\"line\">    statistics.map &#123; case (name, _) =&gt; Row(name) &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  // All columns are string type</div><div class=\"line\">  val schema = StructType(</div><div class=\"line\">    StructField(&quot;summary&quot;, StringType) :: outputCols.map(StructField(_, StringType))).toAttributes</div><div class=\"line\">  // `toArray` forces materialization to make the seq serializable</div><div class=\"line\">  LocalRelation.fromExternalRows(schema, ret.toArray.toSeq)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the first `n` rows.</div><div class=\"line\"> *</div><div class=\"line\"> * @note this method should only be used if the resulting array is expected to be small, as</div><div class=\"line\"> * all the data is loaded into the driver&apos;s memory.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">n</div><div class=\"line\">def head(n: Int): Array[T] = withAction(&quot;head&quot;, limit(n).queryExecution)(collectFromPlan)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the first row.</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def head(): T = head(1).head</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the first row. Alias for head().</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def first(): T = head()</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Concise syntax for chaining custom transformations.</div><div class=\"line\"> * &#123;&#123;&#123;</div><div class=\"line\"> *   def featurize(ds: Dataset[T]): Dataset[U] = ...</div><div class=\"line\"> *</div><div class=\"line\"> *   ds</div><div class=\"line\"> *     .transform(featurize)</div><div class=\"line\"> *     .transform(...)</div><div class=\"line\"> * &#125;&#125;&#125;</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def transform[U](t: Dataset[T] =&gt; Dataset[U]): Dataset[U] = t(this)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset that only contains elements where `func` returns `true`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def filter(func: T =&gt; Boolean): Dataset[T] = &#123;</div><div class=\"line\">  withTypedPlan(TypedFilter(func, logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset that only contains elements where `func` returns `true`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def filter(func: FilterFunction[T]): Dataset[T] = &#123;</div><div class=\"line\">  withTypedPlan(TypedFilter(func, logicalPlan))</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</code></pre><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `func` to each element.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def map[U : Encoder](func: T =&gt; U): Dataset[U] = withTypedPlan &#123;</div><div class=\"line\">  MapElements[T, U](func, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `func` to each element.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def map[U](func: MapFunction[T, U], encoder: Encoder[U]): Dataset[U] = &#123;</div><div class=\"line\">  implicit val uEnc = encoder</div><div class=\"line\">  withTypedPlan(MapElements[T, U](func, logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `func` to each partition.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def mapPartitions[U : Encoder](func: Iterator[T] =&gt; Iterator[U]): Dataset[U] = &#123;</div><div class=\"line\">  new Dataset[U](</div><div class=\"line\">    sparkSession,</div><div class=\"line\">    MapPartitions[T, U](func, logicalPlan),</div><div class=\"line\">    implicitly[Encoder[U]])</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset that contains the result of applying `f` to each partition.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def mapPartitions[U](f: MapPartitionsFunction[T, U], encoder: Encoder[U]): Dataset[U] = &#123;</div><div class=\"line\">  val func: (Iterator[T]) =&gt; Iterator[U] = x =&gt; f.call(x.asJava).asScala</div><div class=\"line\">  mapPartitions(func)(encoder)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new `DataFrame` that contains the result of applying a serialized R function</div><div class=\"line\"> * `func` to each partition.</div><div class=\"line\"> */</div><div class=\"line\">private[sql] def mapPartitionsInR(</div><div class=\"line\">    func: Array[Byte],</div><div class=\"line\">    packageNames: Array[Byte],</div><div class=\"line\">    broadcastVars: Array[Broadcast[Object]],</div><div class=\"line\">    schema: StructType): DataFrame = &#123;</div><div class=\"line\">  val rowEncoder = encoder.asInstanceOf[ExpressionEncoder[Row]]</div><div class=\"line\">  Dataset.ofRows(</div><div class=\"line\">    sparkSession,</div><div class=\"line\">    MapPartitionsInR(func, packageNames, broadcastVars, schema, rowEncoder, logicalPlan))</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Scala-specific)</div><div class=\"line\"> * Returns a new Dataset by first applying a function to all elements of this Dataset,</div><div class=\"line\"> * and then flattening the results.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def flatMap[U : Encoder](func: T =&gt; TraversableOnce[U]): Dataset[U] =</div><div class=\"line\">  mapPartitions(_.flatMap(func))</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Returns a new Dataset by first applying a function to all elements of this Dataset,</div><div class=\"line\"> * and then flattening the results.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def flatMap[U](f: FlatMapFunction[T, U], encoder: Encoder[U]): Dataset[U] = &#123;</div><div class=\"line\">  val func: (T) =&gt; Iterator[U] = x =&gt; f.call(x).asScala</div><div class=\"line\">  flatMap(func)(encoder)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Applies a function `f` to all rows.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def foreach(f: T =&gt; Unit): Unit = withNewExecutionId &#123;</div><div class=\"line\">  rdd.foreach(f)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * (Java-specific)</div><div class=\"line\"> * Runs `func` on each element of this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def foreach(func: ForeachFunction[T]): Unit = foreach(func.call(_))</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Applies a function `f` to each partition of this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group action</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def foreachPartition(f: Iterator[T] =&gt; Unit): Unit = withNewExecutionId &#123;</div><div class=\"line\">  rdd.foreachPartition(f)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div></pre></td><td class=\"code\"><pre><div class=\"line\">  /**</div><div class=\"line\">   * (Java-specific)</div><div class=\"line\">   * Runs `func` on each partition of this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def foreachPartition(func: ForeachPartitionFunction[T]): Unit =</div><div class=\"line\">    foreachPartition(it =&gt; func.call(it.asJava))</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns the first `n` rows in the Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * Running take requires moving data into the application&apos;s driver process, and doing so with</div><div class=\"line\">   * a very large `n` can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def take(n: Int): Array[T] = head(n)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns the first `n` rows in the Dataset as a list.</div><div class=\"line\">   *</div><div class=\"line\">   * Running take requires moving data into the application&apos;s driver process, and doing so with</div><div class=\"line\">   * a very large `n` can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">    </div><div class=\"line\">  def takeAsList(n: Int): java.util.List[T] = java.util.Arrays.asList(take(n) : _*)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns an array that contains all rows in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * Running collect requires moving all the data into the application&apos;s driver process, and</div><div class=\"line\">   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * For Java API, use [[collectAsList]].</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">  def collect(): Array[T] = withAction(&quot;collect&quot;, queryExecution)(collectFromPlan)</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns a Java list that contains all rows in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * Running collect requires moving all the data into the application&apos;s driver process, and</div><div class=\"line\">   * doing so on a very large dataset can crash the driver process with OutOfMemoryError.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  def collectAsList(): java.util.List[T] = withAction(&quot;collectAsList&quot;, queryExecution) &#123; plan =&gt;</div><div class=\"line\">    val values = collectFromPlan(plan)</div><div class=\"line\">    java.util.Arrays.asList(values : _*)</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Return an iterator that contains all rows in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * The iterator will consume as much memory as the largest partition in this Dataset.</div><div class=\"line\">   *</div><div class=\"line\">   * @note this results in multiple Spark jobs, and if the input Dataset is the result</div><div class=\"line\">   * of a wide transformation (e.g. join with different partitioners), to avoid</div><div class=\"line\">   * recomputing the input Dataset should be cached first.</div><div class=\"line\">   *</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 2.0.0</div><div class=\"line\">   */</div><div class=\"line\">  def toLocalIterator(): java.util.Iterator[T] = &#123;</div><div class=\"line\">    withAction(&quot;toLocalIterator&quot;, queryExecution) &#123; plan =&gt;</div><div class=\"line\">      plan.executeToIterator().map(boundEnc.fromRow).asJava</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  /**</div><div class=\"line\">   * Returns the number of rows in the Dataset.</div><div class=\"line\">   * @group action</div><div class=\"line\">   * @since 1.6.0</div><div class=\"line\">   */</div><div class=\"line\">  </div><div class=\"line\">  def count(): Long = withAction(&quot;count&quot;, groupBy().count().queryExecution) &#123; plan =&gt;</div><div class=\"line\">    plan.executeCollect().head.getLong(0)</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><pre><code><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that has exactly `numPartitions` partitions.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">def repartition(numPartitions: Int): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Repartition(numPartitions, shuffle = true, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset partitioned by the given partitioning expressions into</div><div class=\"line\"> * `numPartitions`. The resulting Dataset is hash partitioned.</div><div class=\"line\"> *</div><div class=\"line\"> * This is the same operation as &quot;DISTRIBUTE BY&quot; in SQL (Hive QL).</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def repartition(numPartitions: Int, partitionExprs: Column*): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  RepartitionByExpression(partitionExprs.map(_.expr), logicalPlan, numPartitions)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset partitioned by the given partitioning expressions, using</div><div class=\"line\"> * `spark.sql.shuffle.partitions` as number of partitions.</div><div class=\"line\"> * The resulting Dataset is hash partitioned.</div><div class=\"line\"> *</div><div class=\"line\"> * This is the same operation as &quot;DISTRIBUTE BY&quot; in SQL (Hive QL).</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@scala.annotation.varargs</div><div class=\"line\">def repartition(partitionExprs: Column*): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  RepartitionByExpression(</div><div class=\"line\">    partitionExprs.map(_.expr), logicalPlan, sparkSession.sessionState.conf.numShufflePartitions)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that has exactly `numPartitions` partitions.</div><div class=\"line\"> * Similar to coalesce defined on an `RDD`, this operation results in a narrow dependency, e.g.</div><div class=\"line\"> * if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of</div><div class=\"line\"> * the 100 new partitions will claim 10 of the current partitions.  If a larger number of</div><div class=\"line\"> * partitions is requested, it will stay at the current number of partitions.</div><div class=\"line\"> *</div><div class=\"line\"> * However, if you&apos;re doing a drastic coalesce, e.g. to numPartitions = 1,</div><div class=\"line\"> * this may result in your computation taking place on fewer nodes than</div><div class=\"line\"> * you like (e.g. one node in the case of numPartitions = 1). To avoid this,</div><div class=\"line\"> * you can call repartition. This will add a shuffle step, but means the</div><div class=\"line\"> * current upstream partitions will be executed in parallel (per whatever</div><div class=\"line\"> * the current partitioning is).</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def coalesce(numPartitions: Int): Dataset[T] = withTypedPlan &#123;</div><div class=\"line\">  Repartition(numPartitions, shuffle = false, logicalPlan)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns a new Dataset that contains only the unique rows from this Dataset.</div><div class=\"line\"> * This is an alias for `dropDuplicates`.</div><div class=\"line\"> *</div><div class=\"line\"> * @note Equality checking is performed directly on the encoded representation of the data</div><div class=\"line\"> * and thus is not affected by a custom `equals` function defined on `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group typedrel</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def distinct(): Dataset[T] = dropDuplicates()</div></pre></td></tr></table></figure>\n</code></pre><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>  rddrdd</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">                </div><div class=\"line\">def persist(): this.type = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.cacheQuery(this)</div><div class=\"line\">  this</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def cache(): this.type = persist()</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Persist this Dataset with the given storage level.</div><div class=\"line\"> * @param newLevel One of: `MEMORY_ONLY`, `MEMORY_AND_DISK`, `MEMORY_ONLY_SER`,</div><div class=\"line\"> *                 `MEMORY_AND_DISK_SER`, `DISK_ONLY`, `MEMORY_ONLY_2`,</div><div class=\"line\"> *                 `MEMORY_AND_DISK_2`, etc.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def persist(newLevel: StorageLevel): this.type = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.cacheQuery(this, None, newLevel)</div><div class=\"line\">  this</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Get the Dataset&apos;s current storage level, or StorageLevel.NONE if not persisted.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">def storageLevel: StorageLevel = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.lookupCachedData(this).map &#123; cachedData =&gt;</div><div class=\"line\">    cachedData.cachedRepresentation.storageLevel</div><div class=\"line\">  &#125;.getOrElse(StorageLevel.NONE)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div><div class=\"line\"> *</div><div class=\"line\"> * @param blocking Whether to block until all blocks are deleted.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def unpersist(blocking: Boolean): this.type = &#123;</div><div class=\"line\">  sparkSession.sharedState.cacheManager.uncacheQuery(this, blocking)</div><div class=\"line\">  this</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def unpersist(): this.type = unpersist(blocking = false)</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Represents the content of the Dataset as an `RDD` of `T`.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">lazy val rdd: RDD[T] = &#123;</div><div class=\"line\">  val objectType = exprEnc.deserializer.dataType</div><div class=\"line\">  val deserialized = CatalystSerde.deserialize[T](logicalPlan)</div><div class=\"line\">  sparkSession.sessionState.executePlan(deserialized).toRdd.mapPartitions &#123; rows =&gt;</div><div class=\"line\">    rows.map(_.get(0, objectType).asInstanceOf[T])</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the content of the Dataset as a `JavaRDD` of `T`s.</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def toJavaRDD: JavaRDD[T] = rdd.toJavaRDD()</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Returns the content of the Dataset as a `JavaRDD` of `T`s.</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def javaRDD: JavaRDD[T] = toJavaRDD</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>datasetsqldataset<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Registers this Dataset as a temporary table using the given name. The lifetime of this</div><div class=\"line\"> * temporary table is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@deprecated(&quot;Use createOrReplaceTempView(viewName) instead.&quot;, &quot;2.0.0&quot;)</div><div class=\"line\">def registerTempTable(tableName: String): Unit = &#123;</div><div class=\"line\">  createOrReplaceTempView(tableName)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Creates a local temporary view using the given name. The lifetime of this</div><div class=\"line\"> * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * Local temporary view is session-scoped. Its lifetime is the lifetime of the session that</div><div class=\"line\"> * created it, i.e. it will be automatically dropped when the session terminates. It&apos;s not</div><div class=\"line\"> * tied to any databases, i.e. we can&apos;t use `db1.view1` to reference a local temporary view.</div><div class=\"line\"> *</div><div class=\"line\"> * @throws AnalysisException if the view name is invalid or already exists</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\"></div><div class=\"line\">@throws[AnalysisException]</div><div class=\"line\">def createTempView(viewName: String): Unit = withPlan &#123;</div><div class=\"line\">  createTempViewCommand(viewName, replace = false, global = false)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Creates a local temporary view using the given name. The lifetime of this</div><div class=\"line\"> * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def createOrReplaceTempView(viewName: String): Unit = withPlan &#123;</div><div class=\"line\">  createTempViewCommand(viewName, replace = true, global = false)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * Creates a global temporary view using the given name. The lifetime of this</div><div class=\"line\"> * temporary view is tied to this Spark application.</div><div class=\"line\"> *</div><div class=\"line\"> * Global temporary view is cross-session. Its lifetime is the lifetime of the Spark application,</div><div class=\"line\"> * i.e. it will be automatically dropped when the application terminates. It&apos;s tied to a system</div><div class=\"line\"> * preserved database `global_temp`, and we must use the qualified name to refer a global temp</div><div class=\"line\"> * view, e.g. `SELECT * FROM global_temp.view1`.</div><div class=\"line\"> *</div><div class=\"line\"> * @throws AnalysisException if the view name is invalid or already exists</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.1.0</div><div class=\"line\"> */</div><div class=\"line\">@throws[AnalysisException]</div><div class=\"line\">def createGlobalTempView(viewName: String): Unit = withPlan &#123;</div><div class=\"line\">  createTempViewCommand(viewName, replace = false, global = true)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">private def createTempViewCommand(</div><div class=\"line\">    viewName: String,</div><div class=\"line\">    replace: Boolean,</div><div class=\"line\">    global: Boolean): CreateViewCommand = &#123;</div><div class=\"line\">  val viewType = if (global) GlobalTempView else LocalTempView</div><div class=\"line\"></div><div class=\"line\">  val tableIdentifier = try &#123;</div><div class=\"line\">    sparkSession.sessionState.sqlParser.parseTableIdentifier(viewName)</div><div class=\"line\">  &#125; catch &#123;</div><div class=\"line\">    case _: ParseException =&gt; throw new AnalysisException(s&quot;Invalid view name: $viewName&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\">  CreateViewCommand(</div><div class=\"line\">    name = tableIdentifier,</div><div class=\"line\">    userSpecifiedColumns = Nil,</div><div class=\"line\">    comment = None,</div><div class=\"line\">    properties = Map.empty,</div><div class=\"line\">    originalText = None,</div><div class=\"line\">    child = logicalPlan,</div><div class=\"line\">    allowExisting = false,</div><div class=\"line\">    replace = replace,</div><div class=\"line\">    viewType = viewType)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><pre><code>writewritewrite\n</code></pre><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Interface for saving the content of the non-streaming Dataset out into external storage.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 1.6.0</div><div class=\"line\"> */</div><div class=\"line\">def write: DataFrameWriter[T] = &#123;</div><div class=\"line\">  if (isStreaming) &#123;</div><div class=\"line\">    logicalPlan.failAnalysis(</div><div class=\"line\">      &quot;&apos;write&apos; can not be called on streaming Dataset/DataFrame&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\">  new DataFrameWriter[T](this)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">/**</div><div class=\"line\"> * :: Experimental ::</div><div class=\"line\"> * Interface for saving the content of the streaming Dataset out into external storage.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">@Experimental</div><div class=\"line\">@InterfaceStability.Evolving</div><div class=\"line\">def writeStream: DataStreamWriter[T] = &#123;</div><div class=\"line\">  if (!isStreaming) &#123;</div><div class=\"line\">    logicalPlan.failAnalysis(</div><div class=\"line\">      &quot;&apos;writeStream&apos; can be called only on streaming Dataset/DataFrame&quot;)</div><div class=\"line\">  &#125;</div><div class=\"line\">  new DataStreamWriter[T](this)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"json\"><a href=\"#json\" class=\"headerlink\" title=\"json\"></a>json</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns the content of the Dataset as a Dataset of JSON strings.</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def toJSON: Dataset[String] = &#123;</div><div class=\"line\">  val rowSchema = this.schema</div><div class=\"line\">  val sessionLocalTimeZone = sparkSession.sessionState.conf.sessionLocalTimeZone</div><div class=\"line\">  val rdd: RDD[String] = queryExecution.toRdd.mapPartitions &#123; iter =&gt;</div><div class=\"line\">    val writer = new CharArrayWriter()</div><div class=\"line\">    // create the Generator without separator inserted between 2 records</div><div class=\"line\">    val gen = new JacksonGenerator(rowSchema, writer,</div><div class=\"line\">      new JSONOptions(Map.empty[String, String], sessionLocalTimeZone))</div><div class=\"line\"></div><div class=\"line\">    new Iterator[String] &#123;</div><div class=\"line\">      override def hasNext: Boolean = iter.hasNext</div><div class=\"line\">      override def next(): String = &#123;</div><div class=\"line\">        gen.write(iter.next())</div><div class=\"line\">        gen.flush()</div><div class=\"line\"></div><div class=\"line\">        val json = writer.toString</div><div class=\"line\">        if (hasNext) &#123;</div><div class=\"line\">          writer.reset()</div><div class=\"line\">        &#125; else &#123;</div><div class=\"line\">          gen.close()</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        json</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">  import sparkSession.implicits.newStringEncoder</div><div class=\"line\">  sparkSession.createDataset(rdd)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>  dataSet<br>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">/**</div><div class=\"line\"> * Returns a best-effort snapshot of the files that compose this Dataset. This method simply</div><div class=\"line\"> * asks each constituent BaseRelation for its respective files and takes the union of all results.</div><div class=\"line\"> * Depending on the source relations, this may not find all input files. Duplicates are removed.</div><div class=\"line\"> *</div><div class=\"line\"> * @group basic</div><div class=\"line\"> * @since 2.0.0</div><div class=\"line\"> */</div><div class=\"line\">def inputFiles: Array[String] = &#123;</div><div class=\"line\">  val files: Seq[String] = queryExecution.optimizedPlan.collect &#123;</div><div class=\"line\">    case LogicalRelation(fsBasedRelation: FileRelation, _, _) =&gt;</div><div class=\"line\">      fsBasedRelation.inputFiles</div><div class=\"line\">    case fr: FileRelation =&gt;</div><div class=\"line\">      fr.inputFiles</div><div class=\"line\">  &#125;.flatten</div><div class=\"line\">  files.toSet.toArray</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cj70mt0o9000060tus60zt94y","category_id":"cj70mt0or000460tuxolgvinf","_id":"cj70mt0pm000d60tudrvtta23"},{"post_id":"cj70mt0pn000e60tu14g5drzk","category_id":"cj70mt0pw000i60tu3c2ps462","_id":"cj70mt0qh000r60tu6tuwv1y2"},{"post_id":"cj70mt0qd000p60tui7nopoch","category_id":"cj70mt0qk000u60tujrwu8jwn","_id":"cj70mt0qr001160tuhg8qb74b"},{"post_id":"cj70mt11o001g60tusrxx6308","category_id":"cj70mt0pw000i60tu3c2ps462","_id":"cj70mt11z001i60tus0fcgehs"}],"PostTag":[{"post_id":"cj70mt0o9000060tus60zt94y","tag_id":"cj70mt0oy000560tugsc85bs8","_id":"cj70mt0pk000b60tuspdahmx3"},{"post_id":"cj70mt0p0000660tucsr32ywl","tag_id":"cj70mt0pi000a60tukjsprfwe","_id":"cj70mt0pv000h60tu5h72ibyf"},{"post_id":"cj70mt0p8000860tugthcweur","tag_id":"cj70mt0pi000a60tukjsprfwe","_id":"cj70mt0q5000m60tutxy8ggfb"},{"post_id":"cj70mt0pg000960tu6xsgjttb","tag_id":"cj70mt0q0000k60tuwkqkh14l","_id":"cj70mt0qh000q60tuevx057xl"},{"post_id":"cj70mt0q6000n60tu24fljvsv","tag_id":"cj70mt0q0000k60tuwkqkh14l","_id":"cj70mt0qk000t60tuew6z9ehg"},{"post_id":"cj70mt0pk000c60tucebvddu5","tag_id":"cj70mt0qb000o60tuz6n1nt0f","_id":"cj70mt0qo000x60tucqc7d0hg"},{"post_id":"cj70mt0qo000y60tulzcbcag5","tag_id":"cj70mt0qb000o60tuz6n1nt0f","_id":"cj70mt0qr001060tuxjkpb8xe"},{"post_id":"cj70mt0pn000e60tu14g5drzk","tag_id":"cj70mt0ql000v60tumq96gys6","_id":"cj70mt0qs001360tuiwiugrz1"},{"post_id":"cj70mt0pn000e60tu14g5drzk","tag_id":"cj70mt0qr000z60tuwokgslem","_id":"cj70mt0qs001460tuzaigk6z7"},{"post_id":"cj70mt0ps000g60tupfaojebl","tag_id":"cj70mt0qs001260tuue9hfg3e","_id":"cj70mt0qv001660tucy8nbepj"},{"post_id":"cj70mt0py000j60tupzkv0omm","tag_id":"cj70mt0ql000v60tumq96gys6","_id":"cj70mt0qw001860tu8dmupsrz"},{"post_id":"cj70mt0q2000l60tu3a1pfoam","tag_id":"cj70mt0qv001760tu10h07d5e","_id":"cj70mt0qx001a60tu44ciehnh"},{"post_id":"cj70mt0qd000p60tui7nopoch","tag_id":"cj70mt0qw001960tu5rw28csy","_id":"cj70mt0qy001c60tuk7m8s2iu"},{"post_id":"cj70mt0qi000s60tuo9h0op03","tag_id":"cj70mt0qw001960tu5rw28csy","_id":"cj70mt0r0001e60tu4e5dlm62"},{"post_id":"cj70mt0qm000w60tusjmyn6zp","tag_id":"cj70mt0qw001960tu5rw28csy","_id":"cj70mt0r0001f60tuc3t38s44"},{"post_id":"cj70mt11o001g60tusrxx6308","tag_id":"cj70mt0ql000v60tumq96gys6","_id":"cj70mt120001j60tucuwbcc26"},{"post_id":"cj70mt11o001g60tusrxx6308","tag_id":"cj70mt11w001h60tuu6wxrleg","_id":"cj70mt120001k60tu2qd5aub3"}],"Tag":[{"name":"-","_id":"cj70mt0oy000560tugsc85bs8"},{"name":"","_id":"cj70mt0pi000a60tukjsprfwe"},{"name":"","_id":"cj70mt0q0000k60tuwkqkh14l"},{"name":"linux","_id":"cj70mt0qb000o60tuz6n1nt0f"},{"name":"spark","_id":"cj70mt0ql000v60tumq96gys6"},{"name":"sql","_id":"cj70mt0qr000z60tuwokgslem"},{"name":"hexo","_id":"cj70mt0qs001260tuue9hfg3e"},{"name":"java","_id":"cj70mt0qv001760tu10h07d5e"},{"name":"scala","_id":"cj70mt0qw001960tu5rw28csy"},{"name":"","_id":"cj70mt11w001h60tuu6wxrleg"}]}}